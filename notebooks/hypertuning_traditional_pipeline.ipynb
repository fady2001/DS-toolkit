{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f5df1e",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "091b98a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"H\": 8, \"I\": 9, \"J\": 10,}\n",
    "list(dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cbdf18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "\n",
    "# Optuna for hyperparameter optimization\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# Define custom RMSLE function to handle zero values\n",
    "def rmsle_score(y_true, y_pred):\n",
    "    \"\"\"Calculate RMSLE with handling for zero and negative values\"\"\"\n",
    "    # Add small epsilon to avoid log(0) and ensure positive values\n",
    "    epsilon = 1e-15\n",
    "    y_true_log = np.log1p(np.maximum(y_true, epsilon))\n",
    "    y_pred_log = np.log1p(np.maximum(y_pred, epsilon))\n",
    "    return np.sqrt(mean_squared_error(y_true_log, y_pred_log))\n",
    "\n",
    "# Create scorer for GridSearchCV\n",
    "rmsle_scorer = make_scorer(rmsle_score, greater_is_better=False)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d493a80",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Initial Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96fc43a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/interim/traditional_final_train.csv', parse_dates=['date'])\n",
    "test_df = pd.read_csv('../data/interim/traditional_final_test.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0453ec8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns in the dataset:\n",
      "- family\n",
      "- city\n",
      "- state\n",
      "- type\n"
     ]
    }
   ],
   "source": [
    "# print categorial columns\n",
    "print(\"Categorical columns in the dataset:\")\n",
    "for col in train_df.select_dtypes(include=['object']).columns:\n",
    "    print(f\"- {col}\")\n",
    "    \n",
    "# Encode categorical features\n",
    "categorical_cols = train_df.select_dtypes(include=['object']).columns\n",
    "encoders = {}\n",
    "for col in categorical_cols:\n",
    "    encoder = OrdinalEncoder()\n",
    "    train_df[col+\"_encoded\"] = encoder.fit_transform(train_df[[col]])\n",
    "    encoders[col] = encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7d5140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_cols:\n",
    "    test_df[col+\"_encoded\"] = encoders[col].transform(test_df[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f624adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'date', 'store_nbr', 'family', 'sales', 'onpromotion', 'year',\n",
       "       'month', 'day', 'dayofweek', 'weekofyear', 'day_of_year', 'is_weekend',\n",
       "       'is_month_start', 'is_month_end', 'is_quarter_start', 'is_quarter_end',\n",
       "       'is_payday', 'days_since_payday', 'days_until_payday',\n",
       "       'sales_rolling_mean_7', 'sales_rolling_std_7', 'sales_rolling_max_7',\n",
       "       'sales_rolling_min_7', 'sales_rolling_mean_14', 'sales_rolling_std_14',\n",
       "       'sales_rolling_max_14', 'sales_rolling_min_14', 'sales_rolling_mean_30',\n",
       "       'sales_rolling_std_30', 'sales_rolling_max_30', 'sales_rolling_min_30',\n",
       "       'sales_lag_1', 'sales_lag_7', 'sales_lag_14', 'sales_lag_30',\n",
       "       'is_national_holiday', 'is_regional_holiday', 'is_local_holiday',\n",
       "       'is_additional_holiday', 'is_working_day', 'is_event', 'is_bridge_day',\n",
       "       'is_transferred_day', 'dcoilwtico', 'city', 'state', 'type', 'cluster',\n",
       "       'transactions', 'family_encoded', 'city_encoded', 'state_encoded',\n",
       "       'type_encoded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "697e82ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['date', 'store_nbr',\"family\",'onpromotion', 'year',\n",
    "       'month', 'day', 'dayofweek', 'weekofyear', 'day_of_year', 'is_weekend',\n",
    "       'is_month_start', 'is_month_end', 'is_quarter_start', 'is_quarter_end',\n",
    "       'is_payday', 'days_since_payday', 'days_until_payday',\n",
    "       'is_national_holiday', 'is_regional_holiday', 'is_local_holiday',\n",
    "       'is_additional_holiday', 'is_working_day', 'is_event', 'is_bridge_day',\n",
    "       'is_transferred_day', 'dcoilwtico', 'cluster',\n",
    "       'transactions', 'family_encoded', 'city_encoded', 'state_encoded',\n",
    "       'type_encoded','sales_rolling_mean_7', 'sales_rolling_std_7', 'sales_rolling_max_7',\n",
    "       'sales_rolling_min_7', 'sales_rolling_mean_14', 'sales_rolling_std_14',\n",
    "       'sales_rolling_max_14', 'sales_rolling_min_14', 'sales_rolling_mean_30',\n",
    "       'sales_rolling_std_30', 'sales_rolling_max_30', 'sales_rolling_min_30',\n",
    "       'sales_lag_1', 'sales_lag_7', 'sales_lag_14', 'sales_lag_30',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e21a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df[feature_cols]\n",
    "test = test_df[feature_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c248ace5",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter Tuning Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1344ec14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter grid defined for LightGBM tuning\n",
      "Total combinations in small grid: 256\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter grid for LightGBM\n",
    "param_grid = {\n",
    "    'n_estimators': [500, 1000, 1500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'num_leaves': [31, 50, 100],\n",
    "    'max_depth': [-1, 10, 20],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [0, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "# For faster tuning, use a smaller parameter grid\n",
    "# You can expand this for more thorough tuning\n",
    "param_grid_small = {\n",
    "    'n_estimators': [500, 1000],\n",
    "    'learning_rate': [0.01, 0.05],\n",
    "    'num_leaves': [31, 50],\n",
    "    'max_depth': [-1, 10],\n",
    "    'subsample': [0.8, 0.9],\n",
    "    'colsample_bytree': [0.8, 0.9],\n",
    "    'reg_alpha': [0, 0.1],\n",
    "    'reg_lambda': [0, 0.1]\n",
    "}\n",
    "\n",
    "print(\"Hyperparameter grid defined for LightGBM tuning\")\n",
    "print(f\"Total combinations in small grid: {np.prod([len(v) for v in param_grid_small.values()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2aa5f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform hyperparameter tuning for a specific family\n",
    "def tune_hyperparameters(X_train, y_train, family_name, param_grid=param_grid_small, cv_folds=3):\n",
    "    \"\"\"\n",
    "    Perform hyperparameter tuning for LightGBM model\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== Tuning hyperparameters for {family_name} ===\")\n",
    "    \n",
    "    # Create base model\n",
    "    lgb_model = lgb.LGBMRegressor(\n",
    "        objective='regression',\n",
    "        metric='rmse',\n",
    "        random_state=42,\n",
    "        force_row_wise=True,\n",
    "        verbose=-1  # Reduce verbosity\n",
    "    )\n",
    "    \n",
    "    # Create time series split for cross-validation\n",
    "    tscv = TimeSeriesSplit(n_splits=cv_folds)\n",
    "    \n",
    "    # Perform grid search\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=lgb_model,\n",
    "        param_grid=param_grid,\n",
    "        scoring=rmsle_scorer,\n",
    "        cv=tscv,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit grid search\n",
    "    print(f\"Starting grid search with {np.prod([len(v) for v in param_grid.values()])} parameter combinations...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Best RMSLE score: {-grid_search.best_score_:.4f}\")\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    \n",
    "    return grid_search.best_estimator_, grid_search.best_params_, -grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "603644ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform hyperparameter tuning for a specific family\n",
    "def Randomized_tune_hyperparameters(X_train, y_train, family_name, param_grid=param_grid_small, cv_folds=3):\n",
    "    \"\"\"\n",
    "    Perform hyperparameter tuning for LightGBM model using RandomizedSearchCV\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== Randomized Tuning hyperparameters for {family_name} ===\")\n",
    "    \n",
    "    # Create base model\n",
    "    lgb_model = lgb.LGBMRegressor(\n",
    "        objective='regression',\n",
    "        metric='rmse',\n",
    "        random_state=42,\n",
    "        force_row_wise=True,\n",
    "        verbose=-1  # Reduce verbosity\n",
    "    )\n",
    "    \n",
    "    # Create time series split for cross-validation\n",
    "    tscv = TimeSeriesSplit(n_splits=cv_folds)\n",
    "    \n",
    "    # Perform randomized search\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=lgb_model,\n",
    "        param_distributions=param_grid,\n",
    "        scoring=rmsle_scorer,\n",
    "        cv=tscv,\n",
    "        n_iter=30,  # Number of iterations for randomized search\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Fit randomized search\n",
    "    print(f\"Starting randomized search with {len(param_grid)} parameter combinations...\")\n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Best RMSLE score: {-random_search.best_score_:.4f}\")\n",
    "    print(f\"Best parameters: {random_search.best_params_}\")\n",
    "    \n",
    "    return random_search.best_estimator_, random_search.best_params_, -random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d95b141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_tune_hyperparameters(X_train, y_train, family_name, param_grid=param_grid_small, cv_folds=3):\n",
    "    \"\"\"\n",
    "    Perform hyperparameter tuning for LightGBM model using Optuna\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== Optuna Tuning hyperparameters for {family_name} ===\")\n",
    "    \n",
    "    # Define objective function for Optuna\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_categorical('n_estimators', param_grid['n_estimators']),\n",
    "            'learning_rate': trial.suggest_categorical('learning_rate', param_grid['learning_rate']),\n",
    "            'num_leaves': trial.suggest_categorical('num_leaves', param_grid['num_leaves']),\n",
    "            'max_depth': trial.suggest_categorical('max_depth', param_grid['max_depth']),\n",
    "            'subsample': trial.suggest_categorical('subsample', param_grid['subsample']),\n",
    "            'colsample_bytree': trial.suggest_categorical('colsample_bytree', param_grid['colsample_bytree']),\n",
    "            'reg_alpha': trial.suggest_categorical('reg_alpha', param_grid['reg_alpha']),\n",
    "            'reg_lambda': trial.suggest_categorical('reg_lambda', param_grid['reg_lambda'])\n",
    "        }\n",
    "        \n",
    "        lgb_model = lgb.LGBMRegressor(\n",
    "            **params,\n",
    "            objective='regression',\n",
    "            metric='rmse',\n",
    "            random_state=42,\n",
    "            force_row_wise=True,\n",
    "            verbose=-1\n",
    "        )\n",
    "        \n",
    "        tscv = TimeSeriesSplit(n_splits=cv_folds)\n",
    "        scores = []\n",
    "        \n",
    "        for train_index, val_index in tscv.split(X_train):\n",
    "            X_tr, X_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_tr, y_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "            \n",
    "            lgb_model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)])\n",
    "            y_pred = lgb_model.predict(X_val)\n",
    "            score = rmsle_score(y_val, y_pred)\n",
    "            scores.append(score)\n",
    "        \n",
    "        return np.mean(scores)\n",
    "    \n",
    "    # Create Optuna study\n",
    "    study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "    \n",
    "    # Optimize the study\n",
    "    study.optimize(objective, n_trials=50)  # Number of trials can be adjusted\n",
    "    \n",
    "    print(f\"Best RMSLE score: {study.best_value:.4f}\")\n",
    "    print(f\"Best parameters: {study.best_params}\")\n",
    "    \n",
    "    # Create final model with best parameters\n",
    "    best_params = study.best_params\n",
    "    best_model = lgb.LGBMRegressor(\n",
    "        **best_params,\n",
    "        objective='regression',\n",
    "        metric='rmse',\n",
    "        random_state=42,\n",
    "        force_row_wise=True,\n",
    "        verbose=-1\n",
    "    )\n",
    "    best_model.fit(X_train, y_train)\n",
    "    return best_model, best_params, study.best_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a150a73a",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Tuning and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5301e1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter tuning for 33 families...\n",
      "This may take a while depending on the parameter grid size.\n",
      "\n",
      "\n",
      "============================================================\n",
      "Progress: 1/33 - Training model for family: AUTOMOTIVE\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 10:58:34,288] A new study created in memory with name: no-name-495be042-15e3-4d12-9fe2-e9e9e524b743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family AUTOMOTIVE data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for AUTOMOTIVE ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 10:58:42,261] Trial 0 finished with value: 0.5270288537706745 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.5270288537706745.\n",
      "[I 2025-05-31 10:58:48,904] Trial 1 finished with value: 0.5236975677886853 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.5236975677886853.\n",
      "[I 2025-05-31 10:58:56,726] Trial 2 finished with value: 0.5306647045225192 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 1 with value: 0.5236975677886853.\n",
      "[I 2025-05-31 10:59:00,966] Trial 3 finished with value: 0.5445368982254789 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.5236975677886853.\n",
      "[I 2025-05-31 10:59:08,712] Trial 4 finished with value: 0.5377679710420401 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.5236975677886853.\n",
      "[I 2025-05-31 10:59:14,408] Trial 5 finished with value: 0.5452482212095853 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.5236975677886853.\n",
      "[I 2025-05-31 10:59:19,090] Trial 6 finished with value: 0.5244932984059162 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.5236975677886853.\n",
      "[I 2025-05-31 10:59:23,102] Trial 7 finished with value: 0.5305689635916421 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 1 with value: 0.5236975677886853.\n",
      "[I 2025-05-31 10:59:34,706] Trial 8 finished with value: 0.5256688436480091 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.5236975677886853.\n",
      "[I 2025-05-31 10:59:40,082] Trial 9 finished with value: 0.5498140609098457 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 1 with value: 0.5236975677886853.\n",
      "[I 2025-05-31 10:59:46,063] Trial 10 finished with value: 0.5335542515907481 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 1 with value: 0.5236975677886853.\n",
      "[I 2025-05-31 10:59:50,274] Trial 11 finished with value: 0.5244932984059162 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.5236975677886853.\n",
      "[I 2025-05-31 10:59:53,461] Trial 12 finished with value: 0.5197348355283791 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 10:59:59,168] Trial 13 finished with value: 0.5270297948813504 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:00:05,938] Trial 14 finished with value: 0.5323939009779114 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:00:09,206] Trial 15 finished with value: 0.5197348355283791 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:00:12,288] Trial 16 finished with value: 0.5197348355283791 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:00:15,676] Trial 17 finished with value: 0.5197348355283791 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:00:19,620] Trial 18 finished with value: 0.5242740669770335 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:00:22,952] Trial 19 finished with value: 0.5197348355283791 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:00:26,994] Trial 20 finished with value: 0.5197348355283791 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:00:31,013] Trial 21 finished with value: 0.5197348355283791 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:00:34,236] Trial 22 finished with value: 0.5197348355283791 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:00:37,646] Trial 23 finished with value: 0.5197348355283791 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:00:40,778] Trial 24 finished with value: 0.5197348355283791 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:00:43,787] Trial 25 finished with value: 0.5197348355283791 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:00:47,077] Trial 26 finished with value: 0.5242740669770335 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:00:50,175] Trial 27 finished with value: 0.5197348355283791 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:00:53,194] Trial 28 finished with value: 0.5197348355283791 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:00:56,467] Trial 29 finished with value: 0.5210355944818178 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:00:59,708] Trial 30 finished with value: 0.5197348355283791 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:01:02,924] Trial 31 finished with value: 0.5197348355283791 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:01:06,048] Trial 32 finished with value: 0.5197348355283791 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:01:09,122] Trial 33 finished with value: 0.5197348355283791 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:01:12,263] Trial 34 finished with value: 0.5197348355283791 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:01:15,262] Trial 35 finished with value: 0.5197348355283791 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:01:24,386] Trial 36 finished with value: 0.5257034041881344 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:01:29,533] Trial 37 finished with value: 0.5236387444981107 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:01:34,260] Trial 38 finished with value: 0.5457463819133846 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:01:40,403] Trial 39 finished with value: 0.5244932984059162 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:01:48,222] Trial 40 finished with value: 0.5232420185998605 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:01:52,992] Trial 41 finished with value: 0.5197348355283791 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:01:57,474] Trial 42 finished with value: 0.5197348355283791 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:02:01,356] Trial 43 finished with value: 0.5197348355283791 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.5197348355283791.\n",
      "[I 2025-05-31 11:02:05,331] Trial 44 finished with value: 0.5186121148555788 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 44 with value: 0.5186121148555788.\n",
      "[I 2025-05-31 11:02:10,880] Trial 45 finished with value: 0.5428359419835938 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 44 with value: 0.5186121148555788.\n",
      "[I 2025-05-31 11:02:15,194] Trial 46 finished with value: 0.519719641361458 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 44 with value: 0.5186121148555788.\n",
      "[I 2025-05-31 11:02:24,094] Trial 47 finished with value: 0.5362613422688886 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 44 with value: 0.5186121148555788.\n",
      "[I 2025-05-31 11:02:28,274] Trial 48 finished with value: 0.5479083510916373 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 44 with value: 0.5186121148555788.\n",
      "[I 2025-05-31 11:02:32,753] Trial 49 finished with value: 0.5236387444981107 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 44 with value: 0.5186121148555788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.5186\n",
      "Best parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}\n",
      "Validation - RMSE: 5.0195, MAE: 3.4110, RMSLE: 0.4121\n",
      "✓ Successfully tuned model for AUTOMOTIVE\n",
      "\n",
      "============================================================\n",
      "Progress: 2/33 - Training model for family: BABY CARE\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 11:02:34,705] A new study created in memory with name: no-name-9fc45a46-4a56-4256-a6fe-b8380f95dc2e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family BABY CARE data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for BABY CARE ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 11:02:40,233] Trial 0 finished with value: 0.2096489618820908 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.2096489618820908.\n",
      "[I 2025-05-31 11:02:44,983] Trial 1 finished with value: 0.20964377751668192 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.20964377751668192.\n",
      "[I 2025-05-31 11:02:51,051] Trial 2 finished with value: 0.2114645841478265 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 1 with value: 0.20964377751668192.\n",
      "[I 2025-05-31 11:02:53,742] Trial 3 finished with value: 0.20707234332020966 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 3 with value: 0.20707234332020966.\n",
      "[I 2025-05-31 11:03:01,539] Trial 4 finished with value: 0.22721599431662617 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 3 with value: 0.20707234332020966.\n",
      "[I 2025-05-31 11:03:05,104] Trial 5 finished with value: 0.20951662325180506 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 3 with value: 0.20707234332020966.\n",
      "[I 2025-05-31 11:03:08,568] Trial 6 finished with value: 0.2166473624106248 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 3 with value: 0.20707234332020966.\n",
      "[I 2025-05-31 11:03:12,340] Trial 7 finished with value: 0.21866949791600698 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 3 with value: 0.20707234332020966.\n",
      "[I 2025-05-31 11:03:21,458] Trial 8 finished with value: 0.21384871326714058 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 3 with value: 0.20707234332020966.\n",
      "[I 2025-05-31 11:03:26,026] Trial 9 finished with value: 0.20929960043949922 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 3 with value: 0.20707234332020966.\n",
      "[I 2025-05-31 11:03:29,260] Trial 10 finished with value: 0.21583832813724443 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 3 with value: 0.20707234332020966.\n",
      "[I 2025-05-31 11:03:32,495] Trial 11 finished with value: 0.20831350017329017 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 3 with value: 0.20707234332020966.\n",
      "[I 2025-05-31 11:03:35,521] Trial 12 finished with value: 0.2072489660940783 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 3 with value: 0.20707234332020966.\n",
      "[I 2025-05-31 11:03:38,081] Trial 13 finished with value: 0.2072489660940783 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 3 with value: 0.20707234332020966.\n",
      "[I 2025-05-31 11:03:40,643] Trial 14 finished with value: 0.2074622488664796 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 3 with value: 0.20707234332020966.\n",
      "[I 2025-05-31 11:03:43,160] Trial 15 finished with value: 0.2072489660940783 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 3 with value: 0.20707234332020966.\n",
      "[I 2025-05-31 11:03:45,825] Trial 16 finished with value: 0.20705651582935147 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:03:48,458] Trial 17 finished with value: 0.20707234332020966 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:03:51,402] Trial 18 finished with value: 0.21551634274260337 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:03:55,510] Trial 19 finished with value: 0.20705651582935147 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:03:58,171] Trial 20 finished with value: 0.20705651582935147 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:04:01,038] Trial 21 finished with value: 0.20705651582935147 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:04:03,665] Trial 22 finished with value: 0.20705651582935147 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:04:06,622] Trial 23 finished with value: 0.20705651582935147 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:04:09,200] Trial 24 finished with value: 0.20705651582935147 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:04:11,895] Trial 25 finished with value: 0.20705651582935147 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:04:16,611] Trial 26 finished with value: 0.22144138744800634 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:04:19,209] Trial 27 finished with value: 0.20705651582935147 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:04:22,098] Trial 28 finished with value: 0.20705651582935147 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:04:26,941] Trial 29 finished with value: 0.20968771786553228 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:04:30,813] Trial 30 finished with value: 0.20705651582935147 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:04:34,128] Trial 31 finished with value: 0.20705651582935147 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:04:38,619] Trial 32 finished with value: 0.20705651582935147 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:04:43,900] Trial 33 finished with value: 0.20705651582935147 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:04:50,086] Trial 34 finished with value: 0.20968771786553228 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:04:53,258] Trial 35 finished with value: 0.20705651582935147 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:04:59,033] Trial 36 finished with value: 0.21149588448900972 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:05:01,990] Trial 37 finished with value: 0.21662871551555893 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:05:05,098] Trial 38 finished with value: 0.20775382568174183 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:05:08,580] Trial 39 finished with value: 0.2087499707153971 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:05:14,999] Trial 40 finished with value: 0.22393348939809266 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:05:17,623] Trial 41 finished with value: 0.20705651582935147 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:05:20,422] Trial 42 finished with value: 0.20705651582935147 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:05:23,056] Trial 43 finished with value: 0.20705651582935147 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:05:25,962] Trial 44 finished with value: 0.20705651582935147 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:05:29,178] Trial 45 finished with value: 0.20869504611335765 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:05:31,802] Trial 46 finished with value: 0.20705651582935147 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:05:34,576] Trial 47 finished with value: 0.20768252610532856 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:05:37,036] Trial 48 finished with value: 0.2074622488664796 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n",
      "[I 2025-05-31 11:05:39,815] Trial 49 finished with value: 0.21662871551555893 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.20705651582935147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.2071\n",
      "Best parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}\n",
      "Validation - RMSE: 0.1665, MAE: 0.0202, RMSLE: 0.0736\n",
      "✓ Successfully tuned model for BABY CARE\n",
      "\n",
      "============================================================\n",
      "Progress: 3/33 - Training model for family: BEAUTY\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 11:05:41,314] A new study created in memory with name: no-name-de3c453e-1737-4aaf-a8e1-5122512537b6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family BEAUTY data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for BEAUTY ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 11:05:49,101] Trial 0 finished with value: 0.456543357121638 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.456543357121638.\n",
      "[I 2025-05-31 11:05:58,995] Trial 1 finished with value: 0.45880457602382546 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.456543357121638.\n",
      "[I 2025-05-31 11:06:09,374] Trial 2 finished with value: 0.46039992721139217 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.456543357121638.\n",
      "[I 2025-05-31 11:06:14,795] Trial 3 finished with value: 0.4785726231762566 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.456543357121638.\n",
      "[I 2025-05-31 11:06:23,023] Trial 4 finished with value: 0.43947004925192507 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:06:27,898] Trial 5 finished with value: 0.45488131598315157 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:06:31,905] Trial 6 finished with value: 0.44503928649094243 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:06:35,364] Trial 7 finished with value: 0.44650681067743353 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:06:44,134] Trial 8 finished with value: 0.441386693737587 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:06:49,475] Trial 9 finished with value: 0.46319758169434383 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:06:57,480] Trial 10 finished with value: 0.4455104996455311 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:07:05,353] Trial 11 finished with value: 0.43947004925192507 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:07:12,945] Trial 12 finished with value: 0.43947004925192507 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:07:20,873] Trial 13 finished with value: 0.43947004925192507 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:07:28,362] Trial 14 finished with value: 0.4418319360934 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:07:36,119] Trial 15 finished with value: 0.43947004925192507 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:07:43,927] Trial 16 finished with value: 0.43947004925192507 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:07:51,798] Trial 17 finished with value: 0.43947004925192507 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:07:59,045] Trial 18 finished with value: 0.4414763755710684 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:08:06,894] Trial 19 finished with value: 0.43947004925192507 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:08:15,874] Trial 20 finished with value: 0.43947004925192507 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:08:23,858] Trial 21 finished with value: 0.43947004925192507 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:08:37,389] Trial 22 finished with value: 0.43947004925192507 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:08:45,371] Trial 23 finished with value: 0.43947004925192507 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:08:53,518] Trial 24 finished with value: 0.43947004925192507 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:09:01,174] Trial 25 finished with value: 0.43947004925192507 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:09:04,859] Trial 26 finished with value: 0.44827387936773383 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:09:13,767] Trial 27 finished with value: 0.43947004925192507 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:09:21,579] Trial 28 finished with value: 0.43947004925192507 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:09:27,716] Trial 29 finished with value: 0.44276963409113473 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:09:35,727] Trial 30 finished with value: 0.43947004925192507 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:09:43,439] Trial 31 finished with value: 0.43947004925192507 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:09:51,074] Trial 32 finished with value: 0.43947004925192507 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:09:58,717] Trial 33 finished with value: 0.43947004925192507 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:10:06,949] Trial 34 finished with value: 0.45880457602382546 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:10:16,078] Trial 35 finished with value: 0.441386693737587 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:10:19,345] Trial 36 finished with value: 0.45109834073540017 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:10:26,818] Trial 37 finished with value: 0.44161983059265864 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:10:31,726] Trial 38 finished with value: 0.45488131598315157 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:10:37,838] Trial 39 finished with value: 0.4431336608718677 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:10:43,068] Trial 40 finished with value: 0.456836503009629 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:10:51,094] Trial 41 finished with value: 0.43947004925192507 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:10:58,989] Trial 42 finished with value: 0.43947004925192507 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:11:09,464] Trial 43 finished with value: 0.43947004925192507 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:11:21,018] Trial 44 finished with value: 0.43947004925192507 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:11:29,071] Trial 45 finished with value: 0.43947004925192507 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:11:36,943] Trial 46 finished with value: 0.4418319360934 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:11:44,678] Trial 47 finished with value: 0.4412455853385269 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:11:53,544] Trial 48 finished with value: 0.441386693737587 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.43947004925192507.\n",
      "[I 2025-05-31 11:11:57,641] Trial 49 finished with value: 0.44200204563725976 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.43947004925192507.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.4395\n",
      "Best parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}\n",
      "Validation - RMSE: 3.6306, MAE: 2.1390, RMSLE: 0.3784\n",
      "✓ Successfully tuned model for BEAUTY\n",
      "\n",
      "============================================================\n",
      "Progress: 4/33 - Training model for family: BEVERAGES\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 11:12:01,308] A new study created in memory with name: no-name-39faa03a-b827-4a1f-99d6-ecc652ef0b78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family BEVERAGES data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for BEVERAGES ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 11:12:11,032] Trial 0 finished with value: 1.201111731352347 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 1.201111731352347.\n",
      "[I 2025-05-31 11:12:20,721] Trial 1 finished with value: 1.184422406534354 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 1.184422406534354.\n",
      "[I 2025-05-31 11:12:30,431] Trial 2 finished with value: 1.1909683364737287 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 1 with value: 1.184422406534354.\n",
      "[I 2025-05-31 11:12:35,063] Trial 3 finished with value: 1.4222096712990615 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 1.184422406534354.\n",
      "[I 2025-05-31 11:12:46,759] Trial 4 finished with value: 1.0879930234336197 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 1.0879930234336197.\n",
      "[I 2025-05-31 11:12:55,156] Trial 5 finished with value: 1.4035803671744425 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 1.0879930234336197.\n",
      "[I 2025-05-31 11:13:00,498] Trial 6 finished with value: 1.1348406188200613 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 1.0879930234336197.\n",
      "[I 2025-05-31 11:13:04,405] Trial 7 finished with value: 1.1233262917130233 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 1.0879930234336197.\n",
      "[I 2025-05-31 11:13:15,515] Trial 8 finished with value: 1.159172963673394 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 1.0879930234336197.\n",
      "[I 2025-05-31 11:13:22,907] Trial 9 finished with value: 1.3756892019676086 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 1.0879930234336197.\n",
      "[I 2025-05-31 11:13:34,268] Trial 10 finished with value: 1.0830597449255661 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 1.0830597449255661.\n",
      "[I 2025-05-31 11:13:44,325] Trial 11 finished with value: 1.0830597449255661 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 1.0830597449255661.\n",
      "[I 2025-05-31 11:13:54,391] Trial 12 finished with value: 1.0830597449255661 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 1.0830597449255661.\n",
      "[I 2025-05-31 11:14:04,385] Trial 13 finished with value: 1.0830597449255661 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 1.0830597449255661.\n",
      "[I 2025-05-31 11:14:14,373] Trial 14 finished with value: 1.0830597449255661 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 1.0830597449255661.\n",
      "[I 2025-05-31 11:14:24,338] Trial 15 finished with value: 1.0830597449255661 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 1.0830597449255661.\n",
      "[I 2025-05-31 11:14:34,317] Trial 16 finished with value: 1.0830597449255661 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 1.0830597449255661.\n",
      "[I 2025-05-31 11:14:44,764] Trial 17 finished with value: 1.0830597449255661 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 1.0830597449255661.\n",
      "[I 2025-05-31 11:14:54,728] Trial 18 finished with value: 1.0899450581208712 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 10 with value: 1.0830597449255661.\n",
      "[I 2025-05-31 11:15:04,716] Trial 19 finished with value: 1.0830597449255661 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 1.0830597449255661.\n",
      "[I 2025-05-31 11:15:14,975] Trial 20 finished with value: 1.0830597449255661 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 1.0830597449255661.\n",
      "[I 2025-05-31 11:15:24,755] Trial 21 finished with value: 1.0830597449255661 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 1.0830597449255661.\n",
      "[I 2025-05-31 11:15:34,990] Trial 22 finished with value: 1.0830597449255661 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 1.0830597449255661.\n",
      "[I 2025-05-31 11:15:45,138] Trial 23 finished with value: 1.0830597449255661 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 1.0830597449255661.\n",
      "[I 2025-05-31 11:15:55,121] Trial 24 finished with value: 1.0830597449255661 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 1.0830597449255661.\n",
      "[I 2025-05-31 11:16:06,176] Trial 25 finished with value: 1.0830597449255661 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 1.0830597449255661.\n",
      "[I 2025-05-31 11:16:11,329] Trial 26 finished with value: 1.1920273977052611 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 10 with value: 1.0830597449255661.\n",
      "[I 2025-05-31 11:16:22,774] Trial 27 finished with value: 1.0830597449255661 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 1.0830597449255661.\n",
      "[I 2025-05-31 11:16:34,420] Trial 28 finished with value: 1.0830597449255661 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 1.0830597449255661.\n",
      "[I 2025-05-31 11:16:42,167] Trial 29 finished with value: 1.123253050127933 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 10 with value: 1.0830597449255661.\n",
      "[I 2025-05-31 11:16:52,088] Trial 30 finished with value: 1.0830597449255661 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 1.0830597449255661.\n",
      "[I 2025-05-31 11:17:02,089] Trial 31 finished with value: 1.0830597449255661 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 1.0830597449255661.\n",
      "[I 2025-05-31 11:17:12,114] Trial 32 finished with value: 1.0830597449255661 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 1.0830597449255661.\n",
      "[I 2025-05-31 11:17:22,428] Trial 33 finished with value: 1.0830597449255661 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 1.0830597449255661.\n",
      "[I 2025-05-31 11:17:30,448] Trial 34 finished with value: 1.1733789023527492 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 10 with value: 1.0830597449255661.\n",
      "[I 2025-05-31 11:17:40,712] Trial 35 finished with value: 1.0729653114748794 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 35 with value: 1.0729653114748794.\n",
      "[I 2025-05-31 11:17:48,829] Trial 36 finished with value: 1.2056620153923774 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 35 with value: 1.0729653114748794.\n",
      "[I 2025-05-31 11:17:54,648] Trial 37 finished with value: 1.1057650890313624 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 35 with value: 1.0729653114748794.\n",
      "[I 2025-05-31 11:18:05,424] Trial 38 finished with value: 1.1674070139268509 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 35 with value: 1.0729653114748794.\n",
      "[I 2025-05-31 11:18:09,508] Trial 39 finished with value: 1.1168468099061888 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 35 with value: 1.0729653114748794.\n",
      "[I 2025-05-31 11:18:19,753] Trial 40 finished with value: 1.0729653114748794 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 35 with value: 1.0729653114748794.\n",
      "[I 2025-05-31 11:18:30,133] Trial 41 finished with value: 1.0729653114748794 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 35 with value: 1.0729653114748794.\n",
      "[I 2025-05-31 11:18:40,972] Trial 42 finished with value: 1.0729653114748794 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 35 with value: 1.0729653114748794.\n",
      "[I 2025-05-31 11:18:51,247] Trial 43 finished with value: 1.0729653114748794 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 35 with value: 1.0729653114748794.\n",
      "[I 2025-05-31 11:19:02,117] Trial 44 finished with value: 1.0729653114748794 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 35 with value: 1.0729653114748794.\n",
      "[I 2025-05-31 11:19:08,219] Trial 45 finished with value: 1.4035803671744425 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 35 with value: 1.0729653114748794.\n",
      "[I 2025-05-31 11:19:18,549] Trial 46 finished with value: 1.0850977377355173 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 35 with value: 1.0729653114748794.\n",
      "[I 2025-05-31 11:19:28,714] Trial 47 finished with value: 1.0729653114748794 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 35 with value: 1.0729653114748794.\n",
      "[I 2025-05-31 11:19:38,995] Trial 48 finished with value: 1.0729653114748794 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 35 with value: 1.0729653114748794.\n",
      "[I 2025-05-31 11:19:50,536] Trial 49 finished with value: 1.1674070139268509 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 35 with value: 1.0729653114748794.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 1.0730\n",
      "Best parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}\n",
      "Validation - RMSE: 1222.1127, MAE: 712.2011, RMSLE: 0.3451\n",
      "✓ Successfully tuned model for BEVERAGES\n",
      "\n",
      "============================================================\n",
      "Progress: 5/33 - Training model for family: BOOKS\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 11:19:55,425] A new study created in memory with name: no-name-9dd7c658-291d-477f-a788-6a9493225a10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family BOOKS data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for BOOKS ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 11:19:59,490] Trial 0 finished with value: 0.0609081929661513 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.0609081929661513.\n",
      "[I 2025-05-31 11:20:03,897] Trial 1 finished with value: 0.060889515647882995 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.060889515647882995.\n",
      "[I 2025-05-31 11:20:09,309] Trial 2 finished with value: 0.06100139546866231 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 1 with value: 0.060889515647882995.\n",
      "[I 2025-05-31 11:20:11,528] Trial 3 finished with value: 0.06043217349290921 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 3 with value: 0.06043217349290921.\n",
      "[I 2025-05-31 11:20:19,686] Trial 4 finished with value: 0.06564353646945277 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 3 with value: 0.06043217349290921.\n",
      "[I 2025-05-31 11:20:24,662] Trial 5 finished with value: 0.06115144082920795 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 3 with value: 0.06043217349290921.\n",
      "[I 2025-05-31 11:20:28,751] Trial 6 finished with value: 0.06343369297355897 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 3 with value: 0.06043217349290921.\n",
      "[I 2025-05-31 11:20:34,190] Trial 7 finished with value: 0.06283853042243291 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 3 with value: 0.06043217349290921.\n",
      "[I 2025-05-31 11:20:43,476] Trial 8 finished with value: 0.06217699267401256 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 3 with value: 0.06043217349290921.\n",
      "[I 2025-05-31 11:20:46,809] Trial 9 finished with value: 0.0608472258807616 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 3 with value: 0.06043217349290921.\n",
      "[I 2025-05-31 11:20:48,892] Trial 10 finished with value: 0.0636869227820477 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 3 with value: 0.06043217349290921.\n",
      "[I 2025-05-31 11:20:51,841] Trial 11 finished with value: 0.060506042408639764 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 3 with value: 0.06043217349290921.\n",
      "[I 2025-05-31 11:20:54,183] Trial 12 finished with value: 0.06041133373441173 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.06041133373441173.\n",
      "[I 2025-05-31 11:20:56,550] Trial 13 finished with value: 0.06041133373441173 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.06041133373441173.\n",
      "[I 2025-05-31 11:20:58,797] Trial 14 finished with value: 0.06041133373441173 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.06041133373441173.\n",
      "[I 2025-05-31 11:21:01,256] Trial 15 finished with value: 0.06041133373441173 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.06041133373441173.\n",
      "[I 2025-05-31 11:21:03,405] Trial 16 finished with value: 0.06041133373441173 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.06041133373441173.\n",
      "[I 2025-05-31 11:21:05,712] Trial 17 finished with value: 0.06041133373441173 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.06041133373441173.\n",
      "[I 2025-05-31 11:21:07,902] Trial 18 finished with value: 0.06317807483944755 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.06041133373441173.\n",
      "[I 2025-05-31 11:21:10,061] Trial 19 finished with value: 0.06041133373441173 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.06041133373441173.\n",
      "[I 2025-05-31 11:21:12,590] Trial 20 finished with value: 0.06041133373441173 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.06041133373441173.\n",
      "[I 2025-05-31 11:21:14,755] Trial 21 finished with value: 0.06041133373441173 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.06041133373441173.\n",
      "[I 2025-05-31 11:21:17,025] Trial 22 finished with value: 0.06041133373441173 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.06041133373441173.\n",
      "[I 2025-05-31 11:21:19,183] Trial 23 finished with value: 0.06041133373441173 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.06041133373441173.\n",
      "[I 2025-05-31 11:21:21,482] Trial 24 finished with value: 0.06041133373441173 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.06041133373441173.\n",
      "[I 2025-05-31 11:21:23,690] Trial 25 finished with value: 0.06041133373441173 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.06041133373441173.\n",
      "[I 2025-05-31 11:21:28,380] Trial 26 finished with value: 0.06478616483256398 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.06041133373441173.\n",
      "[I 2025-05-31 11:21:30,938] Trial 27 finished with value: 0.06041133373441173 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.06041133373441173.\n",
      "[I 2025-05-31 11:21:33,254] Trial 28 finished with value: 0.06041133373441173 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.06041133373441173.\n",
      "[I 2025-05-31 11:21:38,861] Trial 29 finished with value: 0.06104432965589629 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.06041133373441173.\n",
      "[I 2025-05-31 11:21:41,130] Trial 30 finished with value: 0.06041133373441173 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.06041133373441173.\n",
      "[I 2025-05-31 11:21:44,184] Trial 31 finished with value: 0.06041133373441173 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.06041133373441173.\n",
      "[I 2025-05-31 11:21:46,243] Trial 32 finished with value: 0.06041133373441173 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.06041133373441173.\n",
      "[I 2025-05-31 11:21:48,515] Trial 33 finished with value: 0.06041133373441173 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.06041133373441173.\n",
      "[I 2025-05-31 11:21:53,376] Trial 34 finished with value: 0.060885602355160405 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.06041133373441173.\n",
      "[I 2025-05-31 11:21:56,324] Trial 35 finished with value: 0.06051953640111626 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.06041133373441173.\n",
      "[I 2025-05-31 11:22:03,275] Trial 36 finished with value: 0.06092588358461396 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.06041133373441173.\n",
      "[I 2025-05-31 11:22:06,636] Trial 37 finished with value: 0.06319538850026672 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.06041133373441173.\n",
      "[I 2025-05-31 11:22:10,595] Trial 38 finished with value: 0.06036107241415604 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 38 with value: 0.06036107241415604.\n",
      "[I 2025-05-31 11:22:14,450] Trial 39 finished with value: 0.06115144082920795 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 38 with value: 0.06036107241415604.\n",
      "[I 2025-05-31 11:22:21,311] Trial 40 finished with value: 0.06472818639742925 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 38 with value: 0.06036107241415604.\n",
      "[I 2025-05-31 11:22:23,875] Trial 41 finished with value: 0.06036107241415604 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 38 with value: 0.06036107241415604.\n",
      "[I 2025-05-31 11:22:26,387] Trial 42 finished with value: 0.06036107241415604 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 38 with value: 0.06036107241415604.\n",
      "[I 2025-05-31 11:22:32,683] Trial 43 finished with value: 0.06036107241415604 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 38 with value: 0.06036107241415604.\n",
      "[I 2025-05-31 11:22:35,782] Trial 44 finished with value: 0.06036107241415604 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 38 with value: 0.06036107241415604.\n",
      "[I 2025-05-31 11:22:40,421] Trial 45 finished with value: 0.06115144082920795 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 38 with value: 0.06036107241415604.\n",
      "[I 2025-05-31 11:22:42,802] Trial 46 finished with value: 0.06036107241415604 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 38 with value: 0.06036107241415604.\n",
      "[I 2025-05-31 11:22:44,969] Trial 47 finished with value: 0.06036107241415604 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 38 with value: 0.06036107241415604.\n",
      "[I 2025-05-31 11:22:47,200] Trial 48 finished with value: 0.06036107241415604 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 38 with value: 0.06036107241415604.\n",
      "[I 2025-05-31 11:22:51,565] Trial 49 finished with value: 0.06359808975238665 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 38 with value: 0.06036107241415604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.0604\n",
      "Best parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}\n",
      "Validation - RMSE: 0.5744, MAE: 0.1071, RMSLE: 0.1575\n",
      "✓ Successfully tuned model for BOOKS\n",
      "\n",
      "============================================================\n",
      "Progress: 6/33 - Training model for family: BREAD/BAKERY\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 11:22:53,380] A new study created in memory with name: no-name-e8af4379-bb40-4378-affe-cb3a40d4ac50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family BREAD/BAKERY data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for BREAD/BAKERY ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 11:23:01,422] Trial 0 finished with value: 0.9043408537556621 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.9043408537556621.\n",
      "[I 2025-05-31 11:23:12,790] Trial 1 finished with value: 0.8903560120982338 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.8903560120982338.\n",
      "[I 2025-05-31 11:23:24,583] Trial 2 finished with value: 0.8999579102164247 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 1 with value: 0.8903560120982338.\n",
      "[I 2025-05-31 11:23:30,345] Trial 3 finished with value: 1.0166421485807524 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.8903560120982338.\n",
      "[I 2025-05-31 11:23:40,345] Trial 4 finished with value: 0.814336619913278 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.814336619913278.\n",
      "[I 2025-05-31 11:23:50,629] Trial 5 finished with value: 0.9912398291822989 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.814336619913278.\n",
      "[I 2025-05-31 11:23:56,234] Trial 6 finished with value: 0.8080411129709453 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 6 with value: 0.8080411129709453.\n",
      "[I 2025-05-31 11:24:02,601] Trial 7 finished with value: 0.843135876262409 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 6 with value: 0.8080411129709453.\n",
      "[I 2025-05-31 11:24:20,080] Trial 8 finished with value: 0.8637799460490995 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 6 with value: 0.8080411129709453.\n",
      "[I 2025-05-31 11:24:28,023] Trial 9 finished with value: 0.9843986922514859 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 6 with value: 0.8080411129709453.\n",
      "[I 2025-05-31 11:24:34,282] Trial 10 finished with value: 0.8324203053003293 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 6 with value: 0.8080411129709453.\n",
      "[I 2025-05-31 11:24:47,093] Trial 11 finished with value: 0.7929135307683147 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:25:00,425] Trial 12 finished with value: 0.7929135307683147 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:25:13,174] Trial 13 finished with value: 0.7929135307683147 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:25:23,785] Trial 14 finished with value: 0.8217111176588601 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:25:34,416] Trial 15 finished with value: 0.7929135307683147 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:25:44,534] Trial 16 finished with value: 0.7929135307683147 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:25:54,817] Trial 17 finished with value: 0.7929135307683147 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:26:07,446] Trial 18 finished with value: 0.8099469903111806 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:26:17,785] Trial 19 finished with value: 0.7929135307683147 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:26:29,253] Trial 20 finished with value: 0.7929135307683147 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:26:40,986] Trial 21 finished with value: 0.7929135307683147 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:26:52,091] Trial 22 finished with value: 0.7929135307683147 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:27:02,086] Trial 23 finished with value: 0.7929135307683147 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:27:18,003] Trial 24 finished with value: 0.7929135307683147 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:27:29,706] Trial 25 finished with value: 0.7929135307683147 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:27:38,215] Trial 26 finished with value: 0.8291191673839077 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:27:50,687] Trial 27 finished with value: 0.7929135307683147 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:28:02,018] Trial 28 finished with value: 0.7929135307683147 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:28:09,914] Trial 29 finished with value: 0.8414343687893296 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:28:20,623] Trial 30 finished with value: 0.7929135307683147 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:28:42,540] Trial 31 finished with value: 0.7929135307683147 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:28:53,442] Trial 32 finished with value: 0.7929135307683147 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:29:07,622] Trial 33 finished with value: 0.7929135307683147 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:29:20,094] Trial 34 finished with value: 0.8903560120982338 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:29:34,053] Trial 35 finished with value: 0.7929135307683147 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:29:42,637] Trial 36 finished with value: 0.9073376441284946 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:29:50,504] Trial 37 finished with value: 0.8218174517808006 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:30:04,678] Trial 38 finished with value: 0.8637799460490995 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:30:10,825] Trial 39 finished with value: 0.8490842321668343 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:30:21,723] Trial 40 finished with value: 0.8293040193687394 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:30:30,074] Trial 41 finished with value: 0.7929135307683147 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:30:38,330] Trial 42 finished with value: 0.7929135307683147 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:30:47,187] Trial 43 finished with value: 0.7929135307683147 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:30:52,623] Trial 44 finished with value: 0.8374141911613187 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:31:07,650] Trial 45 finished with value: 0.8561657973297283 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:31:20,926] Trial 46 finished with value: 0.8217111176588601 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:31:31,389] Trial 47 finished with value: 0.814336619913278 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:31:38,038] Trial 48 finished with value: 0.8374141911613187 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n",
      "[I 2025-05-31 11:31:52,083] Trial 49 finished with value: 0.8605545151707702 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.7929135307683147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.7929\n",
      "Best parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}\n",
      "Validation - RMSE: 130.9187, MAE: 89.8859, RMSLE: 0.2868\n",
      "✓ Successfully tuned model for BREAD/BAKERY\n",
      "\n",
      "============================================================\n",
      "Progress: 7/33 - Training model for family: CELEBRATION\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 11:32:00,713] A new study created in memory with name: no-name-4ed32838-021a-40bb-8ef5-554a3fe9dbc1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family CELEBRATION data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for CELEBRATION ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 11:32:06,826] Trial 0 finished with value: 0.4632833954705949 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4632833954705949.\n",
      "[I 2025-05-31 11:32:12,631] Trial 1 finished with value: 0.46297474024588636 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.46297474024588636.\n",
      "[I 2025-05-31 11:32:23,899] Trial 2 finished with value: 0.46071436066291777 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 2 with value: 0.46071436066291777.\n",
      "[I 2025-05-31 11:32:27,492] Trial 3 finished with value: 0.47417918794848896 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 2 with value: 0.46071436066291777.\n",
      "[I 2025-05-31 11:32:37,499] Trial 4 finished with value: 0.458995398706276 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.458995398706276.\n",
      "[I 2025-05-31 11:32:43,504] Trial 5 finished with value: 0.4638772053565114 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.458995398706276.\n",
      "[I 2025-05-31 11:32:49,380] Trial 6 finished with value: 0.46203977364395393 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.458995398706276.\n",
      "[I 2025-05-31 11:32:53,416] Trial 7 finished with value: 0.459526969246889 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.458995398706276.\n",
      "[I 2025-05-31 11:33:01,306] Trial 8 finished with value: 0.45365814986473385 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:33:05,440] Trial 9 finished with value: 0.4651650702438952 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:33:13,190] Trial 10 finished with value: 0.4628577341222835 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:33:20,439] Trial 11 finished with value: 0.458995398706276 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:33:27,797] Trial 12 finished with value: 0.458995398706276 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:33:35,078] Trial 13 finished with value: 0.458995398706276 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:33:46,706] Trial 14 finished with value: 0.45494232057731837 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:33:58,116] Trial 15 finished with value: 0.45494232057731837 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:34:15,088] Trial 16 finished with value: 0.45494232057731837 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:34:27,028] Trial 17 finished with value: 0.45494232057731837 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:34:34,822] Trial 18 finished with value: 0.4584350985843111 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:34:44,905] Trial 19 finished with value: 0.45494232057731837 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:34:55,094] Trial 20 finished with value: 0.45494232057731837 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:35:02,812] Trial 21 finished with value: 0.45494232057731837 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:35:11,761] Trial 22 finished with value: 0.45494232057731837 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:35:19,838] Trial 23 finished with value: 0.45494232057731837 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:35:27,509] Trial 24 finished with value: 0.45494232057731837 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:35:35,224] Trial 25 finished with value: 0.45494232057731837 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:35:38,341] Trial 26 finished with value: 0.4749689114373088 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:35:48,648] Trial 27 finished with value: 0.45494232057731837 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:35:57,205] Trial 28 finished with value: 0.45365814986473385 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:36:02,356] Trial 29 finished with value: 0.4632833954705949 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:36:10,075] Trial 30 finished with value: 0.45365814986473385 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:36:17,866] Trial 31 finished with value: 0.45365814986473385 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:36:25,617] Trial 32 finished with value: 0.45365814986473385 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:36:33,229] Trial 33 finished with value: 0.45365814986473385 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:36:38,336] Trial 34 finished with value: 0.46297474024588636 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:36:46,057] Trial 35 finished with value: 0.45365814986473385 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:36:52,183] Trial 36 finished with value: 0.4608806760344253 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:36:56,512] Trial 37 finished with value: 0.4634358740996067 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:37:02,543] Trial 38 finished with value: 0.45553697202172677 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:37:05,545] Trial 39 finished with value: 0.47436470638641853 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:37:14,269] Trial 40 finished with value: 0.4600987746028502 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:37:25,009] Trial 41 finished with value: 0.45365814986473385 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:37:34,557] Trial 42 finished with value: 0.45365814986473385 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:37:42,565] Trial 43 finished with value: 0.45365814986473385 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:37:51,437] Trial 44 finished with value: 0.45365814986473385 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:37:55,942] Trial 45 finished with value: 0.4554531402043844 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:38:04,770] Trial 46 finished with value: 0.45365814986473385 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:38:14,127] Trial 47 finished with value: 0.45365814986473385 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:38:24,447] Trial 48 finished with value: 0.4599334824909765 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n",
      "[I 2025-05-31 11:38:29,958] Trial 49 finished with value: 0.4629981889437296 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.45365814986473385.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.4537\n",
      "Best parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}\n",
      "Validation - RMSE: 12.4434, MAE: 4.6371, RMSLE: 0.3678\n",
      "✓ Successfully tuned model for CELEBRATION\n",
      "\n",
      "============================================================\n",
      "Progress: 8/33 - Training model for family: CLEANING\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 11:38:35,602] A new study created in memory with name: no-name-d5450a07-379a-4963-bccf-b1a1b022f477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family CLEANING data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for CLEANING ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 11:38:46,180] Trial 0 finished with value: 1.1401153203061531 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 1.1401153203061531.\n",
      "[I 2025-05-31 11:38:56,018] Trial 1 finished with value: 1.1461459872060669 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 1.1401153203061531.\n",
      "[I 2025-05-31 11:39:06,736] Trial 2 finished with value: 1.1428520472948398 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 0 with value: 1.1401153203061531.\n",
      "[I 2025-05-31 11:39:11,876] Trial 3 finished with value: 1.2512029153854332 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 1.1401153203061531.\n",
      "[I 2025-05-31 11:39:21,851] Trial 4 finished with value: 1.0913511353882033 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 1.0913511353882033.\n",
      "[I 2025-05-31 11:39:28,342] Trial 5 finished with value: 1.2681953482791088 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 1.0913511353882033.\n",
      "[I 2025-05-31 11:39:37,598] Trial 6 finished with value: 1.1107193070049528 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 1.0913511353882033.\n",
      "[I 2025-05-31 11:39:42,422] Trial 7 finished with value: 1.101660484392948 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 1.0913511353882033.\n",
      "[I 2025-05-31 11:39:57,243] Trial 8 finished with value: 1.1257338829390975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 1.0913511353882033.\n",
      "[I 2025-05-31 11:40:07,718] Trial 9 finished with value: 1.2586361549724792 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 1.0913511353882033.\n",
      "[I 2025-05-31 11:40:18,692] Trial 10 finished with value: 1.0924426241815066 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 4 with value: 1.0913511353882033.\n",
      "[I 2025-05-31 11:40:32,355] Trial 11 finished with value: 1.0924426241815066 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 4 with value: 1.0913511353882033.\n",
      "[I 2025-05-31 11:40:42,295] Trial 12 finished with value: 1.0924426241815066 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 4 with value: 1.0913511353882033.\n",
      "[I 2025-05-31 11:40:51,618] Trial 13 finished with value: 1.0924426241815066 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 4 with value: 1.0913511353882033.\n",
      "[I 2025-05-31 11:41:02,143] Trial 14 finished with value: 1.0959142219335727 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 1.0913511353882033.\n",
      "[I 2025-05-31 11:41:17,129] Trial 15 finished with value: 1.0924426241815066 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 4 with value: 1.0913511353882033.\n",
      "[I 2025-05-31 11:41:31,381] Trial 16 finished with value: 1.0911433108007447 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:41:51,823] Trial 17 finished with value: 1.0913511353882033 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:42:04,615] Trial 18 finished with value: 1.091857993411433 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:42:19,810] Trial 19 finished with value: 1.0911433108007447 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:42:31,996] Trial 20 finished with value: 1.0911433108007447 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:42:44,434] Trial 21 finished with value: 1.0911433108007447 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:43:02,272] Trial 22 finished with value: 1.0911433108007447 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:43:20,400] Trial 23 finished with value: 1.0911433108007447 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:43:33,048] Trial 24 finished with value: 1.0911433108007447 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:43:44,200] Trial 25 finished with value: 1.0911433108007447 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:43:48,310] Trial 26 finished with value: 1.1056444204490694 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:43:58,067] Trial 27 finished with value: 1.0911433108007447 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:44:07,690] Trial 28 finished with value: 1.0911433108007447 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:44:14,715] Trial 29 finished with value: 1.1003456287028244 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:44:25,844] Trial 30 finished with value: 1.0911433108007447 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:44:40,768] Trial 31 finished with value: 1.0911433108007447 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:44:51,435] Trial 32 finished with value: 1.0911433108007447 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:45:01,725] Trial 33 finished with value: 1.0911433108007447 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:45:12,922] Trial 34 finished with value: 1.149478094117788 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:45:22,484] Trial 35 finished with value: 1.0911433108007447 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:45:30,812] Trial 36 finished with value: 1.1435629880647455 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:45:36,132] Trial 37 finished with value: 1.1187139106678419 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:45:47,542] Trial 38 finished with value: 1.1235117400965853 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:45:51,449] Trial 39 finished with value: 1.1116698353695151 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:46:05,011] Trial 40 finished with value: 1.0911433108007447 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:46:16,819] Trial 41 finished with value: 1.0911433108007447 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:46:28,258] Trial 42 finished with value: 1.0911433108007447 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:46:39,551] Trial 43 finished with value: 1.0911433108007447 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:46:56,146] Trial 44 finished with value: 1.0911433108007447 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:47:03,138] Trial 45 finished with value: 1.2681953482791088 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:47:14,337] Trial 46 finished with value: 1.1139552015502385 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:47:26,594] Trial 47 finished with value: 1.0911433108007447 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:47:39,483] Trial 48 finished with value: 1.0959142219335727 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n",
      "[I 2025-05-31 11:47:55,911] Trial 49 finished with value: 1.1235117400965853 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 1.0911433108007447.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 1.0911\n",
      "Best parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}\n",
      "Validation - RMSE: 293.9887, MAE: 202.5995, RMSLE: 0.3143\n",
      "✓ Successfully tuned model for CLEANING\n",
      "\n",
      "============================================================\n",
      "Progress: 9/33 - Training model for family: DAIRY\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 11:48:01,881] A new study created in memory with name: no-name-3eb01502-3535-4254-a642-62adceca5b9f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family DAIRY data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for DAIRY ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 11:48:11,789] Trial 0 finished with value: 0.7352638297216543 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.7352638297216543.\n",
      "[I 2025-05-31 11:48:19,338] Trial 1 finished with value: 0.7808706297389821 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.7352638297216543.\n",
      "[I 2025-05-31 11:48:27,825] Trial 2 finished with value: 0.780298978408679 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.7352638297216543.\n",
      "[I 2025-05-31 11:48:32,308] Trial 3 finished with value: 0.8864641824465456 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.7352638297216543.\n",
      "[I 2025-05-31 11:48:41,762] Trial 4 finished with value: 0.6208839262716723 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.6208839262716723.\n",
      "[I 2025-05-31 11:48:47,766] Trial 5 finished with value: 0.7856107919137093 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.6208839262716723.\n",
      "[I 2025-05-31 11:48:52,959] Trial 6 finished with value: 0.53371883964806 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 6 with value: 0.53371883964806.\n",
      "[I 2025-05-31 11:48:57,346] Trial 7 finished with value: 0.8442989439399429 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 6 with value: 0.53371883964806.\n",
      "[I 2025-05-31 11:49:16,628] Trial 8 finished with value: 0.7011962649411871 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 6 with value: 0.53371883964806.\n",
      "[I 2025-05-31 11:49:25,161] Trial 9 finished with value: 0.8342734621318156 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 6 with value: 0.53371883964806.\n",
      "[I 2025-05-31 11:49:30,863] Trial 10 finished with value: 0.803055803899774 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 6 with value: 0.53371883964806.\n",
      "[I 2025-05-31 11:49:41,846] Trial 11 finished with value: 0.5142083545991296 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:49:56,861] Trial 12 finished with value: 0.5142083545991296 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:50:08,893] Trial 13 finished with value: 0.5142083545991296 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:50:19,534] Trial 14 finished with value: 0.8415488387704372 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:50:31,054] Trial 15 finished with value: 0.5142083545991296 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:50:42,700] Trial 16 finished with value: 0.5142083545991296 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:50:53,088] Trial 17 finished with value: 0.5142083545991296 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:51:03,760] Trial 18 finished with value: 0.8692255519875403 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:51:14,002] Trial 19 finished with value: 0.5142083545991296 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:51:25,172] Trial 20 finished with value: 0.5142083545991296 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:51:38,865] Trial 21 finished with value: 0.5142083545991296 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:51:52,684] Trial 22 finished with value: 0.5142083545991296 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:52:05,995] Trial 23 finished with value: 0.5142083545991296 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:52:17,285] Trial 24 finished with value: 0.5142083545991296 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:52:30,084] Trial 25 finished with value: 0.5142083545991296 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:52:39,999] Trial 26 finished with value: 0.8291825724648526 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:52:52,393] Trial 27 finished with value: 0.5142083545991296 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:53:05,874] Trial 28 finished with value: 0.5142083545991296 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:53:13,582] Trial 29 finished with value: 0.8305049234818712 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:53:22,255] Trial 30 finished with value: 0.5142083545991296 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:53:31,928] Trial 31 finished with value: 0.5142083545991296 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:53:47,594] Trial 32 finished with value: 0.5142083545991296 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:53:59,363] Trial 33 finished with value: 0.5142083545991296 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:54:10,801] Trial 34 finished with value: 0.7808706297389821 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:54:20,521] Trial 35 finished with value: 0.5142083545991296 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:54:29,540] Trial 36 finished with value: 0.7476248297273719 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:54:36,529] Trial 37 finished with value: 0.5937172532987753 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:54:50,293] Trial 38 finished with value: 0.7011962649411871 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:54:54,990] Trial 39 finished with value: 0.7546764163541865 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:55:06,165] Trial 40 finished with value: 0.6147979455557552 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:55:16,892] Trial 41 finished with value: 0.5142083545991296 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:55:28,426] Trial 42 finished with value: 0.5142083545991296 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:55:41,390] Trial 43 finished with value: 0.5142083545991296 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:55:48,205] Trial 44 finished with value: 0.6689873278964752 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:56:01,875] Trial 45 finished with value: 0.7227877565938088 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:56:16,868] Trial 46 finished with value: 0.8415488387704372 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:56:29,965] Trial 47 finished with value: 0.6208839262716723 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:56:36,120] Trial 48 finished with value: 0.6689873278964752 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n",
      "[I 2025-05-31 11:56:48,785] Trial 49 finished with value: 0.6946951837910121 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.5142083545991296.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.5142\n",
      "Best parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}\n",
      "Validation - RMSE: 247.3630, MAE: 169.5704, RMSLE: 0.2597\n",
      "✓ Successfully tuned model for DAIRY\n",
      "\n",
      "============================================================\n",
      "Progress: 10/33 - Training model for family: DELI\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 11:56:53,677] A new study created in memory with name: no-name-4f4569f3-56d5-42dc-9e88-6fca7e9d4088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family DELI data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for DELI ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 11:57:02,711] Trial 0 finished with value: 0.822479476947715 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.822479476947715.\n",
      "[I 2025-05-31 11:57:10,678] Trial 1 finished with value: 0.83202064625807 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.822479476947715.\n",
      "[I 2025-05-31 11:57:19,495] Trial 2 finished with value: 0.8261553599947246 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.822479476947715.\n",
      "[I 2025-05-31 11:57:26,832] Trial 3 finished with value: 0.9064429583984093 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.822479476947715.\n",
      "[I 2025-05-31 11:57:40,756] Trial 4 finished with value: 0.7910618628012499 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7910618628012499.\n",
      "[I 2025-05-31 11:57:48,054] Trial 5 finished with value: 0.8854209329198063 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7910618628012499.\n",
      "[I 2025-05-31 11:57:53,885] Trial 6 finished with value: 0.8259122623519874 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7910618628012499.\n",
      "[I 2025-05-31 11:57:58,439] Trial 7 finished with value: 0.8338192471075843 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.7910618628012499.\n",
      "[I 2025-05-31 11:58:11,414] Trial 8 finished with value: 0.8161329057991741 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7910618628012499.\n",
      "[I 2025-05-31 11:58:22,396] Trial 9 finished with value: 0.8939032116350082 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.7910618628012499.\n",
      "[I 2025-05-31 11:58:37,817] Trial 10 finished with value: 0.8153437919973707 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 4 with value: 0.7910618628012499.\n",
      "[I 2025-05-31 11:58:49,252] Trial 11 finished with value: 0.8153437919973707 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 4 with value: 0.7910618628012499.\n",
      "[I 2025-05-31 11:59:00,701] Trial 12 finished with value: 0.8153437919973707 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 4 with value: 0.7910618628012499.\n",
      "[I 2025-05-31 11:59:11,771] Trial 13 finished with value: 0.8153437919973707 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 4 with value: 0.7910618628012499.\n",
      "[I 2025-05-31 11:59:20,705] Trial 14 finished with value: 0.8064697964366107 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7910618628012499.\n",
      "[I 2025-05-31 11:59:31,399] Trial 15 finished with value: 0.8064697964366107 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7910618628012499.\n",
      "[I 2025-05-31 11:59:40,506] Trial 16 finished with value: 0.7910618628012499 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7910618628012499.\n",
      "[I 2025-05-31 11:59:55,073] Trial 17 finished with value: 0.7910618628012499 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7910618628012499.\n",
      "[I 2025-05-31 12:00:05,425] Trial 18 finished with value: 0.7874742409589818 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:00:14,462] Trial 19 finished with value: 0.7874742409589818 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:00:23,302] Trial 20 finished with value: 0.7874742409589818 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:00:38,413] Trial 21 finished with value: 0.7874742409589818 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:00:48,775] Trial 22 finished with value: 0.7874742409589818 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:00:58,210] Trial 23 finished with value: 0.7874742409589818 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:01:07,941] Trial 24 finished with value: 0.7874742409589818 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:01:17,526] Trial 25 finished with value: 0.7874742409589818 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:01:21,639] Trial 26 finished with value: 0.8259491181683883 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:01:31,267] Trial 27 finished with value: 0.7874742409589818 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:01:45,068] Trial 28 finished with value: 0.7874742409589818 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:01:53,913] Trial 29 finished with value: 0.8208921809158313 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:02:07,234] Trial 30 finished with value: 0.7874742409589818 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:02:17,282] Trial 31 finished with value: 0.7874742409589818 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:02:27,278] Trial 32 finished with value: 0.7874742409589818 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:02:37,057] Trial 33 finished with value: 0.7874742409589818 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:02:45,995] Trial 34 finished with value: 0.822479476947715 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:02:56,208] Trial 35 finished with value: 0.7874742409589818 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:03:05,066] Trial 36 finished with value: 0.822479476947715 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:03:10,636] Trial 37 finished with value: 0.7978577013817211 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:03:22,600] Trial 38 finished with value: 0.8109268865815341 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:03:26,833] Trial 39 finished with value: 0.8259491181683883 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:03:37,850] Trial 40 finished with value: 0.7874742409589818 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:03:48,509] Trial 41 finished with value: 0.7874742409589818 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:04:01,744] Trial 42 finished with value: 0.7874742409589818 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:04:13,305] Trial 43 finished with value: 0.7874742409589818 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:04:24,378] Trial 44 finished with value: 0.7927346498866545 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:04:31,584] Trial 45 finished with value: 0.8743370560287178 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:04:42,403] Trial 46 finished with value: 0.7927346498866545 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:04:53,715] Trial 47 finished with value: 0.7874742409589818 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:05:04,471] Trial 48 finished with value: 0.807866541221219 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n",
      "[I 2025-05-31 12:05:20,498] Trial 49 finished with value: 0.8107154833753597 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.7874742409589818.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.7875\n",
      "Best parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}\n",
      "Validation - RMSE: 89.4610, MAE: 58.6638, RMSLE: 0.2812\n",
      "✓ Successfully tuned model for DELI\n",
      "\n",
      "============================================================\n",
      "Progress: 11/33 - Training model for family: EGGS\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 12:05:26,360] A new study created in memory with name: no-name-9ec32118-7e4c-43b6-84a1-a81e8455c4e6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family EGGS data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for EGGS ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 12:05:36,188] Trial 0 finished with value: 0.8651452484646249 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.8651452484646249.\n",
      "[I 2025-05-31 12:05:46,825] Trial 1 finished with value: 0.8479890183500972 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.8479890183500972.\n",
      "[I 2025-05-31 12:05:58,088] Trial 2 finished with value: 0.8656105831572187 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 1 with value: 0.8479890183500972.\n",
      "[I 2025-05-31 12:06:04,238] Trial 3 finished with value: 0.9051708494896248 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.8479890183500972.\n",
      "[I 2025-05-31 12:06:15,215] Trial 4 finished with value: 0.7536810451303787 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7536810451303787.\n",
      "[I 2025-05-31 12:06:24,986] Trial 5 finished with value: 0.8742234045754188 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7536810451303787.\n",
      "[I 2025-05-31 12:06:31,247] Trial 6 finished with value: 0.771623069144475 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7536810451303787.\n",
      "[I 2025-05-31 12:06:36,445] Trial 7 finished with value: 0.7750507937391017 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.7536810451303787.\n",
      "[I 2025-05-31 12:06:58,691] Trial 8 finished with value: 0.8040601185225662 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7536810451303787.\n",
      "[I 2025-05-31 12:07:08,467] Trial 9 finished with value: 0.8865833640851916 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.7536810451303787.\n",
      "[I 2025-05-31 12:07:26,821] Trial 10 finished with value: 0.7747573180807841 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 4 with value: 0.7536810451303787.\n",
      "[I 2025-05-31 12:07:33,916] Trial 11 finished with value: 0.771623069144475 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7536810451303787.\n",
      "[I 2025-05-31 12:07:40,759] Trial 12 finished with value: 0.771623069144475 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7536810451303787.\n",
      "[I 2025-05-31 12:07:54,109] Trial 13 finished with value: 0.7666939542172023 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7536810451303787.\n",
      "[I 2025-05-31 12:08:07,130] Trial 14 finished with value: 0.7852581774254414 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7536810451303787.\n",
      "[I 2025-05-31 12:08:22,211] Trial 15 finished with value: 0.7536810451303787 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7536810451303787.\n",
      "[I 2025-05-31 12:08:43,351] Trial 16 finished with value: 0.7536810451303787 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7536810451303787.\n",
      "[I 2025-05-31 12:08:59,053] Trial 17 finished with value: 0.7536810451303787 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7536810451303787.\n",
      "[I 2025-05-31 12:09:09,861] Trial 18 finished with value: 0.7961794745057932 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.7536810451303787.\n",
      "[I 2025-05-31 12:09:22,010] Trial 19 finished with value: 0.7536810451303787 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7536810451303787.\n",
      "[I 2025-05-31 12:09:32,026] Trial 20 finished with value: 0.7536810451303787 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7536810451303787.\n",
      "[I 2025-05-31 12:09:42,027] Trial 21 finished with value: 0.7536810451303787 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7536810451303787.\n",
      "[I 2025-05-31 12:09:52,173] Trial 22 finished with value: 0.7536810451303787 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7536810451303787.\n",
      "[I 2025-05-31 12:10:02,212] Trial 23 finished with value: 0.7536810451303787 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7536810451303787.\n",
      "[I 2025-05-31 12:10:12,592] Trial 24 finished with value: 0.7536810451303787 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7536810451303787.\n",
      "[I 2025-05-31 12:10:22,568] Trial 25 finished with value: 0.7536810451303787 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7536810451303787.\n",
      "[I 2025-05-31 12:10:30,271] Trial 26 finished with value: 0.7448550610513074 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 0.7448550610513074.\n",
      "[I 2025-05-31 12:10:38,597] Trial 27 finished with value: 0.7448550610513074 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 0.7448550610513074.\n",
      "[I 2025-05-31 12:10:47,771] Trial 28 finished with value: 0.7448550610513074 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 0.7448550610513074.\n",
      "[I 2025-05-31 12:10:55,588] Trial 29 finished with value: 0.7448550610513074 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 0.7448550610513074.\n",
      "[I 2025-05-31 12:11:03,627] Trial 30 finished with value: 0.7448550610513074 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 0.7448550610513074.\n",
      "[I 2025-05-31 12:11:11,920] Trial 31 finished with value: 0.7448550610513074 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 0.7448550610513074.\n",
      "[I 2025-05-31 12:11:19,531] Trial 32 finished with value: 0.7448550610513074 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 0.7448550610513074.\n",
      "[I 2025-05-31 12:11:27,245] Trial 33 finished with value: 0.7448550610513074 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 0.7448550610513074.\n",
      "[I 2025-05-31 12:11:36,318] Trial 34 finished with value: 0.8626797481070844 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 0.7448550610513074.\n",
      "[I 2025-05-31 12:11:46,116] Trial 35 finished with value: 0.7448550610513074 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 0.7448550610513074.\n",
      "[I 2025-05-31 12:11:56,149] Trial 36 finished with value: 0.8626797481070844 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 0.7448550610513074.\n",
      "[I 2025-05-31 12:12:03,906] Trial 37 finished with value: 0.7448550610513074 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 0.7448550610513074.\n",
      "[I 2025-05-31 12:12:12,892] Trial 38 finished with value: 0.8706093885834191 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 0.7448550610513074.\n",
      "[I 2025-05-31 12:12:17,231] Trial 39 finished with value: 0.7750507937391017 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 0.7448550610513074.\n",
      "[I 2025-05-31 12:12:24,870] Trial 40 finished with value: 0.7448550610513074 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 0.7448550610513074.\n",
      "[I 2025-05-31 12:12:32,506] Trial 41 finished with value: 0.7448550610513074 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 0.7448550610513074.\n",
      "[I 2025-05-31 12:12:40,073] Trial 42 finished with value: 0.7448550610513074 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 0.7448550610513074.\n",
      "[I 2025-05-31 12:12:47,824] Trial 43 finished with value: 0.7448550610513074 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 0.7448550610513074.\n",
      "[I 2025-05-31 12:12:52,270] Trial 44 finished with value: 0.7750507937391017 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 0.7448550610513074.\n",
      "[I 2025-05-31 12:13:01,443] Trial 45 finished with value: 0.8626797481070844 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 0.7448550610513074.\n",
      "[I 2025-05-31 12:13:09,490] Trial 46 finished with value: 0.797706107158306 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 0.7448550610513074.\n",
      "[I 2025-05-31 12:13:15,538] Trial 47 finished with value: 0.7750507937391017 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 0.7448550610513074.\n",
      "[I 2025-05-31 12:13:28,460] Trial 48 finished with value: 0.7448550610513074 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 0.7448550610513074.\n",
      "[I 2025-05-31 12:13:38,073] Trial 49 finished with value: 0.8706093885834191 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 0.7448550610513074.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.7449\n",
      "Best parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation - RMSE: 48.1156, MAE: 32.3554, RMSLE: 0.2704\n",
      "✓ Successfully tuned model for EGGS\n",
      "\n",
      "============================================================\n",
      "Progress: 12/33 - Training model for family: FROZEN FOODS\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 12:13:43,328] A new study created in memory with name: no-name-3ef48b5c-d663-4eeb-9eb8-817574f69671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family FROZEN FOODS data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for FROZEN FOODS ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 12:13:51,152] Trial 0 finished with value: 0.6268866781091673 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.6268866781091673.\n",
      "[I 2025-05-31 12:13:58,811] Trial 1 finished with value: 0.5258521691513678 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.5258521691513678.\n",
      "[I 2025-05-31 12:14:06,881] Trial 2 finished with value: 0.5414148554775661 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 1 with value: 0.5258521691513678.\n",
      "[I 2025-05-31 12:14:11,113] Trial 3 finished with value: 0.7690929015830094 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.5258521691513678.\n",
      "[I 2025-05-31 12:14:21,893] Trial 4 finished with value: 0.6079886608345918 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.5258521691513678.\n",
      "[I 2025-05-31 12:14:27,861] Trial 5 finished with value: 0.7260633481261135 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.5258521691513678.\n",
      "[I 2025-05-31 12:14:36,118] Trial 6 finished with value: 0.5320645978787423 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.5258521691513678.\n",
      "[I 2025-05-31 12:14:42,806] Trial 7 finished with value: 0.5105006551201116 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:14:53,762] Trial 8 finished with value: 0.5821690719180072 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:14:59,782] Trial 9 finished with value: 0.7233843834581816 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:15:03,972] Trial 10 finished with value: 0.5105006551201116 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:15:08,179] Trial 11 finished with value: 0.5105006551201116 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:15:12,153] Trial 12 finished with value: 0.5105006551201116 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:15:15,953] Trial 13 finished with value: 0.5105006551201116 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:15:19,901] Trial 14 finished with value: 0.5105006551201116 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:15:23,966] Trial 15 finished with value: 0.5105006551201116 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:15:27,882] Trial 16 finished with value: 0.5105006551201116 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:15:31,745] Trial 17 finished with value: 0.5105006551201116 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:15:35,468] Trial 18 finished with value: 0.5105596565568467 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:15:39,429] Trial 19 finished with value: 0.5105006551201116 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:15:43,428] Trial 20 finished with value: 0.5105006551201116 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:15:47,251] Trial 21 finished with value: 0.5105006551201116 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:15:51,343] Trial 22 finished with value: 0.5105006551201116 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:15:55,232] Trial 23 finished with value: 0.5105006551201116 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:15:59,243] Trial 24 finished with value: 0.5105006551201116 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:16:03,013] Trial 25 finished with value: 0.5105006551201116 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:16:11,853] Trial 26 finished with value: 0.5861942487516717 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:16:15,793] Trial 27 finished with value: 0.5105006551201116 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:16:19,800] Trial 28 finished with value: 0.5105006551201116 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:16:26,798] Trial 29 finished with value: 0.5323299607803237 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:16:31,087] Trial 30 finished with value: 0.5105006551201116 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:16:36,593] Trial 31 finished with value: 0.5105006551201116 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:16:42,455] Trial 32 finished with value: 0.5105006551201116 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:16:46,460] Trial 33 finished with value: 0.5105006551201116 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:16:53,681] Trial 34 finished with value: 0.5449531169359346 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:16:57,662] Trial 35 finished with value: 0.5269027831742291 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5105006551201116.\n",
      "[I 2025-05-31 12:17:05,083] Trial 36 finished with value: 0.48439520365200806 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 36 with value: 0.48439520365200806.\n",
      "[I 2025-05-31 12:17:16,136] Trial 37 finished with value: 0.5821690719180072 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 36 with value: 0.48439520365200806.\n",
      "[I 2025-05-31 12:17:24,838] Trial 38 finished with value: 0.5449531169359346 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 36 with value: 0.48439520365200806.\n",
      "[I 2025-05-31 12:17:35,685] Trial 39 finished with value: 0.5821690719180072 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 36 with value: 0.48439520365200806.\n",
      "[I 2025-05-31 12:17:43,100] Trial 40 finished with value: 0.48439520365200806 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 36 with value: 0.48439520365200806.\n",
      "[I 2025-05-31 12:17:50,328] Trial 41 finished with value: 0.48439520365200806 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 36 with value: 0.48439520365200806.\n",
      "[I 2025-05-31 12:17:57,642] Trial 42 finished with value: 0.48439520365200806 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 36 with value: 0.48439520365200806.\n",
      "[I 2025-05-31 12:18:05,102] Trial 43 finished with value: 0.48439520365200806 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 36 with value: 0.48439520365200806.\n",
      "[I 2025-05-31 12:18:14,607] Trial 44 finished with value: 0.48439520365200806 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 36 with value: 0.48439520365200806.\n",
      "[I 2025-05-31 12:18:22,196] Trial 45 finished with value: 0.4950842166014409 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 36 with value: 0.48439520365200806.\n",
      "[I 2025-05-31 12:18:32,785] Trial 46 finished with value: 0.5379059675279035 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 36 with value: 0.48439520365200806.\n",
      "[I 2025-05-31 12:18:39,981] Trial 47 finished with value: 0.48439520365200806 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 36 with value: 0.48439520365200806.\n",
      "[I 2025-05-31 12:18:47,997] Trial 48 finished with value: 0.48439520365200806 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 36 with value: 0.48439520365200806.\n",
      "[I 2025-05-31 12:18:55,053] Trial 49 finished with value: 0.5449531169359346 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 36 with value: 0.48439520365200806.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.4844\n",
      "Best parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}\n",
      "Validation - RMSE: 239.8899, MAE: 62.8021, RMSLE: 0.6354\n",
      "✓ Successfully tuned model for FROZEN FOODS\n",
      "\n",
      "============================================================\n",
      "Progress: 13/33 - Training model for family: GROCERY I\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 12:18:58,952] A new study created in memory with name: no-name-33e8f18d-d557-4dce-8c99-094cdfbb181f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family GROCERY I data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for GROCERY I ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 12:19:09,618] Trial 0 finished with value: 1.22741844420364 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 1.22741844420364.\n",
      "[I 2025-05-31 12:19:18,281] Trial 1 finished with value: 1.2112293578455322 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 1.2112293578455322.\n",
      "[I 2025-05-31 12:19:27,550] Trial 2 finished with value: 1.2292325907905008 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 1 with value: 1.2112293578455322.\n",
      "[I 2025-05-31 12:19:32,265] Trial 3 finished with value: 1.4794755891833722 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 1.2112293578455322.\n",
      "[I 2025-05-31 12:19:43,248] Trial 4 finished with value: 1.2875760164080439 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 1.2112293578455322.\n",
      "[I 2025-05-31 12:19:50,895] Trial 5 finished with value: 1.434857083490132 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 1.2112293578455322.\n",
      "[I 2025-05-31 12:19:56,167] Trial 6 finished with value: 1.2286540240347887 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 1.2112293578455322.\n",
      "[I 2025-05-31 12:20:00,592] Trial 7 finished with value: 1.2426176140226022 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 1 with value: 1.2112293578455322.\n",
      "[I 2025-05-31 12:20:13,313] Trial 8 finished with value: 1.1820295661289286 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 1.1820295661289286.\n",
      "[I 2025-05-31 12:20:21,270] Trial 9 finished with value: 1.4344633494499017 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 8 with value: 1.1820295661289286.\n",
      "[I 2025-05-31 12:20:32,308] Trial 10 finished with value: 1.3800396275964928 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 8 with value: 1.1820295661289286.\n",
      "[I 2025-05-31 12:20:40,872] Trial 11 finished with value: 1.2112293578455322 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 1.1820295661289286.\n",
      "[I 2025-05-31 12:20:49,643] Trial 12 finished with value: 1.2112293578455322 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 1.1820295661289286.\n",
      "[I 2025-05-31 12:21:00,774] Trial 13 finished with value: 1.1585888579249077 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 13 with value: 1.1585888579249077.\n",
      "[I 2025-05-31 12:21:13,008] Trial 14 finished with value: 1.1830153683474631 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 13 with value: 1.1585888579249077.\n",
      "[I 2025-05-31 12:21:26,756] Trial 15 finished with value: 1.1820295661289286 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 13 with value: 1.1585888579249077.\n",
      "[I 2025-05-31 12:21:38,238] Trial 16 finished with value: 1.1585888579249077 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 13 with value: 1.1585888579249077.\n",
      "[I 2025-05-31 12:21:49,427] Trial 17 finished with value: 1.1585888579249077 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 13 with value: 1.1585888579249077.\n",
      "[I 2025-05-31 12:21:59,249] Trial 18 finished with value: 1.3128629127900844 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 13 with value: 1.1585888579249077.\n",
      "[I 2025-05-31 12:22:10,500] Trial 19 finished with value: 1.1585888579249077 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 13 with value: 1.1585888579249077.\n",
      "[I 2025-05-31 12:22:24,550] Trial 20 finished with value: 1.1585888579249077 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 13 with value: 1.1585888579249077.\n",
      "[I 2025-05-31 12:22:37,487] Trial 21 finished with value: 1.1585888579249077 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 13 with value: 1.1585888579249077.\n",
      "[I 2025-05-31 12:22:48,577] Trial 22 finished with value: 1.1585888579249077 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 13 with value: 1.1585888579249077.\n",
      "[I 2025-05-31 12:23:11,743] Trial 23 finished with value: 1.1585888579249077 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 13 with value: 1.1585888579249077.\n",
      "[I 2025-05-31 12:23:26,616] Trial 24 finished with value: 1.1585888579249077 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 13 with value: 1.1585888579249077.\n",
      "[I 2025-05-31 12:23:37,723] Trial 25 finished with value: 1.1585888579249077 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 13 with value: 1.1585888579249077.\n",
      "[I 2025-05-31 12:23:43,292] Trial 26 finished with value: 1.1565753613124246 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 1.1565753613124246.\n",
      "[I 2025-05-31 12:23:49,263] Trial 27 finished with value: 1.1565753613124246 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 1.1565753613124246.\n",
      "[I 2025-05-31 12:23:54,889] Trial 28 finished with value: 1.1565753613124246 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 1.1565753613124246.\n",
      "[I 2025-05-31 12:24:00,884] Trial 29 finished with value: 1.1565753613124246 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 1.1565753613124246.\n",
      "[I 2025-05-31 12:24:06,702] Trial 30 finished with value: 1.1565753613124246 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 1.1565753613124246.\n",
      "[I 2025-05-31 12:24:12,517] Trial 31 finished with value: 1.1565753613124246 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 1.1565753613124246.\n",
      "[I 2025-05-31 12:24:18,187] Trial 32 finished with value: 1.1565753613124246 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 1.1565753613124246.\n",
      "[I 2025-05-31 12:24:23,822] Trial 33 finished with value: 1.1565753613124246 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 1.1565753613124246.\n",
      "[I 2025-05-31 12:24:28,113] Trial 34 finished with value: 1.1968281941515289 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 1.1565753613124246.\n",
      "[I 2025-05-31 12:24:33,639] Trial 35 finished with value: 1.1565753613124246 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 1.1565753613124246.\n",
      "[I 2025-05-31 12:24:38,001] Trial 36 finished with value: 1.1968281941515289 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 1.1565753613124246.\n",
      "[I 2025-05-31 12:24:43,866] Trial 37 finished with value: 1.1565753613124246 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 1.1565753613124246.\n",
      "[I 2025-05-31 12:24:49,417] Trial 38 finished with value: 1.1565753613124246 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 1.1565753613124246.\n",
      "[I 2025-05-31 12:24:53,772] Trial 39 finished with value: 1.1968281941515289 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 1.1565753613124246.\n",
      "[I 2025-05-31 12:24:59,978] Trial 40 finished with value: 1.2634833406850268 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 1.1565753613124246.\n",
      "[I 2025-05-31 12:25:06,068] Trial 41 finished with value: 1.1565753613124246 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 1.1565753613124246.\n",
      "[I 2025-05-31 12:25:11,716] Trial 42 finished with value: 1.1565753613124246 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 1.1565753613124246.\n",
      "[I 2025-05-31 12:25:17,348] Trial 43 finished with value: 1.1565753613124246 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 1.1565753613124246.\n",
      "[I 2025-05-31 12:25:23,121] Trial 44 finished with value: 1.1565753613124246 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 1.1565753613124246.\n",
      "[I 2025-05-31 12:25:28,894] Trial 45 finished with value: 1.1565753613124246 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 1.1565753613124246.\n",
      "[I 2025-05-31 12:25:35,101] Trial 46 finished with value: 1.2634833406850268 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 1.1565753613124246.\n",
      "[I 2025-05-31 12:25:39,580] Trial 47 finished with value: 1.1968281941515289 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 1.1565753613124246.\n",
      "[I 2025-05-31 12:25:45,364] Trial 48 finished with value: 1.1565753613124246 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 1.1565753613124246.\n",
      "[I 2025-05-31 12:25:51,583] Trial 49 finished with value: 1.2634833406850268 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 26 with value: 1.1565753613124246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 1.1566\n",
      "Best parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation - RMSE: 1536.6755, MAE: 854.5172, RMSLE: 0.3849\n",
      "✓ Successfully tuned model for GROCERY I\n",
      "\n",
      "============================================================\n",
      "Progress: 14/33 - Training model for family: GROCERY II\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 12:25:55,098] A new study created in memory with name: no-name-d968ec54-ebee-4426-902b-8480164c2139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family GROCERY II data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for GROCERY II ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 12:26:02,348] Trial 0 finished with value: 0.6007349238698908 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.6007349238698908.\n",
      "[I 2025-05-31 12:26:10,368] Trial 1 finished with value: 0.5988966460055912 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.5988966460055912.\n",
      "[I 2025-05-31 12:26:18,238] Trial 2 finished with value: 0.6110331005139021 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 1 with value: 0.5988966460055912.\n",
      "[I 2025-05-31 12:26:22,787] Trial 3 finished with value: 0.6263115562651517 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.5988966460055912.\n",
      "[I 2025-05-31 12:26:31,434] Trial 4 finished with value: 0.5634701703510492 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:26:36,916] Trial 5 finished with value: 0.6240125793929883 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:26:40,873] Trial 6 finished with value: 0.6003668291691163 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:26:44,563] Trial 7 finished with value: 0.5877666751399309 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:26:54,002] Trial 8 finished with value: 0.5744153630314197 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:26:59,767] Trial 9 finished with value: 0.6282214228446291 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:27:08,927] Trial 10 finished with value: 0.5706835187720541 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:27:17,885] Trial 11 finished with value: 0.5706835187720541 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:27:26,889] Trial 12 finished with value: 0.5706835187720541 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:27:35,848] Trial 13 finished with value: 0.5706835187720541 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:27:44,497] Trial 14 finished with value: 0.5696248262242231 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:27:53,068] Trial 15 finished with value: 0.5696248262242231 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:28:01,830] Trial 16 finished with value: 0.5634701703510492 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:28:10,688] Trial 17 finished with value: 0.5634701703510492 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:28:17,558] Trial 18 finished with value: 0.5676945004538111 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:28:26,108] Trial 19 finished with value: 0.5634701703510492 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:28:34,697] Trial 20 finished with value: 0.5634701703510492 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:28:44,628] Trial 21 finished with value: 0.5634701703510492 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:28:54,067] Trial 22 finished with value: 0.5634701703510492 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:29:03,031] Trial 23 finished with value: 0.5634701703510492 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:29:11,920] Trial 24 finished with value: 0.5634701703510492 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:29:20,605] Trial 25 finished with value: 0.5634701703510492 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:29:24,044] Trial 26 finished with value: 0.5744554235926226 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:29:33,180] Trial 27 finished with value: 0.5634701703510492 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:29:42,019] Trial 28 finished with value: 0.5634701703510492 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:29:47,768] Trial 29 finished with value: 0.5709719099067011 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:29:56,506] Trial 30 finished with value: 0.5634701703510492 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:30:05,371] Trial 31 finished with value: 0.5634701703510492 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:30:14,151] Trial 32 finished with value: 0.5634701703510492 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:30:22,845] Trial 33 finished with value: 0.5634701703510492 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:30:29,796] Trial 34 finished with value: 0.5988966460055912 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:30:39,246] Trial 35 finished with value: 0.5744153630314197 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:30:42,787] Trial 36 finished with value: 0.5712673551049084 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:30:49,549] Trial 37 finished with value: 0.5676945004538111 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:30:54,731] Trial 38 finished with value: 0.6240125793929883 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:31:01,149] Trial 39 finished with value: 0.5680676036516297 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:31:06,652] Trial 40 finished with value: 0.6240311499175875 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:31:15,480] Trial 41 finished with value: 0.5634701703510492 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:31:24,198] Trial 42 finished with value: 0.5634701703510492 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:31:32,752] Trial 43 finished with value: 0.5634701703510492 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:31:41,304] Trial 44 finished with value: 0.5634701703510492 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:31:50,631] Trial 45 finished with value: 0.57563462080629 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:31:59,239] Trial 46 finished with value: 0.5634701703510492 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:32:07,804] Trial 47 finished with value: 0.5696248262242231 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:32:18,717] Trial 48 finished with value: 0.580744219664015 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n",
      "[I 2025-05-31 12:32:24,185] Trial 49 finished with value: 0.5663380141616078 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5634701703510492.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.5635\n",
      "Best parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}\n",
      "Validation - RMSE: 21.1978, MAE: 11.9117, RMSLE: 0.4213\n",
      "✓ Successfully tuned model for GROCERY II\n",
      "\n",
      "============================================================\n",
      "Progress: 15/33 - Training model for family: HARDWARE\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 12:32:30,502] A new study created in memory with name: no-name-da931246-520a-4ae1-bffa-16618c4eb39a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family HARDWARE data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for HARDWARE ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 12:32:37,315] Trial 0 finished with value: 0.4552974654165323 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:32:43,473] Trial 1 finished with value: 0.4553962385637562 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:32:49,596] Trial 2 finished with value: 0.45549939213460594 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:32:53,020] Trial 3 finished with value: 0.4556219861107813 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:32:59,876] Trial 4 finished with value: 0.46908078744166554 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:33:07,008] Trial 5 finished with value: 0.455527304950692 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:33:10,973] Trial 6 finished with value: 0.4607411976453129 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:33:14,349] Trial 7 finished with value: 0.4588787777912657 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:33:21,941] Trial 8 finished with value: 0.4558506824573092 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:33:26,619] Trial 9 finished with value: 0.45564653020238527 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:33:31,951] Trial 10 finished with value: 0.46379750044592694 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:33:37,729] Trial 11 finished with value: 0.4552974654165323 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:33:43,672] Trial 12 finished with value: 0.4552974654165323 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:33:49,787] Trial 13 finished with value: 0.4552974654165323 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:33:55,776] Trial 14 finished with value: 0.4553182747084384 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:34:01,600] Trial 15 finished with value: 0.4552974654165323 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:34:07,390] Trial 16 finished with value: 0.4552974654165323 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:34:15,113] Trial 17 finished with value: 0.4552974654165323 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:34:20,536] Trial 18 finished with value: 0.46379750044592694 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:34:27,075] Trial 19 finished with value: 0.4552974654165323 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:34:32,976] Trial 20 finished with value: 0.4552974654165323 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:34:38,931] Trial 21 finished with value: 0.4552974654165323 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:34:44,981] Trial 22 finished with value: 0.4552974654165323 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:34:50,910] Trial 23 finished with value: 0.4552974654165323 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:34:56,842] Trial 24 finished with value: 0.4552974654165323 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:35:02,753] Trial 25 finished with value: 0.4552974654165323 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:35:07,130] Trial 26 finished with value: 0.45970180630510193 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:35:13,084] Trial 27 finished with value: 0.4552974654165323 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:35:19,004] Trial 28 finished with value: 0.4552974654165323 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:35:24,816] Trial 29 finished with value: 0.4553962385637562 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:35:31,203] Trial 30 finished with value: 0.4552974654165323 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:35:37,058] Trial 31 finished with value: 0.4552974654165323 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:35:42,941] Trial 32 finished with value: 0.4552974654165323 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:35:49,137] Trial 33 finished with value: 0.4552974654165323 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:35:54,959] Trial 34 finished with value: 0.4554637760328466 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:36:01,965] Trial 35 finished with value: 0.4553962385637562 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.4552974654165323.\n",
      "[I 2025-05-31 12:36:06,810] Trial 36 finished with value: 0.45526201097361185 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 36 with value: 0.45526201097361185.\n",
      "[I 2025-05-31 12:36:10,812] Trial 37 finished with value: 0.4608768456726398 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 36 with value: 0.45526201097361185.\n",
      "[I 2025-05-31 12:36:15,544] Trial 38 finished with value: 0.45526201097361185 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 36 with value: 0.45526201097361185.\n",
      "[I 2025-05-31 12:36:19,607] Trial 39 finished with value: 0.4608994312849826 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 36 with value: 0.45526201097361185.\n",
      "[I 2025-05-31 12:36:24,105] Trial 40 finished with value: 0.45526201097361185 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 36 with value: 0.45526201097361185.\n",
      "[I 2025-05-31 12:36:28,487] Trial 41 finished with value: 0.45526201097361185 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 36 with value: 0.45526201097361185.\n",
      "[I 2025-05-31 12:36:33,046] Trial 42 finished with value: 0.45526201097361185 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 36 with value: 0.45526201097361185.\n",
      "[I 2025-05-31 12:36:37,520] Trial 43 finished with value: 0.45526201097361185 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 36 with value: 0.45526201097361185.\n",
      "[I 2025-05-31 12:36:42,052] Trial 44 finished with value: 0.45526201097361185 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 36 with value: 0.45526201097361185.\n",
      "[I 2025-05-31 12:36:46,642] Trial 45 finished with value: 0.45526201097361185 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 36 with value: 0.45526201097361185.\n",
      "[I 2025-05-31 12:36:51,166] Trial 46 finished with value: 0.45526201097361185 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 36 with value: 0.45526201097361185.\n",
      "[I 2025-05-31 12:36:55,906] Trial 47 finished with value: 0.4554850487616595 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 36 with value: 0.45526201097361185.\n",
      "[I 2025-05-31 12:37:00,314] Trial 48 finished with value: 0.45527029584760886 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 36 with value: 0.45526201097361185.\n",
      "[I 2025-05-31 12:37:04,287] Trial 49 finished with value: 0.4619269815355303 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 36 with value: 0.45526201097361185.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.4553\n",
      "Best parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation - RMSE: 1.4322, MAE: 0.9549, RMSLE: 0.4998\n",
      "✓ Successfully tuned model for HARDWARE\n",
      "\n",
      "============================================================\n",
      "Progress: 16/33 - Training model for family: HOME AND KITCHEN I\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 12:37:07,532] A new study created in memory with name: no-name-6865f6f3-387b-4bdf-bb4b-43958b09f7d6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family HOME AND KITCHEN I data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for HOME AND KITCHEN I ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 12:37:13,940] Trial 0 finished with value: 0.6036239011873938 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.6036239011873938.\n",
      "[I 2025-05-31 12:37:20,402] Trial 1 finished with value: 0.6066413835436512 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.6036239011873938.\n",
      "[I 2025-05-31 12:37:27,689] Trial 2 finished with value: 0.6076251726187837 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.6036239011873938.\n",
      "[I 2025-05-31 12:37:31,282] Trial 3 finished with value: 0.6022287864594541 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 3 with value: 0.6022287864594541.\n",
      "[I 2025-05-31 12:37:41,844] Trial 4 finished with value: 0.5813157016301145 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5813157016301145.\n",
      "[I 2025-05-31 12:37:47,308] Trial 5 finished with value: 0.5697670438149366 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.5697670438149366.\n",
      "[I 2025-05-31 12:37:50,836] Trial 6 finished with value: 0.5843806946815612 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.5697670438149366.\n",
      "[I 2025-05-31 12:37:54,499] Trial 7 finished with value: 0.607428928627377 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 5 with value: 0.5697670438149366.\n",
      "[I 2025-05-31 12:38:04,119] Trial 8 finished with value: 0.5631764665826221 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.5631764665826221.\n",
      "[I 2025-05-31 12:38:09,390] Trial 9 finished with value: 0.5716295184573565 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 8 with value: 0.5631764665826221.\n",
      "[I 2025-05-31 12:38:19,070] Trial 10 finished with value: 0.5653602201845284 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 8 with value: 0.5631764665826221.\n",
      "[I 2025-05-31 12:38:28,444] Trial 11 finished with value: 0.5653602201845284 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 8 with value: 0.5631764665826221.\n",
      "[I 2025-05-31 12:38:38,277] Trial 12 finished with value: 0.5653602201845284 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 8 with value: 0.5631764665826221.\n",
      "[I 2025-05-31 12:38:48,442] Trial 13 finished with value: 0.5653602201845284 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 8 with value: 0.5631764665826221.\n",
      "[I 2025-05-31 12:38:58,462] Trial 14 finished with value: 0.5628146632526705 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 14 with value: 0.5628146632526705.\n",
      "[I 2025-05-31 12:39:07,987] Trial 15 finished with value: 0.5628146632526705 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 14 with value: 0.5628146632526705.\n",
      "[I 2025-05-31 12:39:18,041] Trial 16 finished with value: 0.5628146632526705 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 14 with value: 0.5628146632526705.\n",
      "[I 2025-05-31 12:39:27,711] Trial 17 finished with value: 0.5628146632526705 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 14 with value: 0.5628146632526705.\n",
      "[I 2025-05-31 12:39:34,997] Trial 18 finished with value: 0.561314650875286 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.561314650875286.\n",
      "[I 2025-05-31 12:39:42,564] Trial 19 finished with value: 0.561314650875286 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.561314650875286.\n",
      "[I 2025-05-31 12:39:50,188] Trial 20 finished with value: 0.561314650875286 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.561314650875286.\n",
      "[I 2025-05-31 12:39:57,569] Trial 21 finished with value: 0.561314650875286 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.561314650875286.\n",
      "[I 2025-05-31 12:40:04,981] Trial 22 finished with value: 0.561314650875286 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.561314650875286.\n",
      "[I 2025-05-31 12:40:12,348] Trial 23 finished with value: 0.561314650875286 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.561314650875286.\n",
      "[I 2025-05-31 12:40:19,771] Trial 24 finished with value: 0.561314650875286 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.561314650875286.\n",
      "[I 2025-05-31 12:40:27,106] Trial 25 finished with value: 0.561314650875286 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.561314650875286.\n",
      "[I 2025-05-31 12:40:30,751] Trial 26 finished with value: 0.5921843370660297 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.561314650875286.\n",
      "[I 2025-05-31 12:40:38,004] Trial 27 finished with value: 0.561314650875286 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.561314650875286.\n",
      "[I 2025-05-31 12:40:45,321] Trial 28 finished with value: 0.561314650875286 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.561314650875286.\n",
      "[I 2025-05-31 12:40:51,561] Trial 29 finished with value: 0.5937062595037771 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.561314650875286.\n",
      "[I 2025-05-31 12:40:58,879] Trial 30 finished with value: 0.561314650875286 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.561314650875286.\n",
      "[I 2025-05-31 12:41:06,125] Trial 31 finished with value: 0.561314650875286 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.561314650875286.\n",
      "[I 2025-05-31 12:41:13,488] Trial 32 finished with value: 0.561314650875286 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.561314650875286.\n",
      "[I 2025-05-31 12:41:20,919] Trial 33 finished with value: 0.561314650875286 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.561314650875286.\n",
      "[I 2025-05-31 12:41:27,080] Trial 34 finished with value: 0.5937062595037771 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.561314650875286.\n",
      "[I 2025-05-31 12:41:34,365] Trial 35 finished with value: 0.5658370915866168 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.561314650875286.\n",
      "[I 2025-05-31 12:41:40,821] Trial 36 finished with value: 0.5937062595037771 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.561314650875286.\n",
      "[I 2025-05-31 12:41:45,322] Trial 37 finished with value: 0.5543083680282558 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.5543083680282558.\n",
      "[I 2025-05-31 12:41:49,811] Trial 38 finished with value: 0.5543083680282558 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.5543083680282558.\n",
      "[I 2025-05-31 12:41:53,509] Trial 39 finished with value: 0.6045560321706375 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.5543083680282558.\n",
      "[I 2025-05-31 12:41:56,782] Trial 40 finished with value: 0.5769156091995188 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.5543083680282558.\n",
      "[I 2025-05-31 12:42:01,274] Trial 41 finished with value: 0.5543083680282558 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.5543083680282558.\n",
      "[I 2025-05-31 12:42:05,747] Trial 42 finished with value: 0.5543083680282558 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.5543083680282558.\n",
      "[I 2025-05-31 12:42:10,254] Trial 43 finished with value: 0.5543083680282558 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.5543083680282558.\n",
      "[I 2025-05-31 12:42:15,028] Trial 44 finished with value: 0.5541679710816051 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 44 with value: 0.5541679710816051.\n",
      "[I 2025-05-31 12:42:19,826] Trial 45 finished with value: 0.5541679710816051 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 44 with value: 0.5541679710816051.\n",
      "[I 2025-05-31 12:42:23,532] Trial 46 finished with value: 0.5889242901193682 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 44 with value: 0.5541679710816051.\n",
      "[I 2025-05-31 12:42:28,316] Trial 47 finished with value: 0.5541679710816051 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 44 with value: 0.5541679710816051.\n",
      "[I 2025-05-31 12:42:33,122] Trial 48 finished with value: 0.5541679710816051 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 44 with value: 0.5541679710816051.\n",
      "[I 2025-05-31 12:42:36,763] Trial 49 finished with value: 0.5889242901193682 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 44 with value: 0.5541679710816051.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.5542\n",
      "Best parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation - RMSE: 40.2124, MAE: 14.5579, RMSLE: 0.5554\n",
      "✓ Successfully tuned model for HOME AND KITCHEN I\n",
      "\n",
      "============================================================\n",
      "Progress: 17/33 - Training model for family: HOME AND KITCHEN II\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 12:42:40,144] A new study created in memory with name: no-name-6ad44a1c-1d5f-489e-bffc-f9d2fa63b3d2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family HOME AND KITCHEN II data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for HOME AND KITCHEN II ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 12:42:46,643] Trial 0 finished with value: 0.5060469306186303 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.5060469306186303.\n",
      "[I 2025-05-31 12:42:52,900] Trial 1 finished with value: 0.5370034587600563 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.5060469306186303.\n",
      "[I 2025-05-31 12:42:59,884] Trial 2 finished with value: 0.49127762598870756 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 2 with value: 0.49127762598870756.\n",
      "[I 2025-05-31 12:43:03,359] Trial 3 finished with value: 0.49743843172909924 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 2 with value: 0.49127762598870756.\n",
      "[I 2025-05-31 12:43:11,794] Trial 4 finished with value: 0.510921896458313 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 2 with value: 0.49127762598870756.\n",
      "[I 2025-05-31 12:43:16,943] Trial 5 finished with value: 0.4894791957577563 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.4894791957577563.\n",
      "[I 2025-05-31 12:43:20,800] Trial 6 finished with value: 0.5081770684222497 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.4894791957577563.\n",
      "[I 2025-05-31 12:43:24,362] Trial 7 finished with value: 0.5359275409398795 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 5 with value: 0.4894791957577563.\n",
      "[I 2025-05-31 12:43:33,682] Trial 8 finished with value: 0.5122133359366942 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.4894791957577563.\n",
      "[I 2025-05-31 12:43:38,753] Trial 9 finished with value: 0.4692344171566987 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:43:43,510] Trial 10 finished with value: 0.5367470851621253 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:43:48,700] Trial 11 finished with value: 0.4692344171566987 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:43:54,225] Trial 12 finished with value: 0.4692344171566987 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:43:59,222] Trial 13 finished with value: 0.4692344171566987 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:44:04,254] Trial 14 finished with value: 0.4692344171566987 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:44:09,735] Trial 15 finished with value: 0.4692344171566987 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:44:14,725] Trial 16 finished with value: 0.4692344171566987 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:44:19,749] Trial 17 finished with value: 0.4692344171566987 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:44:23,906] Trial 18 finished with value: 0.5281259260770107 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:44:28,996] Trial 19 finished with value: 0.4692344171566987 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:44:33,982] Trial 20 finished with value: 0.4692344171566987 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:44:39,318] Trial 21 finished with value: 0.4692344171566987 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:44:44,417] Trial 22 finished with value: 0.4692344171566987 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:44:49,515] Trial 23 finished with value: 0.4692344171566987 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:44:54,614] Trial 24 finished with value: 0.4692344171566987 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:44:59,680] Trial 25 finished with value: 0.4692344171566987 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:45:06,108] Trial 26 finished with value: 0.5915279408735248 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:45:11,026] Trial 27 finished with value: 0.4692344171566987 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:45:16,049] Trial 28 finished with value: 0.4692344171566987 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:45:22,562] Trial 29 finished with value: 0.5434379662235186 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:45:27,641] Trial 30 finished with value: 0.4692344171566987 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:45:32,694] Trial 31 finished with value: 0.4692344171566987 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:45:37,601] Trial 32 finished with value: 0.4692344171566987 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:45:42,766] Trial 33 finished with value: 0.4692344171566987 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:45:49,531] Trial 34 finished with value: 0.5554880020138263 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:45:54,708] Trial 35 finished with value: 0.4839020977454072 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:46:01,140] Trial 36 finished with value: 0.5005537134149826 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:46:06,001] Trial 37 finished with value: 0.5005379729642304 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 9 with value: 0.4692344171566987.\n",
      "[I 2025-05-31 12:46:10,616] Trial 38 finished with value: 0.4463949531359881 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 38 with value: 0.4463949531359881.\n",
      "[I 2025-05-31 12:46:14,146] Trial 39 finished with value: 0.49743843172909924 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 38 with value: 0.4463949531359881.\n",
      "[I 2025-05-31 12:46:21,030] Trial 40 finished with value: 0.5774557673254241 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 38 with value: 0.4463949531359881.\n",
      "[I 2025-05-31 12:46:25,587] Trial 41 finished with value: 0.4463949531359881 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 38 with value: 0.4463949531359881.\n",
      "[I 2025-05-31 12:46:30,079] Trial 42 finished with value: 0.4463949531359881 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 38 with value: 0.4463949531359881.\n",
      "[I 2025-05-31 12:46:34,509] Trial 43 finished with value: 0.4463949531359881 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 38 with value: 0.4463949531359881.\n",
      "[I 2025-05-31 12:46:38,799] Trial 44 finished with value: 0.4463949531359881 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 38 with value: 0.4463949531359881.\n",
      "[I 2025-05-31 12:46:43,558] Trial 45 finished with value: 0.4387281649769332 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 45 with value: 0.4387281649769332.\n",
      "[I 2025-05-31 12:46:48,006] Trial 46 finished with value: 0.4387281649769332 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 45 with value: 0.4387281649769332.\n",
      "[I 2025-05-31 12:46:52,565] Trial 47 finished with value: 0.4387281649769332 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 45 with value: 0.4387281649769332.\n",
      "[I 2025-05-31 12:46:57,119] Trial 48 finished with value: 0.4387281649769332 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 45 with value: 0.4387281649769332.\n",
      "[I 2025-05-31 12:47:00,885] Trial 49 finished with value: 0.5081770684222497 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 45 with value: 0.4387281649769332.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.4387\n",
      "Best parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}\n",
      "Validation - RMSE: 31.7055, MAE: 11.1285, RMSLE: 0.4525\n",
      "✓ Successfully tuned model for HOME AND KITCHEN II\n",
      "\n",
      "============================================================\n",
      "Progress: 18/33 - Training model for family: HOME APPLIANCES\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 12:47:03,534] A new study created in memory with name: no-name-7b6e8218-828a-4ed9-b8d7-53c47ec7a425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family HOME APPLIANCES data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for HOME APPLIANCES ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 12:47:09,173] Trial 0 finished with value: 0.27527800876603753 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.27527800876603753.\n",
      "[I 2025-05-31 12:47:14,497] Trial 1 finished with value: 0.2754608323621401 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.27527800876603753.\n",
      "[I 2025-05-31 12:47:20,195] Trial 2 finished with value: 0.275270265307595 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 2 with value: 0.275270265307595.\n",
      "[I 2025-05-31 12:47:23,294] Trial 3 finished with value: 0.2752526336385573 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 3 with value: 0.2752526336385573.\n",
      "[I 2025-05-31 12:47:30,070] Trial 4 finished with value: 0.28639221994294756 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 3 with value: 0.2752526336385573.\n",
      "[I 2025-05-31 12:47:34,101] Trial 5 finished with value: 0.2754270890365765 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 3 with value: 0.2752526336385573.\n",
      "[I 2025-05-31 12:47:37,742] Trial 6 finished with value: 0.2804050363776392 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 3 with value: 0.2752526336385573.\n",
      "[I 2025-05-31 12:47:40,564] Trial 7 finished with value: 0.2781347794369993 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 3 with value: 0.2752526336385573.\n",
      "[I 2025-05-31 12:47:48,445] Trial 8 finished with value: 0.2762463685115574 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 3 with value: 0.2752526336385573.\n",
      "[I 2025-05-31 12:47:52,677] Trial 9 finished with value: 0.2753784073063415 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 3 with value: 0.2752526336385573.\n",
      "[I 2025-05-31 12:47:55,682] Trial 10 finished with value: 0.2789896245730921 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 3 with value: 0.2752526336385573.\n",
      "[I 2025-05-31 12:48:01,508] Trial 11 finished with value: 0.27546305775961594 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 3 with value: 0.2752526336385573.\n",
      "[I 2025-05-31 12:48:04,607] Trial 12 finished with value: 0.2751853417164618 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.2751853417164618.\n",
      "[I 2025-05-31 12:48:07,841] Trial 13 finished with value: 0.2751839009063479 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.2751839009063479.\n",
      "[I 2025-05-31 12:48:11,008] Trial 14 finished with value: 0.2751212627313428 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:48:14,067] Trial 15 finished with value: 0.2751212627313428 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:48:17,420] Trial 16 finished with value: 0.2751212627313428 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:48:20,494] Trial 17 finished with value: 0.2751212627313428 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:48:23,626] Trial 18 finished with value: 0.2778396066818793 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:48:26,917] Trial 19 finished with value: 0.2751212627313428 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:48:29,941] Trial 20 finished with value: 0.2751212627313428 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:48:33,089] Trial 21 finished with value: 0.2751212627313428 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:48:36,142] Trial 22 finished with value: 0.2751212627313428 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:48:39,276] Trial 23 finished with value: 0.2751212627313428 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:48:42,454] Trial 24 finished with value: 0.2751212627313428 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:48:45,703] Trial 25 finished with value: 0.2751212627313428 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:48:49,539] Trial 26 finished with value: 0.2795963074475528 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:48:53,009] Trial 27 finished with value: 0.2751212627313428 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:48:56,488] Trial 28 finished with value: 0.2751212627313428 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:49:02,757] Trial 29 finished with value: 0.27520690827433136 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:49:05,893] Trial 30 finished with value: 0.2751212627313428 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:49:09,337] Trial 31 finished with value: 0.2751212627313428 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:49:12,820] Trial 32 finished with value: 0.2751212627313428 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:49:16,627] Trial 33 finished with value: 0.2751212627313428 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:49:22,002] Trial 34 finished with value: 0.2752882932541057 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:49:25,283] Trial 35 finished with value: 0.2751212627313428 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:49:30,731] Trial 36 finished with value: 0.2752459558168527 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:49:34,447] Trial 37 finished with value: 0.2795963074475528 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:49:37,396] Trial 38 finished with value: 0.27516310954457973 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:49:41,738] Trial 39 finished with value: 0.2754632762415406 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:49:47,078] Trial 40 finished with value: 0.2818660007053965 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:49:50,179] Trial 41 finished with value: 0.2751212627313428 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:49:53,350] Trial 42 finished with value: 0.2751212627313428 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:49:56,815] Trial 43 finished with value: 0.2751212627313428 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:50:00,123] Trial 44 finished with value: 0.2751839009063479 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:50:03,159] Trial 45 finished with value: 0.2751953990274319 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:50:07,582] Trial 46 finished with value: 0.2753784073063415 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:50:10,965] Trial 47 finished with value: 0.27522498154199865 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:50:13,752] Trial 48 finished with value: 0.2778396066818793 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n",
      "[I 2025-05-31 12:50:19,148] Trial 49 finished with value: 0.2752882932541057 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 14 with value: 0.2751212627313428.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.2751\n",
      "Best parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation - RMSE: 0.9672, MAE: 0.6037, RMSLE: 0.3997\n",
      "✓ Successfully tuned model for HOME APPLIANCES\n",
      "\n",
      "============================================================\n",
      "Progress: 19/33 - Training model for family: HOME CARE\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 12:50:21,293] A new study created in memory with name: no-name-ebe7608b-241c-4e3e-98ef-7e9033a97000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family HOME CARE data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for HOME CARE ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 12:50:29,713] Trial 0 finished with value: 0.6652737702231624 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.6652737702231624.\n",
      "[I 2025-05-31 12:50:37,864] Trial 1 finished with value: 0.6769316450901245 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.6652737702231624.\n",
      "[I 2025-05-31 12:50:47,167] Trial 2 finished with value: 0.6312958457392748 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 2 with value: 0.6312958457392748.\n",
      "[I 2025-05-31 12:50:51,603] Trial 3 finished with value: 0.7759087620080812 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 2 with value: 0.6312958457392748.\n",
      "[I 2025-05-31 12:51:01,312] Trial 4 finished with value: 0.4866971724653371 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.4866971724653371.\n",
      "[I 2025-05-31 12:51:07,319] Trial 5 finished with value: 0.6682723236677627 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.4866971724653371.\n",
      "[I 2025-05-31 12:51:12,492] Trial 6 finished with value: 0.5738175722656206 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.4866971724653371.\n",
      "[I 2025-05-31 12:51:17,716] Trial 7 finished with value: 0.701189648405308 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.4866971724653371.\n",
      "[I 2025-05-31 12:51:29,104] Trial 8 finished with value: 0.5437747634771978 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.4866971724653371.\n",
      "[I 2025-05-31 12:51:36,043] Trial 9 finished with value: 0.6894932815737179 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.4866971724653371.\n",
      "[I 2025-05-31 12:51:46,505] Trial 10 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:51:56,765] Trial 11 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:52:07,219] Trial 12 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:52:17,315] Trial 13 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:52:27,553] Trial 14 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:52:37,747] Trial 15 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:52:48,223] Trial 16 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:52:58,407] Trial 17 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:53:08,008] Trial 18 finished with value: 0.5198044574939924 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:53:18,289] Trial 19 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:53:28,422] Trial 20 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:53:38,674] Trial 21 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:53:49,812] Trial 22 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:54:00,192] Trial 23 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:54:10,395] Trial 24 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:54:21,302] Trial 25 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:54:25,393] Trial 26 finished with value: 0.6132324561134374 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:54:35,632] Trial 27 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:54:46,350] Trial 28 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:54:53,851] Trial 29 finished with value: 0.6861236150706432 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:55:05,065] Trial 30 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:55:15,875] Trial 31 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:55:26,500] Trial 32 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:55:37,641] Trial 33 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:55:46,220] Trial 34 finished with value: 0.6963193100372753 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:55:57,166] Trial 35 finished with value: 0.5275667673607797 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:56:05,840] Trial 36 finished with value: 0.7090157465958838 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:56:11,945] Trial 37 finished with value: 0.518731117250166 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:56:23,230] Trial 38 finished with value: 0.4843525154692491 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:56:27,691] Trial 39 finished with value: 0.5414388588722437 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:56:38,739] Trial 40 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:56:49,787] Trial 41 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:57:00,784] Trial 42 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:57:11,863] Trial 43 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:57:22,691] Trial 44 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:57:29,147] Trial 45 finished with value: 0.6186999923412925 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:57:39,890] Trial 46 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:57:50,633] Trial 47 finished with value: 0.47313382512762975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:58:00,812] Trial 48 finished with value: 0.5204006092044479 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n",
      "[I 2025-05-31 12:58:12,266] Trial 49 finished with value: 0.5154283657322598 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 10 with value: 0.47313382512762975.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.4731\n",
      "Best parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}\n",
      "Validation - RMSE: 98.1831, MAE: 51.0300, RMSLE: 0.6360\n",
      "✓ Successfully tuned model for HOME CARE\n",
      "\n",
      "============================================================\n",
      "Progress: 20/33 - Training model for family: LADIESWEAR\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 12:58:17,417] A new study created in memory with name: no-name-ef4dc83b-9f98-40de-a928-3734900f535a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family LADIESWEAR data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for LADIESWEAR ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 12:58:24,041] Trial 0 finished with value: 0.3640195889581081 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.3640195889581081.\n",
      "[I 2025-05-31 12:58:30,363] Trial 1 finished with value: 0.3632699063097165 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.3632699063097165.\n",
      "[I 2025-05-31 12:58:37,093] Trial 2 finished with value: 0.36234859157102295 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 2 with value: 0.36234859157102295.\n",
      "[I 2025-05-31 12:58:40,503] Trial 3 finished with value: 0.3705846327840079 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 2 with value: 0.36234859157102295.\n",
      "[I 2025-05-31 12:58:48,848] Trial 4 finished with value: 0.33924767024630803 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.33924767024630803.\n",
      "[I 2025-05-31 12:58:53,447] Trial 5 finished with value: 0.362876032811696 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.33924767024630803.\n",
      "[I 2025-05-31 12:58:57,421] Trial 6 finished with value: 0.34833448839202746 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.33924767024630803.\n",
      "[I 2025-05-31 12:59:01,334] Trial 7 finished with value: 0.3506839155312745 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.33924767024630803.\n",
      "[I 2025-05-31 12:59:10,304] Trial 8 finished with value: 0.3513157815406715 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.33924767024630803.\n",
      "[I 2025-05-31 12:59:15,211] Trial 9 finished with value: 0.36563956574326956 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.33924767024630803.\n",
      "[I 2025-05-31 12:59:23,504] Trial 10 finished with value: 0.33874354943034196 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.33874354943034196.\n",
      "[I 2025-05-31 12:59:31,481] Trial 11 finished with value: 0.33874354943034196 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.33874354943034196.\n",
      "[I 2025-05-31 12:59:39,407] Trial 12 finished with value: 0.33874354943034196 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.33874354943034196.\n",
      "[I 2025-05-31 12:59:47,614] Trial 13 finished with value: 0.33874354943034196 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.33874354943034196.\n",
      "[I 2025-05-31 12:59:56,253] Trial 14 finished with value: 0.33874354943034196 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.33874354943034196.\n",
      "[I 2025-05-31 13:00:04,383] Trial 15 finished with value: 0.33874354943034196 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.33874354943034196.\n",
      "[I 2025-05-31 13:00:12,374] Trial 16 finished with value: 0.33874354943034196 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.33874354943034196.\n",
      "[I 2025-05-31 13:00:20,279] Trial 17 finished with value: 0.33874354943034196 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.33874354943034196.\n",
      "[I 2025-05-31 13:00:27,793] Trial 18 finished with value: 0.3418001628880136 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 10 with value: 0.33874354943034196.\n",
      "[I 2025-05-31 13:00:36,076] Trial 19 finished with value: 0.33874354943034196 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.33874354943034196.\n",
      "[I 2025-05-31 13:00:43,963] Trial 20 finished with value: 0.33874354943034196 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.33874354943034196.\n",
      "[I 2025-05-31 13:00:51,787] Trial 21 finished with value: 0.33874354943034196 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.33874354943034196.\n",
      "[I 2025-05-31 13:01:00,180] Trial 22 finished with value: 0.33874354943034196 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.33874354943034196.\n",
      "[I 2025-05-31 13:01:08,282] Trial 23 finished with value: 0.33874354943034196 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.33874354943034196.\n",
      "[I 2025-05-31 13:01:16,066] Trial 24 finished with value: 0.33874354943034196 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.33874354943034196.\n",
      "[I 2025-05-31 13:01:24,052] Trial 25 finished with value: 0.33874354943034196 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.33874354943034196.\n",
      "[I 2025-05-31 13:01:27,210] Trial 26 finished with value: 0.347055306482535 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 10 with value: 0.33874354943034196.\n",
      "[I 2025-05-31 13:01:35,132] Trial 27 finished with value: 0.33874354943034196 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.33874354943034196.\n",
      "[I 2025-05-31 13:01:43,371] Trial 28 finished with value: 0.33874354943034196 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.33874354943034196.\n",
      "[I 2025-05-31 13:01:49,111] Trial 29 finished with value: 0.34034381210409975 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 10 with value: 0.33874354943034196.\n",
      "[I 2025-05-31 13:01:56,974] Trial 30 finished with value: 0.33874354943034196 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.33874354943034196.\n",
      "[I 2025-05-31 13:02:04,940] Trial 31 finished with value: 0.33874354943034196 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.33874354943034196.\n",
      "[I 2025-05-31 13:02:13,013] Trial 32 finished with value: 0.33874354943034196 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.33874354943034196.\n",
      "[I 2025-05-31 13:02:20,852] Trial 33 finished with value: 0.33874354943034196 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.33874354943034196.\n",
      "[I 2025-05-31 13:02:26,842] Trial 34 finished with value: 0.3626749691976597 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 10 with value: 0.33874354943034196.\n",
      "[I 2025-05-31 13:02:34,839] Trial 35 finished with value: 0.3353438975625778 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 35 with value: 0.3353438975625778.\n",
      "[I 2025-05-31 13:02:41,171] Trial 36 finished with value: 0.3638902369361092 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 35 with value: 0.3353438975625778.\n",
      "[I 2025-05-31 13:02:45,704] Trial 37 finished with value: 0.34757930049904867 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 35 with value: 0.3353438975625778.\n",
      "[I 2025-05-31 13:02:54,136] Trial 38 finished with value: 0.36034745432817195 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 35 with value: 0.3353438975625778.\n",
      "[I 2025-05-31 13:02:57,349] Trial 39 finished with value: 0.3578194489958597 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 35 with value: 0.3353438975625778.\n",
      "[I 2025-05-31 13:03:05,389] Trial 40 finished with value: 0.3353438975625778 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 35 with value: 0.3353438975625778.\n",
      "[I 2025-05-31 13:03:13,445] Trial 41 finished with value: 0.3353438975625778 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 35 with value: 0.3353438975625778.\n",
      "[I 2025-05-31 13:03:21,342] Trial 42 finished with value: 0.3353438975625778 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 35 with value: 0.3353438975625778.\n",
      "[I 2025-05-31 13:03:29,357] Trial 43 finished with value: 0.3353438975625778 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 35 with value: 0.3353438975625778.\n",
      "[I 2025-05-31 13:03:37,462] Trial 44 finished with value: 0.3353438975625778 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 35 with value: 0.3353438975625778.\n",
      "[I 2025-05-31 13:03:42,005] Trial 45 finished with value: 0.362876032811696 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 35 with value: 0.3353438975625778.\n",
      "[I 2025-05-31 13:03:50,092] Trial 46 finished with value: 0.34917995373013716 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 35 with value: 0.3353438975625778.\n",
      "[I 2025-05-31 13:03:58,148] Trial 47 finished with value: 0.3353438975625778 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 35 with value: 0.3353438975625778.\n",
      "[I 2025-05-31 13:04:06,129] Trial 48 finished with value: 0.3353438975625778 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 35 with value: 0.3353438975625778.\n",
      "[I 2025-05-31 13:04:14,351] Trial 49 finished with value: 0.36034745432817195 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 35 with value: 0.3353438975625778.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.3353\n",
      "Best parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}\n",
      "Validation - RMSE: 5.9494, MAE: 3.2065, RMSLE: 0.4072\n",
      "✓ Successfully tuned model for LADIESWEAR\n",
      "\n",
      "============================================================\n",
      "Progress: 21/33 - Training model for family: LAWN AND GARDEN\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 13:04:18,510] A new study created in memory with name: no-name-ff36ec74-e016-4801-9211-b1df52ded223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family LAWN AND GARDEN data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for LAWN AND GARDEN ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 13:04:24,890] Trial 0 finished with value: 0.49008041070591 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.49008041070591.\n",
      "[I 2025-05-31 13:04:31,021] Trial 1 finished with value: 0.4918962242262926 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.49008041070591.\n",
      "[I 2025-05-31 13:04:37,928] Trial 2 finished with value: 0.4880317039699664 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 2 with value: 0.4880317039699664.\n",
      "[I 2025-05-31 13:04:41,569] Trial 3 finished with value: 0.48931231528429725 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 2 with value: 0.4880317039699664.\n",
      "[I 2025-05-31 13:04:49,512] Trial 4 finished with value: 0.4609739696962403 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.4609739696962403.\n",
      "[I 2025-05-31 13:04:54,090] Trial 5 finished with value: 0.47015492045030377 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.4609739696962403.\n",
      "[I 2025-05-31 13:04:57,972] Trial 6 finished with value: 0.4618477578976486 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.4609739696962403.\n",
      "[I 2025-05-31 13:05:01,181] Trial 7 finished with value: 0.4736491033989578 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.4609739696962403.\n",
      "[I 2025-05-31 13:05:10,150] Trial 8 finished with value: 0.47852540523145054 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.4609739696962403.\n",
      "[I 2025-05-31 13:05:15,278] Trial 9 finished with value: 0.4651362870242555 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.4609739696962403.\n",
      "[I 2025-05-31 13:05:23,740] Trial 10 finished with value: 0.46531557938670726 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 4 with value: 0.4609739696962403.\n",
      "[I 2025-05-31 13:05:27,442] Trial 11 finished with value: 0.4618477578976486 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.4609739696962403.\n",
      "[I 2025-05-31 13:05:31,212] Trial 12 finished with value: 0.4618477578976486 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.4609739696962403.\n",
      "[I 2025-05-31 13:05:38,081] Trial 13 finished with value: 0.45901705641333046 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 13 with value: 0.45901705641333046.\n",
      "[I 2025-05-31 13:05:44,837] Trial 14 finished with value: 0.45884206599833854 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 14 with value: 0.45884206599833854.\n",
      "[I 2025-05-31 13:05:51,731] Trial 15 finished with value: 0.45884206599833854 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 14 with value: 0.45884206599833854.\n",
      "[I 2025-05-31 13:05:59,187] Trial 16 finished with value: 0.45884206599833854 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 14 with value: 0.45884206599833854.\n",
      "[I 2025-05-31 13:06:06,118] Trial 17 finished with value: 0.45884206599833854 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 14 with value: 0.45884206599833854.\n",
      "[I 2025-05-31 13:06:13,299] Trial 18 finished with value: 0.44936625797921126 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:06:20,522] Trial 19 finished with value: 0.44936625797921126 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:06:27,803] Trial 20 finished with value: 0.44936625797921126 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:06:34,940] Trial 21 finished with value: 0.44936625797921126 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:06:42,246] Trial 22 finished with value: 0.44936625797921126 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:06:49,405] Trial 23 finished with value: 0.44936625797921126 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:06:56,643] Trial 24 finished with value: 0.44936625797921126 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:07:03,788] Trial 25 finished with value: 0.44936625797921126 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:07:09,874] Trial 26 finished with value: 0.47239002947859826 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:07:17,102] Trial 27 finished with value: 0.44936625797921126 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:07:24,444] Trial 28 finished with value: 0.44936625797921126 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:07:30,126] Trial 29 finished with value: 0.47239002947859826 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:07:37,299] Trial 30 finished with value: 0.44936625797921126 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:07:44,672] Trial 31 finished with value: 0.44936625797921126 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:07:52,032] Trial 32 finished with value: 0.44936625797921126 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:07:59,122] Trial 33 finished with value: 0.44936625797921126 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:08:05,531] Trial 34 finished with value: 0.48167158174715813 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:08:12,863] Trial 35 finished with value: 0.44936625797921126 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:08:19,242] Trial 36 finished with value: 0.48167158174715813 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:08:26,441] Trial 37 finished with value: 0.44936625797921126 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:08:35,499] Trial 38 finished with value: 0.46810674231818666 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:08:38,706] Trial 39 finished with value: 0.47303069217399685 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:08:47,085] Trial 40 finished with value: 0.46599390550304665 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:08:54,168] Trial 41 finished with value: 0.44936625797921126 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:09:01,816] Trial 42 finished with value: 0.44936625797921126 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:09:09,092] Trial 43 finished with value: 0.44936625797921126 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:09:14,160] Trial 44 finished with value: 0.46517865866722313 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:09:22,979] Trial 45 finished with value: 0.4768943086620148 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:09:30,909] Trial 46 finished with value: 0.46599390550304665 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:09:34,524] Trial 47 finished with value: 0.46517865866722313 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:09:41,497] Trial 48 finished with value: 0.44936625797921126 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n",
      "[I 2025-05-31 13:09:50,164] Trial 49 finished with value: 0.46810674231818666 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 18 with value: 0.44936625797921126.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.4494\n",
      "Best parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation - RMSE: 8.4211, MAE: 3.6689, RMSLE: 0.5005\n",
      "✓ Successfully tuned model for LAWN AND GARDEN\n",
      "\n",
      "============================================================\n",
      "Progress: 22/33 - Training model for family: LINGERIE\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 13:09:54,373] A new study created in memory with name: no-name-80b5e72a-e8c8-40fb-a3c7-483d0f3efd0c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family LINGERIE data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for LINGERIE ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 13:10:00,748] Trial 0 finished with value: 0.6173750807919167 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.6173750807919167.\n",
      "[I 2025-05-31 13:10:07,056] Trial 1 finished with value: 0.6153682903526322 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.6153682903526322.\n",
      "[I 2025-05-31 13:10:13,564] Trial 2 finished with value: 0.6136775777334769 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 2 with value: 0.6136775777334769.\n",
      "[I 2025-05-31 13:10:17,102] Trial 3 finished with value: 0.6325040360555786 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 2 with value: 0.6136775777334769.\n",
      "[I 2025-05-31 13:10:24,572] Trial 4 finished with value: 0.6055562853629255 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.6055562853629255.\n",
      "[I 2025-05-31 13:10:29,178] Trial 5 finished with value: 0.6214884606772784 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.6055562853629255.\n",
      "[I 2025-05-31 13:10:32,742] Trial 6 finished with value: 0.6149186916746349 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.6055562853629255.\n",
      "[I 2025-05-31 13:10:35,870] Trial 7 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:10:44,271] Trial 8 finished with value: 0.6172723141418022 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:10:48,850] Trial 9 finished with value: 0.6221082434524119 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:10:52,003] Trial 10 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:10:55,054] Trial 11 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:10:58,465] Trial 12 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:11:01,526] Trial 13 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:11:04,681] Trial 14 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:11:07,717] Trial 15 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:11:11,008] Trial 16 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:11:14,098] Trial 17 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:11:17,094] Trial 18 finished with value: 0.6044913754289046 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:11:20,161] Trial 19 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:11:23,304] Trial 20 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:11:26,383] Trial 21 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:11:29,674] Trial 22 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:11:32,735] Trial 23 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:11:35,751] Trial 24 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:11:39,058] Trial 25 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:11:46,086] Trial 26 finished with value: 0.6252803650525202 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:11:49,667] Trial 27 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:11:52,906] Trial 28 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:11:58,483] Trial 29 finished with value: 0.6024150296010603 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:12:01,631] Trial 30 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:12:04,683] Trial 31 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:12:07,885] Trial 32 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:12:11,188] Trial 33 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:12:17,330] Trial 34 finished with value: 0.617132678024257 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:12:20,466] Trial 35 finished with value: 0.6096673288347242 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:12:26,461] Trial 36 finished with value: 0.6191896537264175 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:12:30,784] Trial 37 finished with value: 0.6193583715383921 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:12:34,198] Trial 38 finished with value: 0.6286653648233297 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:12:42,127] Trial 39 finished with value: 0.6196452775750584 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:12:45,439] Trial 40 finished with value: 0.6316600713374395 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:12:48,454] Trial 41 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:12:51,518] Trial 42 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:12:54,870] Trial 43 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:12:57,970] Trial 44 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:13:02,181] Trial 45 finished with value: 0.6193583715383921 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:13:05,381] Trial 46 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:13:08,403] Trial 47 finished with value: 0.5959420465158808 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:13:11,416] Trial 48 finished with value: 0.6044913754289046 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.5959420465158808.\n",
      "[I 2025-05-31 13:13:14,968] Trial 49 finished with value: 0.6316600713374395 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 7 with value: 0.5959420465158808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.5959\n",
      "Best parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation - RMSE: 11.1828, MAE: 3.4911, RMSLE: 0.6678\n",
      "✓ Successfully tuned model for LINGERIE\n",
      "\n",
      "============================================================\n",
      "Progress: 23/33 - Training model for family: LIQUOR,WINE,BEER\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 13:13:17,553] A new study created in memory with name: no-name-7b4e7f11-d7de-4135-abed-58dfc25c1b3d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family LIQUOR,WINE,BEER data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for LIQUOR,WINE,BEER ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 13:13:24,731] Trial 0 finished with value: 0.9586562029223442 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.9586562029223442.\n",
      "[I 2025-05-31 13:13:31,862] Trial 1 finished with value: 0.9426231835532265 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.9426231835532265.\n",
      "[I 2025-05-31 13:13:39,661] Trial 2 finished with value: 0.9143835082376155 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 2 with value: 0.9143835082376155.\n",
      "[I 2025-05-31 13:13:43,591] Trial 3 finished with value: 1.0047722686062464 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 2 with value: 0.9143835082376155.\n",
      "[I 2025-05-31 13:13:52,396] Trial 4 finished with value: 0.9476241190984439 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 2 with value: 0.9143835082376155.\n",
      "[I 2025-05-31 13:13:57,854] Trial 5 finished with value: 0.9490131166244486 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 2 with value: 0.9143835082376155.\n",
      "[I 2025-05-31 13:14:02,611] Trial 6 finished with value: 0.926784455769448 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 2 with value: 0.9143835082376155.\n",
      "[I 2025-05-31 13:14:06,499] Trial 7 finished with value: 0.9010043530129547 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.9010043530129547.\n",
      "[I 2025-05-31 13:14:17,087] Trial 8 finished with value: 0.8964476905689714 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.8964476905689714.\n",
      "[I 2025-05-31 13:14:22,846] Trial 9 finished with value: 0.9538516094808314 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 8 with value: 0.8964476905689714.\n",
      "[I 2025-05-31 13:14:32,185] Trial 10 finished with value: 0.9361985731215516 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 8 with value: 0.8964476905689714.\n",
      "[I 2025-05-31 13:14:36,053] Trial 11 finished with value: 0.9010043530129547 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 8 with value: 0.8964476905689714.\n",
      "[I 2025-05-31 13:14:42,925] Trial 12 finished with value: 0.8962171633032154 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.8962171633032154.\n",
      "[I 2025-05-31 13:14:52,373] Trial 13 finished with value: 0.9738883370838173 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.8962171633032154.\n",
      "[I 2025-05-31 13:14:59,542] Trial 14 finished with value: 0.9482547813385681 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.8962171633032154.\n",
      "[I 2025-05-31 13:15:09,004] Trial 15 finished with value: 0.9738883370838173 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.8962171633032154.\n",
      "[I 2025-05-31 13:15:16,245] Trial 16 finished with value: 0.9123651456479159 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 12 with value: 0.8962171633032154.\n",
      "[I 2025-05-31 13:15:26,283] Trial 17 finished with value: 0.8911304407506023 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 17 with value: 0.8911304407506023.\n",
      "[I 2025-05-31 13:15:34,691] Trial 18 finished with value: 0.938963896962583 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 17 with value: 0.8911304407506023.\n",
      "[I 2025-05-31 13:15:42,348] Trial 19 finished with value: 0.9382343231064448 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 17 with value: 0.8911304407506023.\n",
      "[I 2025-05-31 13:16:04,938] Trial 20 finished with value: 0.8900757642258359 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 20 with value: 0.8900757642258359.\n",
      "[I 2025-05-31 13:16:20,245] Trial 21 finished with value: 0.8900757642258359 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 20 with value: 0.8900757642258359.\n",
      "[I 2025-05-31 13:16:32,513] Trial 22 finished with value: 0.8900757642258359 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 20 with value: 0.8900757642258359.\n",
      "[I 2025-05-31 13:16:44,235] Trial 23 finished with value: 0.8900757642258359 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 20 with value: 0.8900757642258359.\n",
      "[I 2025-05-31 13:16:56,980] Trial 24 finished with value: 0.8900757642258359 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 20 with value: 0.8900757642258359.\n",
      "[I 2025-05-31 13:17:15,034] Trial 25 finished with value: 0.8900757642258359 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 20 with value: 0.8900757642258359.\n",
      "[I 2025-05-31 13:17:29,108] Trial 26 finished with value: 0.9339504724800872 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 20 with value: 0.8900757642258359.\n",
      "[I 2025-05-31 13:17:39,861] Trial 27 finished with value: 0.8900757642258359 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 20 with value: 0.8900757642258359.\n",
      "[I 2025-05-31 13:17:50,726] Trial 28 finished with value: 0.8900757642258359 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 20 with value: 0.8900757642258359.\n",
      "[I 2025-05-31 13:18:00,193] Trial 29 finished with value: 0.9339504724800872 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 20 with value: 0.8900757642258359.\n",
      "[I 2025-05-31 13:18:10,084] Trial 30 finished with value: 0.8900757642258359 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 20 with value: 0.8900757642258359.\n",
      "[I 2025-05-31 13:18:26,279] Trial 31 finished with value: 0.8900757642258359 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 20 with value: 0.8900757642258359.\n",
      "[I 2025-05-31 13:18:37,909] Trial 32 finished with value: 0.8900757642258359 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 20 with value: 0.8900757642258359.\n",
      "[I 2025-05-31 13:18:47,893] Trial 33 finished with value: 0.8900757642258359 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 20 with value: 0.8900757642258359.\n",
      "[I 2025-05-31 13:18:58,161] Trial 34 finished with value: 0.9339504724800872 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 20 with value: 0.8900757642258359.\n",
      "[I 2025-05-31 13:19:09,289] Trial 35 finished with value: 0.8900757642258359 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 20 with value: 0.8900757642258359.\n",
      "[I 2025-05-31 13:19:20,130] Trial 36 finished with value: 0.8900757642258359 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 20 with value: 0.8900757642258359.\n",
      "[I 2025-05-31 13:19:30,533] Trial 37 finished with value: 0.9514602061955291 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 20 with value: 0.8900757642258359.\n",
      "[I 2025-05-31 13:19:47,099] Trial 38 finished with value: 0.9339504724800872 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 20 with value: 0.8900757642258359.\n",
      "[I 2025-05-31 13:19:56,561] Trial 39 finished with value: 0.9514602061955291 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 20 with value: 0.8900757642258359.\n",
      "[I 2025-05-31 13:20:08,805] Trial 40 finished with value: 0.8887420463053809 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 40 with value: 0.8887420463053809.\n",
      "[I 2025-05-31 13:20:21,975] Trial 41 finished with value: 0.8887420463053809 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 40 with value: 0.8887420463053809.\n",
      "[I 2025-05-31 13:20:37,964] Trial 42 finished with value: 0.8887420463053809 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 40 with value: 0.8887420463053809.\n",
      "[I 2025-05-31 13:20:51,288] Trial 43 finished with value: 0.8887420463053809 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 40 with value: 0.8887420463053809.\n",
      "[I 2025-05-31 13:21:03,356] Trial 44 finished with value: 0.8887420463053809 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 40 with value: 0.8887420463053809.\n",
      "[I 2025-05-31 13:21:12,179] Trial 45 finished with value: 0.9490131166244486 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 40 with value: 0.8887420463053809.\n",
      "[I 2025-05-31 13:21:24,412] Trial 46 finished with value: 0.8887420463053809 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 40 with value: 0.8887420463053809.\n",
      "[I 2025-05-31 13:21:32,726] Trial 47 finished with value: 0.9377128609605542 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 40 with value: 0.8887420463053809.\n",
      "[I 2025-05-31 13:21:38,492] Trial 48 finished with value: 0.9563658057775367 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 40 with value: 0.8887420463053809.\n",
      "[I 2025-05-31 13:21:49,930] Trial 49 finished with value: 0.9264933444270884 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 40 with value: 0.8887420463053809.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.8887\n",
      "Best parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}\n",
      "Validation - RMSE: 63.7747, MAE: 27.4202, RMSLE: 0.7739\n",
      "✓ Successfully tuned model for LIQUOR,WINE,BEER\n",
      "\n",
      "============================================================\n",
      "Progress: 24/33 - Training model for family: MAGAZINES\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 13:21:56,962] A new study created in memory with name: no-name-1db3a4e4-5e20-4d1e-a719-3ee5c89e48cc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family MAGAZINES data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for MAGAZINES ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 13:22:03,048] Trial 0 finished with value: 0.3748259231595084 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.3748259231595084.\n",
      "[I 2025-05-31 13:22:08,792] Trial 1 finished with value: 0.3747034058876996 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.3747034058876996.\n",
      "[I 2025-05-31 13:22:14,965] Trial 2 finished with value: 0.3749115264918383 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 1 with value: 0.3747034058876996.\n",
      "[I 2025-05-31 13:22:18,313] Trial 3 finished with value: 0.3809809257350211 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.3747034058876996.\n",
      "[I 2025-05-31 13:22:27,022] Trial 4 finished with value: 0.3678937047395618 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.3678937047395618.\n",
      "[I 2025-05-31 13:22:31,268] Trial 5 finished with value: 0.3785360926695387 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.3678937047395618.\n",
      "[I 2025-05-31 13:22:34,997] Trial 6 finished with value: 0.36817687362497215 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.3678937047395618.\n",
      "[I 2025-05-31 13:22:41,575] Trial 7 finished with value: 0.3692879098525272 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.3678937047395618.\n",
      "[I 2025-05-31 13:22:52,004] Trial 8 finished with value: 0.37221514037717673 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.3678937047395618.\n",
      "[I 2025-05-31 13:22:58,863] Trial 9 finished with value: 0.37898129107308326 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.3678937047395618.\n",
      "[I 2025-05-31 13:23:11,951] Trial 10 finished with value: 0.36621135705198293 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.36621135705198293.\n",
      "[I 2025-05-31 13:23:24,329] Trial 11 finished with value: 0.36621135705198293 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.36621135705198293.\n",
      "[I 2025-05-31 13:23:42,001] Trial 12 finished with value: 0.36621135705198293 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.36621135705198293.\n",
      "[I 2025-05-31 13:24:00,404] Trial 13 finished with value: 0.36621135705198293 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.36621135705198293.\n",
      "[I 2025-05-31 13:24:14,328] Trial 14 finished with value: 0.36621135705198293 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.36621135705198293.\n",
      "[I 2025-05-31 13:24:26,349] Trial 15 finished with value: 0.36621135705198293 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.36621135705198293.\n",
      "[I 2025-05-31 13:24:43,812] Trial 16 finished with value: 0.36621135705198293 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.36621135705198293.\n",
      "[I 2025-05-31 13:24:51,861] Trial 17 finished with value: 0.36621135705198293 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.36621135705198293.\n",
      "[I 2025-05-31 13:25:00,295] Trial 18 finished with value: 0.366571897916147 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 10 with value: 0.36621135705198293.\n",
      "[I 2025-05-31 13:25:10,870] Trial 19 finished with value: 0.36621135705198293 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.36621135705198293.\n",
      "[I 2025-05-31 13:25:19,413] Trial 20 finished with value: 0.36621135705198293 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.36621135705198293.\n",
      "[I 2025-05-31 13:25:27,231] Trial 21 finished with value: 0.36621135705198293 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.36621135705198293.\n",
      "[I 2025-05-31 13:25:34,962] Trial 22 finished with value: 0.36621135705198293 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.36621135705198293.\n",
      "[I 2025-05-31 13:25:42,838] Trial 23 finished with value: 0.36621135705198293 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.36621135705198293.\n",
      "[I 2025-05-31 13:25:50,757] Trial 24 finished with value: 0.36621135705198293 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.36621135705198293.\n",
      "[I 2025-05-31 13:25:58,598] Trial 25 finished with value: 0.36621135705198293 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.36621135705198293.\n",
      "[I 2025-05-31 13:26:01,638] Trial 26 finished with value: 0.36855239575838517 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 10 with value: 0.36621135705198293.\n",
      "[I 2025-05-31 13:26:09,261] Trial 27 finished with value: 0.36621135705198293 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.36621135705198293.\n",
      "[I 2025-05-31 13:26:16,917] Trial 28 finished with value: 0.36621135705198293 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.36621135705198293.\n",
      "[I 2025-05-31 13:26:22,315] Trial 29 finished with value: 0.3659602291305087 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.3659602291305087.\n",
      "[I 2025-05-31 13:26:28,138] Trial 30 finished with value: 0.3659602291305087 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.3659602291305087.\n",
      "[I 2025-05-31 13:26:33,545] Trial 31 finished with value: 0.3659602291305087 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.3659602291305087.\n",
      "[I 2025-05-31 13:26:39,055] Trial 32 finished with value: 0.3659602291305087 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.3659602291305087.\n",
      "[I 2025-05-31 13:26:44,467] Trial 33 finished with value: 0.3659602291305087 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.3659602291305087.\n",
      "[I 2025-05-31 13:26:50,158] Trial 34 finished with value: 0.37493430498355745 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.3659602291305087.\n",
      "[I 2025-05-31 13:26:55,739] Trial 35 finished with value: 0.36850060855026795 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.3659602291305087.\n",
      "[I 2025-05-31 13:27:01,503] Trial 36 finished with value: 0.37493430498355745 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.3659602291305087.\n",
      "[I 2025-05-31 13:27:04,569] Trial 37 finished with value: 0.37151928140161933 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.3659602291305087.\n",
      "[I 2025-05-31 13:27:11,092] Trial 38 finished with value: 0.37493430498355745 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.3659602291305087.\n",
      "[I 2025-05-31 13:27:14,276] Trial 39 finished with value: 0.37151928140161933 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.3659602291305087.\n",
      "[I 2025-05-31 13:27:19,899] Trial 40 finished with value: 0.3659602291305087 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.3659602291305087.\n",
      "[I 2025-05-31 13:27:25,621] Trial 41 finished with value: 0.3659602291305087 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.3659602291305087.\n",
      "[I 2025-05-31 13:27:31,111] Trial 42 finished with value: 0.3659602291305087 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.3659602291305087.\n",
      "[I 2025-05-31 13:27:36,518] Trial 43 finished with value: 0.3659602291305087 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.3659602291305087.\n",
      "[I 2025-05-31 13:27:42,042] Trial 44 finished with value: 0.3659602291305087 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.3659602291305087.\n",
      "[I 2025-05-31 13:27:45,307] Trial 45 finished with value: 0.3812322767182385 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.3659602291305087.\n",
      "[I 2025-05-31 13:27:50,839] Trial 46 finished with value: 0.3659602291305087 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.3659602291305087.\n",
      "[I 2025-05-31 13:27:56,570] Trial 47 finished with value: 0.3659602291305087 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.3659602291305087.\n",
      "[I 2025-05-31 13:28:02,057] Trial 48 finished with value: 0.3659602291305087 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.3659602291305087.\n",
      "[I 2025-05-31 13:28:08,783] Trial 49 finished with value: 0.37493430498355745 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.3659602291305087.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.3660\n",
      "Best parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation - RMSE: 3.4584, MAE: 1.7342, RMSLE: 0.3630\n",
      "✓ Successfully tuned model for MAGAZINES\n",
      "\n",
      "============================================================\n",
      "Progress: 25/33 - Training model for family: MEATS\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 13:28:14,304] A new study created in memory with name: no-name-4315410c-62b4-4c51-acbd-0e8415ac6a2b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family MEATS data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for MEATS ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 13:28:23,854] Trial 0 finished with value: 1.0306348016193978 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 1.0306348016193978.\n",
      "[I 2025-05-31 13:28:32,468] Trial 1 finished with value: 1.0473876715714932 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 1.0306348016193978.\n",
      "[I 2025-05-31 13:28:43,825] Trial 2 finished with value: 1.0568817267536275 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 0 with value: 1.0306348016193978.\n",
      "[I 2025-05-31 13:28:53,033] Trial 3 finished with value: 1.1091167876344796 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 1.0306348016193978.\n",
      "[I 2025-05-31 13:29:05,750] Trial 4 finished with value: 1.0071212345990783 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 1.0071212345990783.\n",
      "[I 2025-05-31 13:29:15,281] Trial 5 finished with value: 1.0657899142925438 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 1.0071212345990783.\n",
      "[I 2025-05-31 13:29:29,278] Trial 6 finished with value: 1.0256597145945907 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 1.0071212345990783.\n",
      "[I 2025-05-31 13:29:34,377] Trial 7 finished with value: 1.1058269268948924 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 1.0071212345990783.\n",
      "[I 2025-05-31 13:30:13,588] Trial 8 finished with value: 0.9964656274855509 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:30:37,622] Trial 9 finished with value: 1.0730240896182386 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:30:49,199] Trial 10 finished with value: 1.0358971142280602 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:30:59,391] Trial 11 finished with value: 1.0071212345990783 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:31:09,980] Trial 12 finished with value: 1.0071212345990783 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:31:19,976] Trial 13 finished with value: 1.0071212345990783 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:31:31,989] Trial 14 finished with value: 1.0102372873111847 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:31:42,406] Trial 15 finished with value: 1.0071212345990783 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:31:54,591] Trial 16 finished with value: 0.9964656274855509 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:32:06,814] Trial 17 finished with value: 0.9964656274855509 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:32:18,884] Trial 18 finished with value: 1.0124288463365616 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:32:30,834] Trial 19 finished with value: 0.9964656274855509 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:32:42,735] Trial 20 finished with value: 0.9964656274855509 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:32:54,940] Trial 21 finished with value: 0.9964656274855509 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:33:07,095] Trial 22 finished with value: 0.9964656274855509 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:33:19,080] Trial 23 finished with value: 0.9964656274855509 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:33:30,903] Trial 24 finished with value: 0.9964656274855509 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:33:42,485] Trial 25 finished with value: 0.9964656274855509 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:33:50,706] Trial 26 finished with value: 1.1044308228322068 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:34:03,817] Trial 27 finished with value: 0.9964656274855509 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:34:17,974] Trial 28 finished with value: 0.9964656274855509 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:34:26,715] Trial 29 finished with value: 1.0306348016193978 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:34:39,267] Trial 30 finished with value: 0.9964656274855509 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:34:51,084] Trial 31 finished with value: 0.9964656274855509 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:35:02,978] Trial 32 finished with value: 0.9964656274855509 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:35:14,898] Trial 33 finished with value: 0.9964656274855509 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:35:23,216] Trial 34 finished with value: 1.0473876715714932 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:35:35,308] Trial 35 finished with value: 0.9964656274855509 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:35:43,664] Trial 36 finished with value: 1.0251638283049223 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:35:50,837] Trial 37 finished with value: 1.0719723436753026 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:36:02,293] Trial 38 finished with value: 1.030502988135082 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:36:07,037] Trial 39 finished with value: 1.0995643903985564 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:36:19,658] Trial 40 finished with value: 1.003950479967075 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:36:31,300] Trial 41 finished with value: 0.9964656274855509 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:36:43,080] Trial 42 finished with value: 0.9964656274855509 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:36:54,829] Trial 43 finished with value: 0.9964656274855509 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:37:06,612] Trial 44 finished with value: 0.9964656274855509 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:37:12,063] Trial 45 finished with value: 1.0040524818315344 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:37:24,258] Trial 46 finished with value: 0.9964656274855509 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:37:35,919] Trial 47 finished with value: 1.0102372873111847 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:37:46,395] Trial 48 finished with value: 1.0232850723296258 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n",
      "[I 2025-05-31 13:37:53,684] Trial 49 finished with value: 1.0657899142925438 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.9964656274855509.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.9965\n",
      "Best parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}\n",
      "Validation - RMSE: 658.5498, MAE: 273.9953, RMSLE: 0.4975\n",
      "✓ Successfully tuned model for MEATS\n",
      "\n",
      "============================================================\n",
      "Progress: 26/33 - Training model for family: PERSONAL CARE\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 13:38:00,707] A new study created in memory with name: no-name-4762861f-e5f4-4579-a9f4-7cf55172966a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family PERSONAL CARE data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for PERSONAL CARE ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 13:38:10,138] Trial 0 finished with value: 0.7929002982596097 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.7929002982596097.\n",
      "[I 2025-05-31 13:38:19,838] Trial 1 finished with value: 0.7910260493547034 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.7910260493547034.\n",
      "[I 2025-05-31 13:38:30,118] Trial 2 finished with value: 0.7992512469458442 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 1 with value: 0.7910260493547034.\n",
      "[I 2025-05-31 13:38:35,278] Trial 3 finished with value: 0.8395482709715526 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.7910260493547034.\n",
      "[I 2025-05-31 13:38:46,760] Trial 4 finished with value: 0.7511313698271547 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7511313698271547.\n",
      "[I 2025-05-31 13:38:54,409] Trial 5 finished with value: 0.8259575740845198 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7511313698271547.\n",
      "[I 2025-05-31 13:39:00,318] Trial 6 finished with value: 0.760332995087175 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.7511313698271547.\n",
      "[I 2025-05-31 13:39:05,263] Trial 7 finished with value: 0.7369161987033984 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.7369161987033984.\n",
      "[I 2025-05-31 13:39:18,259] Trial 8 finished with value: 0.7827204687319096 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 7 with value: 0.7369161987033984.\n",
      "[I 2025-05-31 13:39:25,823] Trial 9 finished with value: 0.8452414286626415 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.7369161987033984.\n",
      "[I 2025-05-31 13:39:30,730] Trial 10 finished with value: 0.7369161987033984 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.7369161987033984.\n",
      "[I 2025-05-31 13:39:35,581] Trial 11 finished with value: 0.7369161987033984 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.7369161987033984.\n",
      "[I 2025-05-31 13:39:40,473] Trial 12 finished with value: 0.7369161987033984 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.7369161987033984.\n",
      "[I 2025-05-31 13:39:45,252] Trial 13 finished with value: 0.7369161987033984 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.7369161987033984.\n",
      "[I 2025-05-31 13:39:50,130] Trial 14 finished with value: 0.7369161987033984 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.7369161987033984.\n",
      "[I 2025-05-31 13:39:54,995] Trial 15 finished with value: 0.7369161987033984 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.7369161987033984.\n",
      "[I 2025-05-31 13:39:59,710] Trial 16 finished with value: 0.7369161987033984 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.7369161987033984.\n",
      "[I 2025-05-31 13:40:04,729] Trial 17 finished with value: 0.7369161987033984 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.7369161987033984.\n",
      "[I 2025-05-31 13:40:09,570] Trial 18 finished with value: 0.7426648461196038 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.7369161987033984.\n",
      "[I 2025-05-31 13:40:14,305] Trial 19 finished with value: 0.7369161987033984 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.7369161987033984.\n",
      "[I 2025-05-31 13:40:19,638] Trial 20 finished with value: 0.7369161987033984 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.7369161987033984.\n",
      "[I 2025-05-31 13:40:24,656] Trial 21 finished with value: 0.7369161987033984 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.7369161987033984.\n",
      "[I 2025-05-31 13:40:29,417] Trial 22 finished with value: 0.7369161987033984 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.7369161987033984.\n",
      "[I 2025-05-31 13:40:34,266] Trial 23 finished with value: 0.7369161987033984 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.7369161987033984.\n",
      "[I 2025-05-31 13:40:39,098] Trial 24 finished with value: 0.7369161987033984 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.7369161987033984.\n",
      "[I 2025-05-31 13:40:44,850] Trial 25 finished with value: 0.7369161987033984 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.7369161987033984.\n",
      "[I 2025-05-31 13:40:55,547] Trial 26 finished with value: 0.7532578385265084 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.7369161987033984.\n",
      "[I 2025-05-31 13:41:00,249] Trial 27 finished with value: 0.7369161987033984 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.7369161987033984.\n",
      "[I 2025-05-31 13:41:05,065] Trial 28 finished with value: 0.7369161987033984 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.7369161987033984.\n",
      "[I 2025-05-31 13:41:13,716] Trial 29 finished with value: 0.6864784247058267 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.6864784247058267.\n",
      "[I 2025-05-31 13:41:22,026] Trial 30 finished with value: 0.6864784247058267 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.6864784247058267.\n",
      "[I 2025-05-31 13:41:30,062] Trial 31 finished with value: 0.6864784247058267 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.6864784247058267.\n",
      "[I 2025-05-31 13:41:38,159] Trial 32 finished with value: 0.6864784247058267 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.6864784247058267.\n",
      "[I 2025-05-31 13:41:50,505] Trial 33 finished with value: 0.6864784247058267 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.6864784247058267.\n",
      "[I 2025-05-31 13:41:59,396] Trial 34 finished with value: 0.7932670212084032 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 29 with value: 0.6864784247058267.\n",
      "[I 2025-05-31 13:42:07,282] Trial 35 finished with value: 0.7336957088236727 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.6864784247058267.\n",
      "[I 2025-05-31 13:42:15,955] Trial 36 finished with value: 0.7932670212084032 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 29 with value: 0.6864784247058267.\n",
      "[I 2025-05-31 13:42:27,266] Trial 37 finished with value: 0.7455277659448205 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.6864784247058267.\n",
      "[I 2025-05-31 13:42:44,141] Trial 38 finished with value: 0.7932670212084032 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 29 with value: 0.6864784247058267.\n",
      "[I 2025-05-31 13:43:05,357] Trial 39 finished with value: 0.7455277659448205 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.6864784247058267.\n",
      "[I 2025-05-31 13:43:13,856] Trial 40 finished with value: 0.710536643170462 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 29 with value: 0.6864784247058267.\n",
      "[I 2025-05-31 13:43:21,578] Trial 41 finished with value: 0.6864784247058267 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.6864784247058267.\n",
      "[I 2025-05-31 13:43:29,542] Trial 42 finished with value: 0.6864784247058267 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.6864784247058267.\n",
      "[I 2025-05-31 13:43:37,294] Trial 43 finished with value: 0.6864784247058267 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.6864784247058267.\n",
      "[I 2025-05-31 13:43:45,046] Trial 44 finished with value: 0.6864784247058267 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.6864784247058267.\n",
      "[I 2025-05-31 13:43:54,018] Trial 45 finished with value: 0.7929002982596097 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.6864784247058267.\n",
      "[I 2025-05-31 13:44:03,939] Trial 46 finished with value: 0.7532578385265084 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.6864784247058267.\n",
      "[I 2025-05-31 13:44:11,719] Trial 47 finished with value: 0.6864784247058267 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.6864784247058267.\n",
      "[I 2025-05-31 13:44:19,459] Trial 48 finished with value: 0.6864784247058267 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 29 with value: 0.6864784247058267.\n",
      "[I 2025-05-31 13:44:27,917] Trial 49 finished with value: 0.7932670212084032 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 29 with value: 0.6864784247058267.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.6865\n",
      "Best parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation - RMSE: 164.5577, MAE: 83.6847, RMSLE: 0.3119\n",
      "✓ Successfully tuned model for PERSONAL CARE\n",
      "\n",
      "============================================================\n",
      "Progress: 27/33 - Training model for family: PET SUPPLIES\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 13:44:33,336] A new study created in memory with name: no-name-ce2b36c8-242b-460f-98da-de0f0b5bde38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family PET SUPPLIES data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for PET SUPPLIES ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 13:44:39,426] Trial 0 finished with value: 0.35537304992704843 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.35537304992704843.\n",
      "[I 2025-05-31 13:44:45,553] Trial 1 finished with value: 0.355409216862905 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.35537304992704843.\n",
      "[I 2025-05-31 13:44:51,898] Trial 2 finished with value: 0.35522672883743683 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 2 with value: 0.35522672883743683.\n",
      "[I 2025-05-31 13:44:55,383] Trial 3 finished with value: 0.36243576683777223 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 2 with value: 0.35522672883743683.\n",
      "[I 2025-05-31 13:45:02,693] Trial 4 finished with value: 0.35125394535477944 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.35125394535477944.\n",
      "[I 2025-05-31 13:45:07,447] Trial 5 finished with value: 0.36088812511968166 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.35125394535477944.\n",
      "[I 2025-05-31 13:45:11,313] Trial 6 finished with value: 0.35061474293657174 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 6 with value: 0.35061474293657174.\n",
      "[I 2025-05-31 13:45:14,375] Trial 7 finished with value: 0.3520663324745783 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 6 with value: 0.35061474293657174.\n",
      "[I 2025-05-31 13:45:22,365] Trial 8 finished with value: 0.35356024399763175 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 6 with value: 0.35061474293657174.\n",
      "[I 2025-05-31 13:45:26,974] Trial 9 finished with value: 0.3610149615076743 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 6 with value: 0.35061474293657174.\n",
      "[I 2025-05-31 13:45:31,418] Trial 10 finished with value: 0.35158977855587353 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 6 with value: 0.35061474293657174.\n",
      "[I 2025-05-31 13:45:38,484] Trial 11 finished with value: 0.3520056203163297 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 6 with value: 0.35061474293657174.\n",
      "[I 2025-05-31 13:45:42,621] Trial 12 finished with value: 0.3505914861988238 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.3505914861988238.\n",
      "[I 2025-05-31 13:45:46,619] Trial 13 finished with value: 0.35061474293657174 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.3505914861988238.\n",
      "[I 2025-05-31 13:45:50,617] Trial 14 finished with value: 0.35116438484913126 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.3505914861988238.\n",
      "[I 2025-05-31 13:45:54,496] Trial 15 finished with value: 0.35061474293657174 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.3505914861988238.\n",
      "[I 2025-05-31 13:45:58,696] Trial 16 finished with value: 0.35061474293657174 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.3505914861988238.\n",
      "[I 2025-05-31 13:46:02,771] Trial 17 finished with value: 0.3505914861988238 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.3505914861988238.\n",
      "[I 2025-05-31 13:46:07,209] Trial 18 finished with value: 0.35131938411000424 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.3505914861988238.\n",
      "[I 2025-05-31 13:46:11,435] Trial 19 finished with value: 0.3505914861988238 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.3505914861988238.\n",
      "[I 2025-05-31 13:46:15,425] Trial 20 finished with value: 0.3505914861988238 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.3505914861988238.\n",
      "[I 2025-05-31 13:46:19,392] Trial 21 finished with value: 0.3505914861988238 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.3505914861988238.\n",
      "[I 2025-05-31 13:46:23,315] Trial 22 finished with value: 0.3505914861988238 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.3505914861988238.\n",
      "[I 2025-05-31 13:46:27,256] Trial 23 finished with value: 0.3505914861988238 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.3505914861988238.\n",
      "[I 2025-05-31 13:46:31,396] Trial 24 finished with value: 0.3505914861988238 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.3505914861988238.\n",
      "[I 2025-05-31 13:46:35,362] Trial 25 finished with value: 0.3505914861988238 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.3505914861988238.\n",
      "[I 2025-05-31 13:46:38,411] Trial 26 finished with value: 0.3520663324745783 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.3505914861988238.\n",
      "[I 2025-05-31 13:46:43,262] Trial 27 finished with value: 0.3505914861988238 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.3505914861988238.\n",
      "[I 2025-05-31 13:46:48,523] Trial 28 finished with value: 0.3505914861988238 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.3505914861988238.\n",
      "[I 2025-05-31 13:46:53,948] Trial 29 finished with value: 0.35119783527049325 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.3505914861988238.\n",
      "[I 2025-05-31 13:46:57,894] Trial 30 finished with value: 0.3505914861988238 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.3505914861988238.\n",
      "[I 2025-05-31 13:47:01,587] Trial 31 finished with value: 0.3505914861988238 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.3505914861988238.\n",
      "[I 2025-05-31 13:47:06,074] Trial 32 finished with value: 0.3505914861988238 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.3505914861988238.\n",
      "[I 2025-05-31 13:47:09,768] Trial 33 finished with value: 0.3505914861988238 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.3505914861988238.\n",
      "[I 2025-05-31 13:47:15,517] Trial 34 finished with value: 0.35557554355673354 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.3505914861988238.\n",
      "[I 2025-05-31 13:47:19,257] Trial 35 finished with value: 0.3505914861988238 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.3505914861988238.\n",
      "[I 2025-05-31 13:47:25,005] Trial 36 finished with value: 0.35557554355673354 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.3505914861988238.\n",
      "[I 2025-05-31 13:47:32,134] Trial 37 finished with value: 0.3504666496425597 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.3504666496425597.\n",
      "[I 2025-05-31 13:47:48,288] Trial 38 finished with value: 0.3607008554690843 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.3504666496425597.\n",
      "[I 2025-05-31 13:47:52,072] Trial 39 finished with value: 0.3516153174352863 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.3504666496425597.\n",
      "[I 2025-05-31 13:48:00,982] Trial 40 finished with value: 0.35150020555690836 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.3504666496425597.\n",
      "[I 2025-05-31 13:48:23,239] Trial 41 finished with value: 0.3504666496425597 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.3504666496425597.\n",
      "[I 2025-05-31 13:48:37,049] Trial 42 finished with value: 0.3504666496425597 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.3504666496425597.\n",
      "[I 2025-05-31 13:48:48,256] Trial 43 finished with value: 0.3504666496425597 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.3504666496425597.\n",
      "[I 2025-05-31 13:49:00,571] Trial 44 finished with value: 0.3504666496425597 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.3504666496425597.\n",
      "[I 2025-05-31 13:49:05,779] Trial 45 finished with value: 0.3609130556104969 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.3504666496425597.\n",
      "[I 2025-05-31 13:49:12,163] Trial 46 finished with value: 0.3504666496425597 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.3504666496425597.\n",
      "[I 2025-05-31 13:49:18,164] Trial 47 finished with value: 0.3504666496425597 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.3504666496425597.\n",
      "[I 2025-05-31 13:49:26,461] Trial 48 finished with value: 0.35162538152946765 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.3504666496425597.\n",
      "[I 2025-05-31 13:49:40,305] Trial 49 finished with value: 0.35344548898786093 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.3504666496425597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.3505\n",
      "Best parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation - RMSE: 4.9254, MAE: 2.4312, RMSLE: 0.3256\n",
      "✓ Successfully tuned model for PET SUPPLIES\n",
      "\n",
      "============================================================\n",
      "Progress: 28/33 - Training model for family: PLAYERS AND ELECTRONICS\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 13:49:46,807] A new study created in memory with name: no-name-020c646f-56c8-4a74-a749-fc494fd8d2d7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family PLAYERS AND ELECTRONICS data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for PLAYERS AND ELECTRONICS ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 13:49:55,454] Trial 0 finished with value: 0.4039212864040862 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4039212864040862.\n",
      "[I 2025-05-31 13:50:01,967] Trial 1 finished with value: 0.40473072881124744 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.4039212864040862.\n",
      "[I 2025-05-31 13:50:20,457] Trial 2 finished with value: 0.40423989140387645 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.4039212864040862.\n",
      "[I 2025-05-31 13:50:28,020] Trial 3 finished with value: 0.4123502646698543 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.4039212864040862.\n",
      "[I 2025-05-31 13:50:44,361] Trial 4 finished with value: 0.41885313695842047 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.4039212864040862.\n",
      "[I 2025-05-31 13:50:50,023] Trial 5 finished with value: 0.4078105915913964 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.4039212864040862.\n",
      "[I 2025-05-31 13:50:54,292] Trial 6 finished with value: 0.4008194013065989 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 6 with value: 0.4008194013065989.\n",
      "[I 2025-05-31 13:50:57,999] Trial 7 finished with value: 0.4007645478941096 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.4007645478941096.\n",
      "[I 2025-05-31 13:51:06,787] Trial 8 finished with value: 0.4001674326658913 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 8 with value: 0.4001674326658913.\n",
      "[I 2025-05-31 13:51:10,923] Trial 9 finished with value: 0.40847839629021493 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 8 with value: 0.4001674326658913.\n",
      "[I 2025-05-31 13:51:18,304] Trial 10 finished with value: 0.40410301629045414 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 8 with value: 0.4001674326658913.\n",
      "[I 2025-05-31 13:51:21,105] Trial 11 finished with value: 0.4007645478941096 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 8 with value: 0.4001674326658913.\n",
      "[I 2025-05-31 13:51:26,247] Trial 12 finished with value: 0.39999188086978105 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.39999188086978105.\n",
      "[I 2025-05-31 13:51:33,356] Trial 13 finished with value: 0.40320636450793373 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.39999188086978105.\n",
      "[I 2025-05-31 13:51:39,062] Trial 14 finished with value: 0.40479449540695306 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 12 with value: 0.39999188086978105.\n",
      "[I 2025-05-31 13:51:45,742] Trial 15 finished with value: 0.40320636450793373 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 12 with value: 0.39999188086978105.\n",
      "[I 2025-05-31 13:51:51,763] Trial 16 finished with value: 0.39725691292626847 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:51:57,019] Trial 17 finished with value: 0.39999188086978105 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:52:03,230] Trial 18 finished with value: 0.404576510167707 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:52:10,919] Trial 19 finished with value: 0.40065050019324544 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:52:18,749] Trial 20 finished with value: 0.39999188086978105 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:52:26,457] Trial 21 finished with value: 0.39999188086978105 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:52:31,410] Trial 22 finished with value: 0.39999188086978105 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:52:36,321] Trial 23 finished with value: 0.39999188086978105 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:52:41,550] Trial 24 finished with value: 0.39999188086978105 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:52:47,454] Trial 25 finished with value: 0.39999188086978105 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:52:52,804] Trial 26 finished with value: 0.4000645710856204 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:52:58,089] Trial 27 finished with value: 0.39999188086978105 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:53:04,208] Trial 28 finished with value: 0.39725691292626847 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:53:12,294] Trial 29 finished with value: 0.4000645710856204 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:53:22,561] Trial 30 finished with value: 0.39725691292626847 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:53:30,115] Trial 31 finished with value: 0.39725691292626847 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:53:36,135] Trial 32 finished with value: 0.39725691292626847 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:53:42,042] Trial 33 finished with value: 0.39725691292626847 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:53:49,347] Trial 34 finished with value: 0.4000645710856204 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:53:55,628] Trial 35 finished with value: 0.39725691292626847 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:54:03,156] Trial 36 finished with value: 0.40352933844851857 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:54:07,616] Trial 37 finished with value: 0.39798798897659043 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:54:15,124] Trial 38 finished with value: 0.40473072881124744 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:54:18,661] Trial 39 finished with value: 0.39798798897659043 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:54:28,182] Trial 40 finished with value: 0.39725691292626847 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:54:36,283] Trial 41 finished with value: 0.39725691292626847 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:54:46,024] Trial 42 finished with value: 0.39725691292626847 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:54:53,730] Trial 43 finished with value: 0.39725691292626847 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:55:00,830] Trial 44 finished with value: 0.39725691292626847 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:55:06,334] Trial 45 finished with value: 0.4078105915913964 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:55:13,313] Trial 46 finished with value: 0.39725691292626847 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:55:23,314] Trial 47 finished with value: 0.4035636465131304 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:55:27,874] Trial 48 finished with value: 0.4116292609434644 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 16 with value: 0.39725691292626847.\n",
      "[I 2025-05-31 13:55:36,493] Trial 49 finished with value: 0.4000645710856204 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 16 with value: 0.39725691292626847.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.3973\n",
      "Best parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}\n",
      "Validation - RMSE: 7.2803, MAE: 3.7287, RMSLE: 0.3685\n",
      "✓ Successfully tuned model for PLAYERS AND ELECTRONICS\n",
      "\n",
      "============================================================\n",
      "Progress: 29/33 - Training model for family: POULTRY\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 13:55:40,398] A new study created in memory with name: no-name-c9cf6800-59d3-4640-82b0-5d3a7cc2429c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family POULTRY data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for POULTRY ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 13:55:50,300] Trial 0 finished with value: 0.890233233068526 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.890233233068526.\n",
      "[I 2025-05-31 13:56:01,833] Trial 1 finished with value: 0.8922417408892845 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.890233233068526.\n",
      "[I 2025-05-31 13:56:11,079] Trial 2 finished with value: 0.8843106760721006 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 2 with value: 0.8843106760721006.\n",
      "[I 2025-05-31 13:56:15,655] Trial 3 finished with value: 1.0165055317902578 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 2 with value: 0.8843106760721006.\n",
      "[I 2025-05-31 13:56:25,514] Trial 4 finished with value: 0.8549174033750507 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.8549174033750507.\n",
      "[I 2025-05-31 13:56:30,927] Trial 5 finished with value: 0.9904148562875591 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.8549174033750507.\n",
      "[I 2025-05-31 13:56:39,218] Trial 6 finished with value: 0.8792201966760039 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.8549174033750507.\n",
      "[I 2025-05-31 13:56:44,807] Trial 7 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:56:55,910] Trial 8 finished with value: 0.8921113860384092 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:57:02,934] Trial 9 finished with value: 0.9823517011937971 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:57:07,226] Trial 10 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:57:11,336] Trial 11 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:57:15,288] Trial 12 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:57:19,156] Trial 13 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:57:23,527] Trial 14 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:57:27,973] Trial 15 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:57:31,877] Trial 16 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:57:35,950] Trial 17 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:57:39,593] Trial 18 finished with value: 0.8423185901206626 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:57:43,230] Trial 19 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:57:46,873] Trial 20 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:57:50,660] Trial 21 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:57:55,634] Trial 22 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:57:59,910] Trial 23 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:58:04,186] Trial 24 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:58:08,607] Trial 25 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:58:18,854] Trial 26 finished with value: 0.8413257075309342 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:58:23,257] Trial 27 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:58:27,649] Trial 28 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:58:36,663] Trial 29 finished with value: 0.8251696897913957 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:58:41,540] Trial 30 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:58:48,467] Trial 31 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:58:54,519] Trial 32 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:59:00,059] Trial 33 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:59:08,648] Trial 34 finished with value: 0.8819953292098089 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:59:13,145] Trial 35 finished with value: 0.8640555489212867 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:59:21,454] Trial 36 finished with value: 0.8805647841356009 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:59:30,200] Trial 37 finished with value: 0.8569496726776701 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:59:36,216] Trial 38 finished with value: 1.0043343152931183 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:59:49,974] Trial 39 finished with value: 0.8429839333441126 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:59:54,824] Trial 40 finished with value: 1.0019529408956585 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 13:59:59,030] Trial 41 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 14:00:03,113] Trial 42 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 14:00:07,737] Trial 43 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 14:00:12,068] Trial 44 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 14:00:18,170] Trial 45 finished with value: 0.8569496726776701 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 14:00:22,426] Trial 46 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 14:00:28,183] Trial 47 finished with value: 0.8212302171994418 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 14:00:32,691] Trial 48 finished with value: 0.8423185901206626 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 7 with value: 0.8212302171994418.\n",
      "[I 2025-05-31 14:00:37,614] Trial 49 finished with value: 1.0019529408956585 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 7 with value: 0.8212302171994418.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.8212\n",
      "Best parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation - RMSE: 287.3123, MAE: 156.2629, RMSLE: 0.4722\n",
      "✓ Successfully tuned model for POULTRY\n",
      "\n",
      "============================================================\n",
      "Progress: 30/33 - Training model for family: PREPARED FOODS\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 14:00:41,234] A new study created in memory with name: no-name-8246f094-f6a2-4172-90c6-c15f2bff8c1c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family PREPARED FOODS data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for PREPARED FOODS ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 14:00:49,675] Trial 0 finished with value: 0.6612927055703611 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.6612927055703611.\n",
      "[I 2025-05-31 14:00:58,038] Trial 1 finished with value: 0.6744117537266955 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.6612927055703611.\n",
      "[I 2025-05-31 14:01:07,910] Trial 2 finished with value: 0.6705029398512218 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.6612927055703611.\n",
      "[I 2025-05-31 14:01:16,349] Trial 3 finished with value: 0.697240018959565 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.6612927055703611.\n",
      "[I 2025-05-31 14:01:32,385] Trial 4 finished with value: 0.6758512465424046 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.6612927055703611.\n",
      "[I 2025-05-31 14:01:40,909] Trial 5 finished with value: 0.6679274975465598 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.6612927055703611.\n",
      "[I 2025-05-31 14:01:47,723] Trial 6 finished with value: 0.663659738987007 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.6612927055703611.\n",
      "[I 2025-05-31 14:01:54,696] Trial 7 finished with value: 0.6827516250411346 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.6612927055703611.\n",
      "[I 2025-05-31 14:02:06,543] Trial 8 finished with value: 0.68014460168976 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.6612927055703611.\n",
      "[I 2025-05-31 14:02:13,358] Trial 9 finished with value: 0.6913657333460046 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.6612927055703611.\n",
      "[I 2025-05-31 14:02:20,739] Trial 10 finished with value: 0.6716615205415475 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.6612927055703611.\n",
      "[I 2025-05-31 14:02:26,095] Trial 11 finished with value: 0.6415276332471181 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 11 with value: 0.6415276332471181.\n",
      "[I 2025-05-31 14:02:30,061] Trial 12 finished with value: 0.6837014607379169 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 11 with value: 0.6415276332471181.\n",
      "[I 2025-05-31 14:02:42,621] Trial 13 finished with value: 0.6353441632681425 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:02:51,823] Trial 14 finished with value: 0.6816296726282487 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:03:03,332] Trial 15 finished with value: 0.6353441632681425 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:03:17,157] Trial 16 finished with value: 0.6353441632681425 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:03:27,164] Trial 17 finished with value: 0.6353441632681425 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:03:36,901] Trial 18 finished with value: 0.663807198878894 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:03:46,221] Trial 19 finished with value: 0.6353441632681425 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:03:55,786] Trial 20 finished with value: 0.6353441632681425 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:04:06,432] Trial 21 finished with value: 0.6353441632681425 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:04:19,886] Trial 22 finished with value: 0.6353441632681425 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:04:29,510] Trial 23 finished with value: 0.6353441632681425 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:04:39,973] Trial 24 finished with value: 0.6353441632681425 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:04:49,938] Trial 25 finished with value: 0.6353441632681425 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:05:00,568] Trial 26 finished with value: 0.663807198878894 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:05:10,891] Trial 27 finished with value: 0.6353441632681425 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:05:20,935] Trial 28 finished with value: 0.6353441632681425 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:05:30,482] Trial 29 finished with value: 0.6353441632681425 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:05:40,229] Trial 30 finished with value: 0.6353441632681425 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:05:49,148] Trial 31 finished with value: 0.6353441632681425 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:05:58,565] Trial 32 finished with value: 0.6353441632681425 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:06:07,502] Trial 33 finished with value: 0.6353441632681425 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:06:22,937] Trial 34 finished with value: 0.6744117537266955 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:06:37,845] Trial 35 finished with value: 0.6353441632681425 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:06:47,560] Trial 36 finished with value: 0.6671573330445684 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:07:00,000] Trial 37 finished with value: 0.655852136409191 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:07:11,228] Trial 38 finished with value: 0.68014460168976 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:07:18,437] Trial 39 finished with value: 0.6697948544017512 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:07:28,896] Trial 40 finished with value: 0.666293815757596 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:07:38,842] Trial 41 finished with value: 0.6353441632681425 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:07:48,167] Trial 42 finished with value: 0.6353441632681425 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:07:57,617] Trial 43 finished with value: 0.6353441632681425 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:08:03,227] Trial 44 finished with value: 0.665442168611379 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:08:15,583] Trial 45 finished with value: 0.6870575142498107 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:08:25,519] Trial 46 finished with value: 0.6353441632681425 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:08:35,885] Trial 47 finished with value: 0.6878716188028506 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:08:58,626] Trial 48 finished with value: 0.655852136409191 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 13 with value: 0.6353441632681425.\n",
      "[I 2025-05-31 14:09:18,325] Trial 49 finished with value: 0.6793845459368248 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 13 with value: 0.6353441632681425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.6353\n",
      "Best parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}\n",
      "Validation - RMSE: 40.2154, MAE: 28.4386, RMSLE: 0.3189\n",
      "✓ Successfully tuned model for PREPARED FOODS\n",
      "\n",
      "============================================================\n",
      "Progress: 31/33 - Training model for family: PRODUCE\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 14:09:23,228] A new study created in memory with name: no-name-48f90676-7c54-407d-82d8-3e2916ad0c07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family PRODUCE data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for PRODUCE ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 14:09:31,204] Trial 0 finished with value: 1.2699388602897221 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 1.2699388602897221.\n",
      "[I 2025-05-31 14:09:39,364] Trial 1 finished with value: 1.2512726432390173 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 1.2512726432390173.\n",
      "[I 2025-05-31 14:10:00,439] Trial 2 finished with value: 1.2468893191189911 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 2 with value: 1.2468893191189911.\n",
      "[I 2025-05-31 14:10:17,055] Trial 3 finished with value: 1.797965568400044 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 2 with value: 1.2468893191189911.\n",
      "[I 2025-05-31 14:10:37,942] Trial 4 finished with value: 1.1531270496143822 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 1.1531270496143822.\n",
      "[I 2025-05-31 14:10:43,912] Trial 5 finished with value: 1.734246367453575 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 1.1531270496143822.\n",
      "[I 2025-05-31 14:10:49,078] Trial 6 finished with value: 1.0332423935127883 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 6 with value: 1.0332423935127883.\n",
      "[I 2025-05-31 14:10:52,916] Trial 7 finished with value: 1.2148232127770693 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 6 with value: 1.0332423935127883.\n",
      "[I 2025-05-31 14:11:03,486] Trial 8 finished with value: 1.091271738694039 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 6 with value: 1.0332423935127883.\n",
      "[I 2025-05-31 14:11:09,291] Trial 9 finished with value: 1.7480287261887562 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 6 with value: 1.0332423935127883.\n",
      "[I 2025-05-31 14:11:14,219] Trial 10 finished with value: 1.094602629259149 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 6 with value: 1.0332423935127883.\n",
      "[I 2025-05-31 14:11:28,195] Trial 11 finished with value: 0.95569278375481 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.95569278375481.\n",
      "[I 2025-05-31 14:11:46,324] Trial 12 finished with value: 0.95569278375481 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.95569278375481.\n",
      "[I 2025-05-31 14:11:54,594] Trial 13 finished with value: 0.95569278375481 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.95569278375481.\n",
      "[I 2025-05-31 14:12:06,464] Trial 14 finished with value: 1.02350384663272 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.95569278375481.\n",
      "[I 2025-05-31 14:12:15,336] Trial 15 finished with value: 0.95569278375481 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.95569278375481.\n",
      "[I 2025-05-31 14:12:24,268] Trial 16 finished with value: 0.95569278375481 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.95569278375481.\n",
      "[I 2025-05-31 14:12:33,631] Trial 17 finished with value: 0.95569278375481 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.95569278375481.\n",
      "[I 2025-05-31 14:12:42,771] Trial 18 finished with value: 1.047139227513033 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 11 with value: 0.95569278375481.\n",
      "[I 2025-05-31 14:12:54,808] Trial 19 finished with value: 0.95569278375481 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.95569278375481.\n",
      "[I 2025-05-31 14:13:03,085] Trial 20 finished with value: 0.95569278375481 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.95569278375481.\n",
      "[I 2025-05-31 14:13:15,804] Trial 21 finished with value: 0.95569278375481 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.95569278375481.\n",
      "[I 2025-05-31 14:13:26,558] Trial 22 finished with value: 0.95569278375481 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.95569278375481.\n",
      "[I 2025-05-31 14:13:35,110] Trial 23 finished with value: 0.95569278375481 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.95569278375481.\n",
      "[I 2025-05-31 14:13:43,956] Trial 24 finished with value: 0.95569278375481 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.95569278375481.\n",
      "[I 2025-05-31 14:13:54,102] Trial 25 finished with value: 0.95569278375481 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.95569278375481.\n",
      "[I 2025-05-31 14:14:01,566] Trial 26 finished with value: 1.0816387282346647 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 11 with value: 0.95569278375481.\n",
      "[I 2025-05-31 14:14:11,688] Trial 27 finished with value: 0.95569278375481 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.95569278375481.\n",
      "[I 2025-05-31 14:14:21,236] Trial 28 finished with value: 0.95569278375481 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.95569278375481.\n",
      "[I 2025-05-31 14:14:29,388] Trial 29 finished with value: 1.274565261550135 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 11 with value: 0.95569278375481.\n",
      "[I 2025-05-31 14:14:38,595] Trial 30 finished with value: 0.95569278375481 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.95569278375481.\n",
      "[I 2025-05-31 14:14:48,017] Trial 31 finished with value: 0.95569278375481 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.95569278375481.\n",
      "[I 2025-05-31 14:14:56,558] Trial 32 finished with value: 0.95569278375481 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.95569278375481.\n",
      "[I 2025-05-31 14:15:06,135] Trial 33 finished with value: 0.95569278375481 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.95569278375481.\n",
      "[I 2025-05-31 14:15:13,717] Trial 34 finished with value: 1.2512726432390173 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.95569278375481.\n",
      "[I 2025-05-31 14:15:24,000] Trial 35 finished with value: 0.95569278375481 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.95569278375481.\n",
      "[I 2025-05-31 14:15:31,851] Trial 36 finished with value: 1.2704293046868729 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 11 with value: 0.95569278375481.\n",
      "[I 2025-05-31 14:15:36,841] Trial 37 finished with value: 0.9405656599282558 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.9405656599282558.\n",
      "[I 2025-05-31 14:15:42,203] Trial 38 finished with value: 1.7229683547968984 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.9405656599282558.\n",
      "[I 2025-05-31 14:15:45,596] Trial 39 finished with value: 1.148020712953911 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.9405656599282558.\n",
      "[I 2025-05-31 14:15:53,659] Trial 40 finished with value: 1.011440249631988 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.9405656599282558.\n",
      "[I 2025-05-31 14:16:00,429] Trial 41 finished with value: 0.9405656599282558 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.9405656599282558.\n",
      "[I 2025-05-31 14:16:06,052] Trial 42 finished with value: 0.9405656599282558 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.9405656599282558.\n",
      "[I 2025-05-31 14:16:12,084] Trial 43 finished with value: 0.9405656599282558 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.9405656599282558.\n",
      "[I 2025-05-31 14:16:17,372] Trial 44 finished with value: 0.9405656599282558 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.9405656599282558.\n",
      "[I 2025-05-31 14:16:23,262] Trial 45 finished with value: 1.6950566936945253 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.9405656599282558.\n",
      "[I 2025-05-31 14:16:28,011] Trial 46 finished with value: 0.9405656599282558 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 37 with value: 0.9405656599282558.\n",
      "[I 2025-05-31 14:16:32,909] Trial 47 finished with value: 0.9186801080444841 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 47 with value: 0.9186801080444841.\n",
      "[I 2025-05-31 14:16:38,191] Trial 48 finished with value: 1.011440249631988 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 47 with value: 0.9186801080444841.\n",
      "[I 2025-05-31 14:16:44,854] Trial 49 finished with value: 1.7229683547968984 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 47 with value: 0.9186801080444841.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.9187\n",
      "Best parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation - RMSE: 763.9216, MAE: 416.6744, RMSLE: 0.8694\n",
      "✓ Successfully tuned model for PRODUCE\n",
      "\n",
      "============================================================\n",
      "Progress: 32/33 - Training model for family: SCHOOL AND OFFICE SUPPLIES\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 14:16:48,055] A new study created in memory with name: no-name-f85baddd-61dd-44b1-b8ed-cf7310706d27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family SCHOOL AND OFFICE SUPPLIES data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for SCHOOL AND OFFICE SUPPLIES ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 14:16:53,419] Trial 0 finished with value: 0.3152476464250231 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.3152476464250231.\n",
      "[I 2025-05-31 14:16:58,821] Trial 1 finished with value: 0.31574066335692247 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.3152476464250231.\n",
      "[I 2025-05-31 14:17:06,794] Trial 2 finished with value: 0.31572273907575177 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.3152476464250231.\n",
      "[I 2025-05-31 14:17:09,888] Trial 3 finished with value: 0.3155643881088893 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.3152476464250231.\n",
      "[I 2025-05-31 14:17:19,761] Trial 4 finished with value: 0.3259265426781562 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 0 with value: 0.3152476464250231.\n",
      "[I 2025-05-31 14:17:23,929] Trial 5 finished with value: 0.3125271838615394 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:17:26,312] Trial 6 finished with value: 0.31824937343710863 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:17:29,853] Trial 7 finished with value: 0.3199129380041439 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:17:38,281] Trial 8 finished with value: 0.3135116904191894 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:17:42,580] Trial 9 finished with value: 0.3132855532039615 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:17:47,511] Trial 10 finished with value: 0.32158701865030054 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:17:51,614] Trial 11 finished with value: 0.3132855532039615 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:17:56,188] Trial 12 finished with value: 0.3132855532039615 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:18:01,584] Trial 13 finished with value: 0.3132855532039615 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:18:05,510] Trial 14 finished with value: 0.31355995912075574 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:18:10,580] Trial 15 finished with value: 0.3132855532039615 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:18:15,772] Trial 16 finished with value: 0.31283310744495463 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:18:20,618] Trial 17 finished with value: 0.3125271838615394 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:18:23,485] Trial 18 finished with value: 0.31824937343710863 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:18:28,636] Trial 19 finished with value: 0.3125271838615394 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:18:35,577] Trial 20 finished with value: 0.3125271838615394 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:18:42,169] Trial 21 finished with value: 0.3125271838615394 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:18:47,047] Trial 22 finished with value: 0.3125271838615394 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:18:51,198] Trial 23 finished with value: 0.3125271838615394 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:18:54,877] Trial 24 finished with value: 0.3125271838615394 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:19:00,958] Trial 25 finished with value: 0.3125271838615394 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:19:08,084] Trial 26 finished with value: 0.32157600916958057 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:19:14,468] Trial 27 finished with value: 0.3125271838615394 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:19:18,775] Trial 28 finished with value: 0.3125271838615394 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:19:26,334] Trial 29 finished with value: 0.31574066335692247 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:19:30,578] Trial 30 finished with value: 0.3125271838615394 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:19:36,089] Trial 31 finished with value: 0.3125271838615394 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:19:40,716] Trial 32 finished with value: 0.3125271838615394 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:19:47,336] Trial 33 finished with value: 0.3125271838615394 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:19:52,364] Trial 34 finished with value: 0.31574066335692247 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:19:56,731] Trial 35 finished with value: 0.3125271838615394 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:20:03,287] Trial 36 finished with value: 0.31552410359352695 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:20:05,992] Trial 37 finished with value: 0.31824937343710863 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:20:12,493] Trial 38 finished with value: 0.3125271838615394 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:20:19,821] Trial 39 finished with value: 0.31552410359352695 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:20:24,835] Trial 40 finished with value: 0.3206972977171455 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:20:28,963] Trial 41 finished with value: 0.3125271838615394 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:20:32,797] Trial 42 finished with value: 0.3125271838615394 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:20:37,577] Trial 43 finished with value: 0.3125271838615394 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:20:41,515] Trial 44 finished with value: 0.3125271838615394 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:20:45,695] Trial 45 finished with value: 0.3125271838615394 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:20:50,719] Trial 46 finished with value: 0.3126301793780529 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:20:55,273] Trial 47 finished with value: 0.31355995912075574 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:20:58,131] Trial 48 finished with value: 0.31954541306332235 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 5 with value: 0.3125271838615394.\n",
      "[I 2025-05-31 14:21:02,846] Trial 49 finished with value: 0.31350689206424676 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 5 with value: 0.3125271838615394.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.3125\n",
      "Best parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}\n",
      "Validation - RMSE: 27.2635, MAE: 4.3615, RMSLE: 0.4187\n",
      "✓ Successfully tuned model for SCHOOL AND OFFICE SUPPLIES\n",
      "\n",
      "============================================================\n",
      "Progress: 33/33 - Training model for family: SEAFOOD\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 14:21:06,406] A new study created in memory with name: no-name-b6564763-5aab-42b8-ac28-ee8856dd3c28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family SEAFOOD data shape: (89316, 47)\n",
      "Tuning set: (71452, 47), Validation set: (17864, 47)\n",
      "\n",
      "=== Optuna Tuning hyperparameters for SEAFOOD ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 14:21:19,741] Trial 0 finished with value: 0.5341753440771532 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 0 with value: 0.5341753440771532.\n",
      "[I 2025-05-31 14:21:32,310] Trial 1 finished with value: 0.5305605413418171 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.5305605413418171.\n",
      "[I 2025-05-31 14:21:44,160] Trial 2 finished with value: 0.5345230575790424 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 1 with value: 0.5305605413418171.\n",
      "[I 2025-05-31 14:21:49,280] Trial 3 finished with value: 0.6111942373903237 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 1 with value: 0.5305605413418171.\n",
      "[I 2025-05-31 14:21:58,249] Trial 4 finished with value: 0.5106516873398826 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5106516873398826.\n",
      "[I 2025-05-31 14:22:06,725] Trial 5 finished with value: 0.5798067039853426 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5106516873398826.\n",
      "[I 2025-05-31 14:22:14,597] Trial 6 finished with value: 0.5124356587149212 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5106516873398826.\n",
      "[I 2025-05-31 14:22:21,404] Trial 7 finished with value: 0.5170967724537302 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.5106516873398826.\n",
      "[I 2025-05-31 14:22:36,270] Trial 8 finished with value: 0.5216529952805841 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 4 with value: 0.5106516873398826.\n",
      "[I 2025-05-31 14:22:42,250] Trial 9 finished with value: 0.5873280715985433 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 4 with value: 0.5106516873398826.\n",
      "[I 2025-05-31 14:22:53,533] Trial 10 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:23:05,014] Trial 11 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:23:24,168] Trial 12 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:23:36,344] Trial 13 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:23:49,563] Trial 14 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:24:00,753] Trial 15 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:24:16,365] Trial 16 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:24:33,435] Trial 17 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:24:51,369] Trial 18 finished with value: 0.513301151239889 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:25:00,648] Trial 19 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:25:15,635] Trial 20 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:25:28,083] Trial 21 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:25:39,545] Trial 22 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:25:50,320] Trial 23 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:25:59,543] Trial 24 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:26:08,740] Trial 25 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:26:12,396] Trial 26 finished with value: 0.5273943594455862 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:26:22,149] Trial 27 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:26:38,026] Trial 28 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:26:46,124] Trial 29 finished with value: 0.5217411441222765 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:26:56,757] Trial 30 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:27:08,768] Trial 31 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:27:22,836] Trial 32 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:27:36,756] Trial 33 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:27:44,703] Trial 34 finished with value: 0.5336942347250166 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:27:54,446] Trial 35 finished with value: 0.5151170112174024 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:28:01,944] Trial 36 finished with value: 0.5315395984817506 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:28:07,226] Trial 37 finished with value: 0.5139695521361795 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:28:17,735] Trial 38 finished with value: 0.5232824151673032 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:28:21,643] Trial 39 finished with value: 0.5183325136434238 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:28:30,793] Trial 40 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:28:40,266] Trial 41 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:28:49,846] Trial 42 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:28:59,052] Trial 43 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:29:11,873] Trial 44 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:29:17,524] Trial 45 finished with value: 0.5816470984627108 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 0.1}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:29:27,857] Trial 46 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:29:42,153] Trial 47 finished with value: 0.5101957658354555 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:29:53,417] Trial 48 finished with value: 0.5102119506362056 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n",
      "[I 2025-05-31 14:30:04,725] Trial 49 finished with value: 0.5255144694125571 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 0}. Best is trial 10 with value: 0.5101957658354555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSLE score: 0.5102\n",
      "Best parameters: {'n_estimators': 1000, 'learning_rate': 0.05, 'num_leaves': 50, 'max_depth': -1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0}\n",
      "Validation - RMSE: 13.0273, MAE: 8.4533, RMSLE: 0.3373\n",
      "✓ Successfully tuned model for SEAFOOD\n",
      "\n",
      "============================================================\n",
      "HYPERPARAMETER TUNING COMPLETED\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Train LightGBM models with hyperparameter tuning for each family\n",
    "families = train_df['family'].unique()\n",
    "models = {}\n",
    "best_params_dict = {}\n",
    "tuning_results = {}\n",
    "\n",
    "print(f\"Starting hyperparameter tuning for {len(families)} families...\")\n",
    "print(\"This may take a while depending on the parameter grid size.\\n\")\n",
    "\n",
    "for i, family in enumerate(families, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Progress: {i}/{len(families)} - Training model for family: {family}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Filter the data for the current family\n",
    "    family_data = train[train['family'] == family].copy()\n",
    "    family_target = train_df[train_df['family'] == family]['sales'].copy()\n",
    "    \n",
    "    # Prepare features (remove date and family columns)\n",
    "    X_family = family_data.drop(columns=['date', 'family'])\n",
    "    y_family = family_target\n",
    "    \n",
    "    print(f\"Family {family} data shape: {X_family.shape}\")\n",
    "    \n",
    "    # Split data for hyperparameter tuning (80% for tuning, 20% for validation)\n",
    "    split_index = int(len(X_family) * 0.8)\n",
    "    X_tune = X_family[:split_index]\n",
    "    y_tune = y_family[:split_index]\n",
    "    X_val = X_family[split_index:]\n",
    "    y_val = y_family[split_index:]\n",
    "    \n",
    "    print(f\"Tuning set: {X_tune.shape}, Validation set: {X_val.shape}\")\n",
    "    \n",
    "    # Perform hyperparameter tuning\n",
    "    try:\n",
    "        best_model, best_params, best_score = optuna_tune_hyperparameters(\n",
    "            X_tune, y_tune, family, param_grid_small, cv_folds=3\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        best_params_dict[family] = best_params\n",
    "        tuning_results[family] = best_score\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        y_val_pred = best_model.predict(X_val)\n",
    "        y_val_pred = np.maximum(y_val_pred, 0)  # Ensure no negative predictions\n",
    "        \n",
    "        # Calculate evaluation metrics\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "        mae = mean_absolute_error(y_val, y_val_pred)\n",
    "        rmsle = rmsle_score(y_val, y_val_pred)\n",
    "        \n",
    "        print(f\"Validation - RMSE: {rmse:.4f}, MAE: {mae:.4f}, RMSLE: {rmsle:.4f}\")\n",
    "        print(f\"✓ Successfully tuned model for {family}\")\n",
    "        \n",
    "        # Store the tuned model (we'll retrain on full data later)\n",
    "        models[family] = best_model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error tuning model for {family}: {str(e)}\")\n",
    "        # Fallback to default parameters\n",
    "        default_model = lgb.LGBMRegressor(\n",
    "            objective='regression',\n",
    "            metric='rmse',\n",
    "            n_estimators=1000,\n",
    "            learning_rate=0.01,\n",
    "            num_leaves=31,\n",
    "            max_depth=-1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            force_row_wise=True\n",
    "        )\n",
    "        default_model.fit(X_tune, y_tune)\n",
    "        models[family] = default_model\n",
    "        best_params_dict[family] = 'default_params'\n",
    "        tuning_results[family] = None\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"HYPERPARAMETER TUNING COMPLETED\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22dd3fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== HYPERPARAMETER TUNING RESULTS SUMMARY ===\n",
      "--------------------------------------------------------------------------------\n",
      "Family                    Best RMSLE      Key Parameters                          \n",
      "--------------------------------------------------------------------------------\n",
      "AUTOMOTIVE                0.5186          {'n_estimators': 500, 'learning_rat...  \n",
      "BABY CARE                 0.2071          {'n_estimators': 500, 'learning_rat...  \n",
      "BEAUTY                    0.4395          {'n_estimators': 1000, 'learning_ra...  \n",
      "BEVERAGES                 1.0730          {'n_estimators': 1000, 'learning_ra...  \n",
      "BOOKS                     0.0604          {'n_estimators': 500, 'learning_rat...  \n",
      "BREAD/BAKERY              0.7929          {'n_estimators': 1000, 'learning_ra...  \n",
      "CELEBRATION               0.4537          {'n_estimators': 1000, 'learning_ra...  \n",
      "CLEANING                  1.0911          {'n_estimators': 1000, 'learning_ra...  \n",
      "DAIRY                     0.5142          {'n_estimators': 1000, 'learning_ra...  \n",
      "DELI                      0.7875          {'n_estimators': 1000, 'learning_ra...  \n",
      "EGGS                      0.7449          {'n_estimators': 1000, 'learning_ra...  \n",
      "FROZEN FOODS              0.4844          {'n_estimators': 1000, 'learning_ra...  \n",
      "GROCERY I                 1.1566          {'n_estimators': 500, 'learning_rat...  \n",
      "GROCERY II                0.5635          {'n_estimators': 1000, 'learning_ra...  \n",
      "HARDWARE                  0.4553          {'n_estimators': 500, 'learning_rat...  \n",
      "HOME AND KITCHEN I        0.5542          {'n_estimators': 500, 'learning_rat...  \n",
      "HOME AND KITCHEN II       0.4387          {'n_estimators': 500, 'learning_rat...  \n",
      "HOME APPLIANCES           0.2751          {'n_estimators': 500, 'learning_rat...  \n",
      "HOME CARE                 0.4731          {'n_estimators': 1000, 'learning_ra...  \n",
      "LADIESWEAR                0.3353          {'n_estimators': 1000, 'learning_ra...  \n",
      "LAWN AND GARDEN           0.4494          {'n_estimators': 1000, 'learning_ra...  \n",
      "LINGERIE                  0.5959          {'n_estimators': 500, 'learning_rat...  \n",
      "LIQUOR,WINE,BEER          0.8887          {'n_estimators': 1000, 'learning_ra...  \n",
      "MAGAZINES                 0.3660          {'n_estimators': 1000, 'learning_ra...  \n",
      "MEATS                     0.9965          {'n_estimators': 1000, 'learning_ra...  \n",
      "PERSONAL CARE             0.6865          {'n_estimators': 1000, 'learning_ra...  \n",
      "PET SUPPLIES              0.3505          {'n_estimators': 500, 'learning_rat...  \n",
      "PLAYERS AND ELECTRONICS   0.3973          {'n_estimators': 1000, 'learning_ra...  \n",
      "POULTRY                   0.8212          {'n_estimators': 500, 'learning_rat...  \n",
      "PREPARED FOODS            0.6353          {'n_estimators': 1000, 'learning_ra...  \n",
      "PRODUCE                   0.9187          {'n_estimators': 500, 'learning_rat...  \n",
      "SCHOOL AND OFFICE SUPPLI  0.3125          {'n_estimators': 500, 'learning_rat...  \n",
      "SEAFOOD                   0.5102          {'n_estimators': 1000, 'learning_ra...  \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Average RMSLE across all families: 0.5863\n",
      "Best performing family: BOOKS\n",
      "Worst performing family: GROCERY I\n"
     ]
    }
   ],
   "source": [
    "# Display tuning results summary\n",
    "print(\"\\n=== HYPERPARAMETER TUNING RESULTS SUMMARY ===\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Family':<25} {'Best RMSLE':<15} {'Key Parameters':<40}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for family in families:\n",
    "    best_score = tuning_results.get(family, 'N/A')\n",
    "    best_params = best_params_dict.get(family, 'N/A')\n",
    "    \n",
    "    if isinstance(best_score, float):\n",
    "        score_str = f\"{best_score:.4f}\"\n",
    "    else:\n",
    "        score_str = str(best_score)\n",
    "    \n",
    "    if isinstance(best_params, dict):\n",
    "        # Show only key parameters for readability\n",
    "        key_params = {k: v for k, v in best_params.items() if k in ['n_estimators', 'learning_rate', 'num_leaves']}\n",
    "        params_str = str(key_params)[:35] + '...' if len(str(key_params)) > 35 else str(key_params)\n",
    "    else:\n",
    "        params_str = str(best_params)\n",
    "    \n",
    "    print(f\"{family[:24]:<25} {score_str:<15} {params_str:<40}\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Calculate average RMSLE\n",
    "valid_scores = [score for score in tuning_results.values() if isinstance(score, float)]\n",
    "if valid_scores:\n",
    "    avg_rmsle = np.mean(valid_scores)\n",
    "    print(f\"\\nAverage RMSLE across all families: {avg_rmsle:.4f}\")\n",
    "    best_family = min(tuning_results.items(), key=lambda x: x[1] if isinstance(x[1], float) else float('inf'))[0]\n",
    "    worst_family = max(tuning_results.items(), key=lambda x: x[1] if isinstance(x[1], float) else 0)[0]\n",
    "    print(f\"Best performing family: {best_family}\")\n",
    "    print(f\"Worst performing family: {worst_family}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed67904c",
   "metadata": {},
   "source": [
    "## 5. Final Model Training on Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69a809b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RETRAINING MODELS WITH BEST PARAMETERS ON FULL DATASET ===\n",
      "This will train the final models using the entire training and validation data...\n",
      "\n",
      "Progress: 1/33 - Final training for family: AUTOMOTIVE\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 2/33 - Final training for family: BABY CARE\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 3/33 - Final training for family: BEAUTY\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 4/33 - Final training for family: BEVERAGES\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 5/33 - Final training for family: BOOKS\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 6/33 - Final training for family: BREAD/BAKERY\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 7/33 - Final training for family: CELEBRATION\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 8/33 - Final training for family: CLEANING\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 9/33 - Final training for family: DAIRY\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 10/33 - Final training for family: DELI\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 11/33 - Final training for family: EGGS\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 12/33 - Final training for family: FROZEN FOODS\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 13/33 - Final training for family: GROCERY I\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 14/33 - Final training for family: GROCERY II\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 15/33 - Final training for family: HARDWARE\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 16/33 - Final training for family: HOME AND KITCHEN I\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 17/33 - Final training for family: HOME AND KITCHEN II\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 18/33 - Final training for family: HOME APPLIANCES\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 19/33 - Final training for family: HOME CARE\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 20/33 - Final training for family: LADIESWEAR\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 21/33 - Final training for family: LAWN AND GARDEN\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 22/33 - Final training for family: LINGERIE\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 23/33 - Final training for family: LIQUOR,WINE,BEER\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 24/33 - Final training for family: MAGAZINES\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 25/33 - Final training for family: MEATS\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 26/33 - Final training for family: PERSONAL CARE\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 27/33 - Final training for family: PET SUPPLIES\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 28/33 - Final training for family: PLAYERS AND ELECTRONICS\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 29/33 - Final training for family: POULTRY\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 30/33 - Final training for family: PREPARED FOODS\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 31/33 - Final training for family: PRODUCE\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 32/33 - Final training for family: SCHOOL AND OFFICE SUPPLIES\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "Progress: 33/33 - Final training for family: SEAFOOD\n",
      "  ✓ Trained on 89316 samples with 47 features\n",
      "\n",
      "✓ Final training completed for all 33 families!\n"
     ]
    }
   ],
   "source": [
    "# Retrain models with best parameters on the full training dataset\n",
    "print(\"\\n=== RETRAINING MODELS WITH BEST PARAMETERS ON FULL DATASET ===\")\n",
    "print(\"This will train the final models using the entire training and validation data...\\n\")\n",
    "\n",
    "final_models = {}\n",
    "final_training_results = {}\n",
    "\n",
    "for i, family in enumerate(families, 1):\n",
    "    print(f\"Progress: {i}/{len(families)} - Final training for family: {family}\")\n",
    "    \n",
    "    # Filter the data for the current family\n",
    "    family_data = train[train['family'] == family].copy()\n",
    "    family_target = train_df[train_df['family'] == family]['sales'].copy()\n",
    "    \n",
    "    # Prepare features (use full dataset)\n",
    "    X_family_full = family_data.drop(columns=['date', 'family'])\n",
    "    y_family_full = family_target\n",
    "    \n",
    "    # Get best parameters for this family\n",
    "    best_params = best_params_dict.get(family, {})\n",
    "    \n",
    "    if isinstance(best_params, dict):\n",
    "        # Create model with best parameters\n",
    "        final_model = lgb.LGBMRegressor(\n",
    "            objective='regression',\n",
    "            metric='rmse',\n",
    "            random_state=42,\n",
    "            force_row_wise=True,\n",
    "            **best_params\n",
    "        )\n",
    "    else:\n",
    "        # Use default parameters if tuning failed\n",
    "        final_model = lgb.LGBMRegressor(\n",
    "            objective='regression',\n",
    "            metric='rmse',\n",
    "            n_estimators=1000,\n",
    "            learning_rate=0.01,\n",
    "            num_leaves=31,\n",
    "            max_depth=-1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            force_row_wise=True\n",
    "        )\n",
    "    \n",
    "    # Train the final model on the full dataset\n",
    "    final_model.fit(X_family_full, y_family_full)\n",
    "    \n",
    "    # Store the final model\n",
    "    final_models[family] = final_model\n",
    "    \n",
    "    # Store training info\n",
    "    final_training_results[family] = {\n",
    "        'training_samples': len(X_family_full),\n",
    "        'features': X_family_full.shape[1],\n",
    "        'best_params': best_params\n",
    "    }\n",
    "    \n",
    "    print(f\"  ✓ Trained on {len(X_family_full)} samples with {X_family_full.shape[1]} features\")\n",
    "\n",
    "print(f\"\\n✓ Final training completed for all {len(families)} families!\")\n",
    "\n",
    "# Update the models dictionary to use final models\n",
    "models = final_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56d4b1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SAVING TRAINED MODELS ===\n",
      "  ✓ Saved model for AUTOMOTIVE: lgb_model_AUTOMOTIVE_20250531_143548.pkl\n",
      "  ✓ Saved model for BABY CARE: lgb_model_BABY_CARE_20250531_143548.pkl\n",
      "  ✓ Saved model for BEAUTY: lgb_model_BEAUTY_20250531_143548.pkl\n",
      "  ✓ Saved model for BEVERAGES: lgb_model_BEVERAGES_20250531_143548.pkl\n",
      "  ✓ Saved model for BOOKS: lgb_model_BOOKS_20250531_143548.pkl\n",
      "  ✓ Saved model for BREAD/BAKERY: lgb_model_BREAD_BAKERY_20250531_143548.pkl\n",
      "  ✓ Saved model for CELEBRATION: lgb_model_CELEBRATION_20250531_143548.pkl\n",
      "  ✓ Saved model for CLEANING: lgb_model_CLEANING_20250531_143548.pkl\n",
      "  ✓ Saved model for DAIRY: lgb_model_DAIRY_20250531_143548.pkl\n",
      "  ✓ Saved model for DELI: lgb_model_DELI_20250531_143548.pkl\n",
      "  ✓ Saved model for EGGS: lgb_model_EGGS_20250531_143548.pkl\n",
      "  ✓ Saved model for FROZEN FOODS: lgb_model_FROZEN_FOODS_20250531_143548.pkl\n",
      "  ✓ Saved model for GROCERY I: lgb_model_GROCERY_I_20250531_143548.pkl\n",
      "  ✓ Saved model for GROCERY II: lgb_model_GROCERY_II_20250531_143548.pkl\n",
      "  ✓ Saved model for HARDWARE: lgb_model_HARDWARE_20250531_143548.pkl\n",
      "  ✓ Saved model for HOME AND KITCHEN I: lgb_model_HOME_AND_KITCHEN_I_20250531_143548.pkl\n",
      "  ✓ Saved model for HOME AND KITCHEN II: lgb_model_HOME_AND_KITCHEN_II_20250531_143548.pkl\n",
      "  ✓ Saved model for HOME APPLIANCES: lgb_model_HOME_APPLIANCES_20250531_143548.pkl\n",
      "  ✓ Saved model for HOME CARE: lgb_model_HOME_CARE_20250531_143548.pkl\n",
      "  ✓ Saved model for LADIESWEAR: lgb_model_LADIESWEAR_20250531_143548.pkl\n",
      "  ✓ Saved model for LAWN AND GARDEN: lgb_model_LAWN_AND_GARDEN_20250531_143548.pkl\n",
      "  ✓ Saved model for LINGERIE: lgb_model_LINGERIE_20250531_143548.pkl\n",
      "  ✓ Saved model for LIQUOR,WINE,BEER: lgb_model_LIQUOR,WINE,BEER_20250531_143548.pkl\n",
      "  ✓ Saved model for MAGAZINES: lgb_model_MAGAZINES_20250531_143548.pkl\n",
      "  ✓ Saved model for MEATS: lgb_model_MEATS_20250531_143548.pkl\n",
      "  ✓ Saved model for PERSONAL CARE: lgb_model_PERSONAL_CARE_20250531_143548.pkl\n",
      "  ✓ Saved model for PET SUPPLIES: lgb_model_PET_SUPPLIES_20250531_143548.pkl\n",
      "  ✓ Saved model for PLAYERS AND ELECTRONICS: lgb_model_PLAYERS_AND_ELECTRONICS_20250531_143548.pkl\n",
      "  ✓ Saved model for POULTRY: lgb_model_POULTRY_20250531_143548.pkl\n",
      "  ✓ Saved model for PREPARED FOODS: lgb_model_PREPARED_FOODS_20250531_143548.pkl\n",
      "  ✓ Saved model for PRODUCE: lgb_model_PRODUCE_20250531_143548.pkl\n",
      "  ✓ Saved model for SCHOOL AND OFFICE SUPPLIES: lgb_model_SCHOOL_AND_OFFICE_SUPPLIES_20250531_143548.pkl\n",
      "  ✓ Saved model for SEAFOOD: lgb_model_SEAFOOD_20250531_143548.pkl\n",
      "\n",
      "✓ Models metadata saved: models_metadata_20250531_143548.pkl\n",
      "✓ All models saved in: ../models\n",
      "✓ Best parameters saved as JSON: best_parameters_20250531_143548.json\n"
     ]
    }
   ],
   "source": [
    "# Save the trained models and metadata\n",
    "print(\"\\n=== SAVING TRAINED MODELS ===\")\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "models_dir = '../models'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Create timestamp for model versioning\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Save individual models and metadata\n",
    "saved_models_info = {}\n",
    "\n",
    "for family in families:\n",
    "    # Clean family name for filename\n",
    "    clean_family_name = family.replace('/', '_').replace(' ', '_').replace('&', 'and')\n",
    "    \n",
    "    # Save model\n",
    "    model_filename = f'lgb_model_{clean_family_name}_{timestamp}.pkl'\n",
    "    model_path = os.path.join(models_dir, model_filename)\n",
    "    joblib.dump(models[family], model_path)\n",
    "    \n",
    "    saved_models_info[family] = {\n",
    "        'model_path': model_path,\n",
    "        'best_params': best_params_dict.get(family, 'default'),\n",
    "        'tuning_score': tuning_results.get(family, 'N/A'),\n",
    "        'training_samples': final_training_results[family]['training_samples']\n",
    "    }\n",
    "    \n",
    "    print(f\"  ✓ Saved model for {family[:30]}: {model_filename}\")\n",
    "\n",
    "# Save models metadata\n",
    "metadata_filename = f'models_metadata_{timestamp}.pkl'\n",
    "metadata_path = os.path.join(models_dir, metadata_filename)\n",
    "joblib.dump(saved_models_info, metadata_path)\n",
    "\n",
    "print(f\"\\n✓ Models metadata saved: {metadata_filename}\")\n",
    "print(f\"✓ All models saved in: {models_dir}\")\n",
    "\n",
    "# Also save best parameters as JSON for easy inspection\n",
    "import json\n",
    "params_filename = f'best_parameters_{timestamp}.json'\n",
    "params_path = os.path.join(models_dir, params_filename)\n",
    "with open(params_path, 'w') as f:\n",
    "    # Convert numpy types to native Python types for JSON serialization\n",
    "    json_params = {}\n",
    "    for family, params in best_params_dict.items():\n",
    "        if isinstance(params, dict):\n",
    "            json_params[family] = {k: int(v) if isinstance(v, np.integer) else float(v) if isinstance(v, np.floating) else v for k, v in params.items()}\n",
    "        else:\n",
    "            json_params[family] = str(params)\n",
    "    json.dump(json_params, f, indent=2)\n",
    "\n",
    "print(f\"✓ Best parameters saved as JSON: {params_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1f6d0c",
   "metadata": {},
   "source": [
    "## 6. Generate Predictions for Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a513f2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions for test set...\n",
      "Predicting for family: AUTOMOTIVE\n",
      "Generated 864 predictions for AUTOMOTIVE\n",
      "Predicting for family: BABY CARE\n",
      "Generated 864 predictions for BABY CARE\n",
      "Predicting for family: BEAUTY\n",
      "Generated 864 predictions for BEAUTY\n",
      "Predicting for family: BEVERAGES\n",
      "Generated 864 predictions for BEVERAGES\n",
      "Predicting for family: BOOKS\n",
      "Generated 864 predictions for BOOKS\n",
      "Predicting for family: BREAD/BAKERY\n",
      "Generated 864 predictions for BREAD/BAKERY\n",
      "Predicting for family: CELEBRATION\n",
      "Generated 864 predictions for CELEBRATION\n",
      "Predicting for family: CLEANING\n",
      "Generated 864 predictions for CLEANING\n",
      "Predicting for family: DAIRY\n",
      "Generated 864 predictions for DAIRY\n",
      "Predicting for family: DELI\n",
      "Generated 864 predictions for DELI\n",
      "Predicting for family: EGGS\n",
      "Generated 864 predictions for EGGS\n",
      "Predicting for family: FROZEN FOODS\n",
      "Generated 864 predictions for FROZEN FOODS\n",
      "Predicting for family: GROCERY I\n",
      "Generated 864 predictions for GROCERY I\n",
      "Predicting for family: GROCERY II\n",
      "Generated 864 predictions for GROCERY II\n",
      "Predicting for family: HARDWARE\n",
      "Generated 864 predictions for HARDWARE\n",
      "Predicting for family: HOME AND KITCHEN I\n",
      "Generated 864 predictions for HOME AND KITCHEN I\n",
      "Predicting for family: HOME AND KITCHEN II\n",
      "Generated 864 predictions for HOME AND KITCHEN II\n",
      "Predicting for family: HOME APPLIANCES\n",
      "Generated 864 predictions for HOME APPLIANCES\n",
      "Predicting for family: HOME CARE\n",
      "Generated 864 predictions for HOME CARE\n",
      "Predicting for family: LADIESWEAR\n",
      "Generated 864 predictions for LADIESWEAR\n",
      "Predicting for family: LAWN AND GARDEN\n",
      "Generated 864 predictions for LAWN AND GARDEN\n",
      "Predicting for family: LINGERIE\n",
      "Generated 864 predictions for LINGERIE\n",
      "Predicting for family: LIQUOR,WINE,BEER\n",
      "Generated 864 predictions for LIQUOR,WINE,BEER\n",
      "Predicting for family: MAGAZINES\n",
      "Generated 864 predictions for MAGAZINES\n",
      "Predicting for family: MEATS\n",
      "Generated 864 predictions for MEATS\n",
      "Predicting for family: PERSONAL CARE\n",
      "Generated 864 predictions for PERSONAL CARE\n",
      "Predicting for family: PET SUPPLIES\n",
      "Generated 864 predictions for PET SUPPLIES\n",
      "Predicting for family: PLAYERS AND ELECTRONICS\n",
      "Generated 864 predictions for PLAYERS AND ELECTRONICS\n",
      "Predicting for family: POULTRY\n",
      "Generated 864 predictions for POULTRY\n",
      "Predicting for family: PREPARED FOODS\n",
      "Generated 864 predictions for PREPARED FOODS\n",
      "Predicting for family: PRODUCE\n",
      "Generated 864 predictions for PRODUCE\n",
      "Predicting for family: SCHOOL AND OFFICE SUPPLIES\n",
      "Generated 864 predictions for SCHOOL AND OFFICE SUPPLIES\n",
      "Predicting for family: SEAFOOD\n",
      "Generated 864 predictions for SEAFOOD\n",
      "Total predictions generated: 28512\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for test set\n",
    "print(\"Generating predictions for test set...\")\n",
    "\n",
    "# Initialize predictions array\n",
    "test_predictions = []\n",
    "test_ids = []\n",
    "\n",
    "# Generate predictions for each family\n",
    "for family in families:\n",
    "    print(f\"Predicting for family: {family}\")\n",
    "    \n",
    "    # Filter test data for current family\n",
    "    family_test_data = test[test['family'] == family].copy()\n",
    "    \n",
    "    if len(family_test_data) > 0:\n",
    "        # Prepare features (remove date and family columns)\n",
    "        X_test_family = family_test_data.drop(columns=['date', 'family'])\n",
    "        \n",
    "        # Get the trained model for this family\n",
    "        model = models[family]\n",
    "        \n",
    "        # Generate predictions\n",
    "        family_predictions = model.predict(X_test_family)\n",
    "        \n",
    "        # Ensure no negative predictions\n",
    "        family_predictions = np.maximum(family_predictions, 0)\n",
    "        \n",
    "        # Store predictions and corresponding IDs\n",
    "        test_predictions.extend(family_predictions)\n",
    "        \n",
    "        # Get corresponding IDs from test_df\n",
    "        family_ids = test_df[test_df['family'] == family]['id'].values\n",
    "        test_ids.extend(family_ids)\n",
    "        \n",
    "        print(f\"Generated {len(family_predictions)} predictions for {family}\")\n",
    "\n",
    "print(f\"Total predictions generated: {len(test_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19f42aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission shape: (28512, 2)\n",
      "\n",
      "First few predictions:\n",
      "        id        sales\n",
      "0  3000888     3.726486\n",
      "1  3000889     0.002220\n",
      "2  3000890     5.926308\n",
      "3  3000891  2002.855071\n",
      "4  3000892     0.001093\n",
      "5  3000893   355.498043\n",
      "6  3000894     7.830936\n",
      "7  3000895   715.918517\n",
      "8  3000896   726.602182\n",
      "9  3000897   136.533694\n",
      "\n",
      "Last few predictions:\n",
      "            id        sales\n",
      "28502  3029390     9.912054\n",
      "28503  3029391   476.483615\n",
      "28504  3029392   526.104009\n",
      "28505  3029393     5.311023\n",
      "28506  3029394     5.982623\n",
      "28507  3029395   411.933115\n",
      "28508  3029396   148.108294\n",
      "28509  3029397  2141.166371\n",
      "28510  3029398   119.941219\n",
      "28511  3029399    14.793278\n",
      "\n",
      "Prediction statistics:\n",
      "Min: 0.0000\n",
      "Max: 11780.7429\n",
      "Mean: 434.7197\n",
      "Median: 28.2085\n"
     ]
    }
   ],
   "source": [
    "# Create submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'sales': test_predictions\n",
    "})\n",
    "\n",
    "# Sort by id to ensure proper order\n",
    "submission_df = submission_df.sort_values('id').reset_index(drop=True)\n",
    "\n",
    "print(f\"Submission shape: {submission_df.shape}\")\n",
    "print(\"\\nFirst few predictions:\")\n",
    "print(submission_df.head(10))\n",
    "\n",
    "print(\"\\nLast few predictions:\")\n",
    "print(submission_df.tail(10))\n",
    "\n",
    "print(f\"\\nPrediction statistics:\")\n",
    "print(f\"Min: {submission_df['sales'].min():.4f}\")\n",
    "print(f\"Max: {submission_df['sales'].max():.4f}\")\n",
    "print(f\"Mean: {submission_df['sales'].mean():.4f}\")\n",
    "print(f\"Median: {submission_df['sales'].median():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ec20d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved as: ../data/submission/traditional_submission_tuned_20250531_143548.csv\n",
      "File contains 28512 predictions\n",
      "\n",
      "Verifying submission file...\n",
      "Loaded file shape: (28512, 2)\n",
      "Columns: ['id', 'sales']\n",
      "No missing values: True\n",
      "All IDs unique: True\n"
     ]
    }
   ],
   "source": [
    "# Save submission file\n",
    "submission_filename = f'../data/submission/traditional_submission_tuned_{timestamp}.csv'\n",
    "submission_df.to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"Submission file saved as: {submission_filename}\")\n",
    "print(f\"File contains {len(submission_df)} predictions\")\n",
    "\n",
    "# Verify the submission file\n",
    "print(\"\\nVerifying submission file...\")\n",
    "verify_df = pd.read_csv(submission_filename)\n",
    "print(f\"Loaded file shape: {verify_df.shape}\")\n",
    "print(f\"Columns: {list(verify_df.columns)}\")\n",
    "print(f\"No missing values: {verify_df.isnull().sum().sum() == 0}\")\n",
    "print(f\"All IDs unique: {len(verify_df['id'].unique()) == len(verify_df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
