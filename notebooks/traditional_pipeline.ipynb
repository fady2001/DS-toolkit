{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f5df1e",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cbdf18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Define custom RMSLE function to handle zero values\n",
    "def rmsle_score(y_true, y_pred):\n",
    "    \"\"\"Calculate RMSLE with handling for zero and negative values\"\"\"\n",
    "    # Add small epsilon to avoid log(0) and ensure positive values\n",
    "    epsilon = 1e-15\n",
    "    y_true_log = np.log1p(np.maximum(y_true, epsilon))\n",
    "    y_pred_log = np.log1p(np.maximum(y_pred, epsilon))\n",
    "    return np.sqrt(mean_squared_error(y_true_log, y_pred_log))\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d493a80",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Initial Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96fc43a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/interim/traditional_final_train.csv', parse_dates=['date'])\n",
    "test_df = pd.read_csv('../data/interim/traditional_final_test.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0453ec8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns in the dataset:\n",
      "- family\n",
      "- city\n",
      "- state\n",
      "- type\n"
     ]
    }
   ],
   "source": [
    "# print categorial columns\n",
    "print(\"Categorical columns in the dataset:\")\n",
    "for col in train_df.select_dtypes(include=['object']).columns:\n",
    "    print(f\"- {col}\")\n",
    "    \n",
    "# Encode categorical features\n",
    "categorical_cols = train_df.select_dtypes(include=['object']).columns\n",
    "encoders = {}\n",
    "for col in categorical_cols:\n",
    "    encoder = OrdinalEncoder()\n",
    "    train_df[col+\"_encoded\"] = encoder.fit_transform(train_df[[col]])\n",
    "    encoders[col] = encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7d5140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_cols:\n",
    "    test_df[col+\"_encoded\"] = encoders[col].transform(test_df[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f624adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'date', 'store_nbr', 'family', 'sales', 'onpromotion', 'year',\n",
       "       'month', 'day', 'dayofweek', 'weekofyear', 'day_of_year', 'is_weekend',\n",
       "       'is_month_start', 'is_month_end', 'is_quarter_start', 'is_quarter_end',\n",
       "       'is_payday', 'days_since_payday', 'days_until_payday',\n",
       "       'sales_rolling_mean_7', 'sales_rolling_std_7', 'sales_rolling_max_7',\n",
       "       'sales_rolling_min_7', 'sales_rolling_mean_14', 'sales_rolling_std_14',\n",
       "       'sales_rolling_max_14', 'sales_rolling_min_14', 'sales_rolling_mean_30',\n",
       "       'sales_rolling_std_30', 'sales_rolling_max_30', 'sales_rolling_min_30',\n",
       "       'sales_lag_1', 'sales_lag_7', 'sales_lag_14', 'sales_lag_30',\n",
       "       'is_national_holiday', 'is_regional_holiday', 'is_local_holiday',\n",
       "       'is_additional_holiday', 'is_working_day', 'is_event', 'is_bridge_day',\n",
       "       'is_transferred_day', 'dcoilwtico', 'city', 'state', 'type', 'cluster',\n",
       "       'transactions', 'family_encoded', 'city_encoded', 'state_encoded',\n",
       "       'type_encoded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "697e82ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['date', 'store_nbr',\"family\",'onpromotion', 'year',\n",
    "       'month', 'day', 'dayofweek', 'weekofyear', 'day_of_year', 'is_weekend',\n",
    "       'is_month_start', 'is_month_end', 'is_quarter_start', 'is_quarter_end',\n",
    "       'is_payday', 'days_since_payday', 'days_until_payday',\n",
    "       'is_national_holiday', 'is_regional_holiday', 'is_local_holiday',\n",
    "       'is_additional_holiday', 'is_working_day', 'is_event', 'is_bridge_day',\n",
    "       'is_transferred_day', 'dcoilwtico', 'cluster',\n",
    "       'transactions', 'family_encoded', 'city_encoded', 'state_encoded',\n",
    "       'type_encoded','sales_rolling_mean_7', 'sales_rolling_std_7', 'sales_rolling_max_7',\n",
    "       'sales_rolling_min_7', 'sales_rolling_mean_14', 'sales_rolling_std_14',\n",
    "       'sales_rolling_max_14', 'sales_rolling_min_14', 'sales_rolling_mean_30',\n",
    "       'sales_rolling_std_30', 'sales_rolling_max_30', 'sales_rolling_min_30',\n",
    "       'sales_lag_1', 'sales_lag_7', 'sales_lag_14', 'sales_lag_30',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e21a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df[feature_cols]\n",
    "test = test_df[feature_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a150a73a",
   "metadata": {},
   "source": [
    "## 6. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5301e1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for family: AUTOMOTIVE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"c:\\Users\\Fady Adel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Fady Adel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Fady Adel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\Fady Adel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2918\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 4.978027\n",
      "Family AUTOMOTIVE - RMSE: 4.9210, MAE: 3.4599, RMSLE: 0.4302\n",
      "Training model for family: BABY CARE\n",
      "[LightGBM] [Info] Total Bins 2189\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 45\n",
      "[LightGBM] [Info] Start training from score 0.136119\n",
      "Family BABY CARE - RMSE: 0.1688, MAE: 0.0258, RMSLE: 0.0748\n",
      "Training model for family: BEAUTY\n",
      "[LightGBM] [Info] Total Bins 2761\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 2.816716\n",
      "Family BEAUTY - RMSE: 3.3232, MAE: 2.1125, RMSLE: 0.3843\n",
      "Training model for family: BEVERAGES\n",
      "[LightGBM] [Info] Total Bins 5214\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 1977.060404\n",
      "Family BEVERAGES - RMSE: 1057.9469, MAE: 651.5660, RMSLE: 1.6554\n",
      "Training model for family: BOOKS\n",
      "[LightGBM] [Info] Total Bins 2146\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 44\n",
      "[LightGBM] [Info] Start training from score 0.047766\n",
      "Family BOOKS - RMSE: 0.5766, MAE: 0.1080, RMSLE: 0.1548\n",
      "Training model for family: BREAD/BAKERY\n",
      "[LightGBM] [Info] Total Bins 5214\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 396.906980\n",
      "Family BREAD/BAKERY - RMSE: 143.8185, MAE: 92.1900, RMSLE: 1.1046\n",
      "Training model for family: CELEBRATION\n",
      "[LightGBM] [Info] Total Bins 3604\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 7.059117\n",
      "Family CELEBRATION - RMSE: 12.3967, MAE: 4.6886, RMSLE: 0.4621\n",
      "Training model for family: CLEANING\n",
      "[LightGBM] [Info] Total Bins 5188\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 930.107415\n",
      "Family CLEANING - RMSE: 339.4020, MAE: 223.0714, RMSLE: 1.3874\n",
      "Training model for family: DAIRY\n",
      "[LightGBM] [Info] Total Bins 5275\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 571.384678\n",
      "Family DAIRY - RMSE: 254.2247, MAE: 162.7017, RMSLE: 1.2251\n",
      "Training model for family: DELI\n",
      "[LightGBM] [Info] Total Bins 5194\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 224.746285\n",
      "Family DELI - RMSE: 89.5800, MAE: 55.1630, RMSLE: 0.9521\n",
      "Training model for family: EGGS\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 154.027557\n",
      "Family EGGS - RMSE: 53.1334, MAE: 34.7659, RMSLE: 0.8766\n",
      "Training model for family: FROZEN FOODS\n",
      "[LightGBM] [Info] Total Bins 5150\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 117.620470\n",
      "Family FROZEN FOODS - RMSE: 256.8392, MAE: 68.9446, RMSLE: 0.9369\n",
      "Training model for family: GROCERY I\n",
      "[LightGBM] [Info] Total Bins 5278\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 3225.102962\n",
      "Family GROCERY I - RMSE: 1533.8922, MAE: 875.7725, RMSLE: 1.8132\n",
      "Training model for family: GROCERY II\n",
      "[LightGBM] [Info] Total Bins 4034\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 16.365588\n",
      "Family GROCERY II - RMSE: 18.9914, MAE: 11.6415, RMSLE: 0.5010\n",
      "Training model for family: HARDWARE\n",
      "[LightGBM] [Info] Total Bins 2254\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 1.073098\n",
      "Family HARDWARE - RMSE: 1.4384, MAE: 0.9641, RMSLE: 0.4997\n",
      "Training model for family: HOME AND KITCHEN I\n",
      "[LightGBM] [Info] Total Bins 4515\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 17.345771\n",
      "Family HOME AND KITCHEN I - RMSE: 40.8379, MAE: 14.7142, RMSLE: 0.6887\n",
      "Training model for family: HOME AND KITCHEN II\n",
      "[LightGBM] [Info] Total Bins 4442\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 13.462660\n",
      "Family HOME AND KITCHEN II - RMSE: 32.0213, MAE: 11.4019, RMSLE: 0.5793\n",
      "Training model for family: HOME APPLIANCES\n",
      "[LightGBM] [Info] Total Bins 2072\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 44\n",
      "[LightGBM] [Info] Start training from score 0.346820\n",
      "Family HOME APPLIANCES - RMSE: 0.9759, MAE: 0.6114, RMSLE: 0.3986\n",
      "Training model for family: HOME CARE\n",
      "[LightGBM] [Info] Total Bins 5144\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 151.857695\n",
      "Family HOME CARE - RMSE: 102.3622, MAE: 53.5474, RMSLE: 1.4979\n",
      "Training model for family: LADIESWEAR\n",
      "[LightGBM] [Info] Total Bins 3592\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 6.247565\n",
      "Family LADIESWEAR - RMSE: 6.1547, MAE: 3.5040, RMSLE: 0.4802\n",
      "Training model for family: LAWN AND GARDEN\n",
      "[LightGBM] [Info] Total Bins 3587\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 5.058081\n",
      "Family LAWN AND GARDEN - RMSE: 9.0893, MAE: 3.9403, RMSLE: 0.5641\n",
      "Training model for family: LINGERIE\n",
      "[LightGBM] [Info] Total Bins 3309\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 7.264275\n",
      "Family LINGERIE - RMSE: 11.1490, MAE: 3.3669, RMSLE: 0.6493\n",
      "Training model for family: LIQUOR,WINE,BEER\n",
      "[LightGBM] [Info] Total Bins 4763\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 72.954739\n",
      "Family LIQUOR,WINE,BEER - RMSE: 67.4801, MAE: 31.4909, RMSLE: 1.1421\n",
      "Training model for family: MAGAZINES\n",
      "[LightGBM] [Info] Total Bins 3066\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 2.377442\n",
      "Family MAGAZINES - RMSE: 3.3941, MAE: 1.8366, RMSLE: 0.3925\n",
      "Training model for family: MEATS\n",
      "[LightGBM] [Info] Total Bins 5175\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 259.830509\n",
      "Family MEATS - RMSE: 216.8432, MAE: 115.0178, RMSLE: 1.0499\n",
      "Training model for family: PERSONAL CARE\n",
      "[LightGBM] [Info] Total Bins 5153\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 227.894671\n",
      "Family PERSONAL CARE - RMSE: 165.0356, MAE: 82.8568, RMSLE: 0.9631\n",
      "Training model for family: PET SUPPLIES\n",
      "[LightGBM] [Info] Total Bins 2899\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 2.626840\n",
      "Family PET SUPPLIES - RMSE: 5.2988, MAE: 2.6333, RMSLE: 0.3611\n",
      "Training model for family: PLAYERS AND ELECTRONICS\n",
      "[LightGBM] [Info] Total Bins 3164\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 4.531266\n",
      "Family PLAYERS AND ELECTRONICS - RMSE: 7.3559, MAE: 3.6732, RMSLE: 0.4137\n",
      "Training model for family: POULTRY\n",
      "[LightGBM] [Info] Total Bins 5167\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 259.971268\n",
      "Family POULTRY - RMSE: 260.8669, MAE: 136.4076, RMSLE: 1.0286\n",
      "Training model for family: PREPARED FOODS\n",
      "[LightGBM] [Info] Total Bins 5134\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 74.770455\n",
      "Family PREPARED FOODS - RMSE: 38.7589, MAE: 27.1126, RMSLE: 0.6564\n",
      "Training model for family: PRODUCE\n",
      "[LightGBM] [Info] Total Bins 5365\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 1036.977075\n",
      "Family PRODUCE - RMSE: 835.9126, MAE: 436.2235, RMSLE: 2.0913\n",
      "Training model for family: SCHOOL AND OFFICE SUPPLIES\n",
      "[LightGBM] [Info] Total Bins 3539\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 1.311874\n",
      "Family SCHOOL AND OFFICE SUPPLIES - RMSE: 28.6107, MAE: 4.5865, RMSLE: 0.4259\n",
      "Training model for family: SEAFOOD\n",
      "[LightGBM] [Info] Total Bins 5127\n",
      "[LightGBM] [Info] Number of data points in the train set: 71452, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 15.125567\n",
      "Family SEAFOOD - RMSE: 13.6090, MAE: 9.0473, RMSLE: 0.4603\n"
     ]
    }
   ],
   "source": [
    "# train a LightGBM model for each family\n",
    "families = train_df['family'].unique()\n",
    "models = {}\n",
    "for family in families:\n",
    "    print(f\"Training model for family: {family}\")\n",
    "    # Filter the data for the current family\n",
    "    family_data = train[train['family'] == family]\n",
    "    # Define features and target\n",
    "    X_family_train = family_data.drop(columns=['family'])\n",
    "    y_family_train = train_df[train_df['family'] == family]['sales']\n",
    "    # split the data into training and validation sets by 0.8 ratio\n",
    "    split_index = int(len(X_family_train) * 0.8)\n",
    "    X_family_train, X_family_val = X_family_train[:split_index], X_family_train[split_index:]\n",
    "    y_family_train, y_family_val = y_family_train[:split_index], y_family_train[split_index:]\n",
    "    # Print the shape of the training and validation sets\n",
    "    X_family_train.drop(columns=['date'], inplace=True)\n",
    "    X_family_val.drop(columns=['date'], inplace=True)\n",
    "    # Define the model\n",
    "    lgb_model = lgb.LGBMRegressor(\n",
    "        objective='regression',\n",
    "        metric='rmse',  # Changed from 'rmsle' to 'rmse' to avoid issues\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.01,\n",
    "        num_leaves=31,\n",
    "        max_depth=-1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        force_row_wise=True\n",
    "    )\n",
    "    \n",
    "    # Fit the model\n",
    "    lgb_model.fit(X_family_train, y_family_train)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    y_family_pred = lgb_model.predict(X_family_val)\n",
    "    # Ensure no negative predictions\n",
    "    y_family_pred = np.maximum(y_family_pred, 0)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_family_val, y_family_pred))\n",
    "    mae = mean_absolute_error(y_family_val, y_family_pred)\n",
    "    rmsle = rmsle_score(y_family_val, y_family_pred)  # Use custom RMSLE function\n",
    "\n",
    "    print(f\"Family {family} - RMSE: {rmse:.4f}, MAE: {mae:.4f}, RMSLE: {rmsle:.4f}\")\n",
    "    \n",
    "    # Store the model\n",
    "    models[family] = lgb_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def51385",
   "metadata": {},
   "source": [
    "## 10. Generate Predictions for Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c020025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions for test set...\n",
      "Predicting for family: AUTOMOTIVE\n",
      "Generated 864 predictions for AUTOMOTIVE\n",
      "Predicting for family: BABY CARE\n",
      "Generated 864 predictions for BABY CARE\n",
      "Predicting for family: BEAUTY\n",
      "Generated 864 predictions for BEAUTY\n",
      "Predicting for family: BEVERAGES\n",
      "Generated 864 predictions for BEVERAGES\n",
      "Predicting for family: BOOKS\n",
      "Generated 864 predictions for BOOKS\n",
      "Predicting for family: BREAD/BAKERY\n",
      "Generated 864 predictions for BREAD/BAKERY\n",
      "Predicting for family: CELEBRATION\n",
      "Generated 864 predictions for CELEBRATION\n",
      "Predicting for family: CLEANING\n",
      "Generated 864 predictions for CLEANING\n",
      "Predicting for family: DAIRY\n",
      "Generated 864 predictions for DAIRY\n",
      "Predicting for family: DELI\n",
      "Generated 864 predictions for DELI\n",
      "Predicting for family: EGGS\n",
      "Generated 864 predictions for EGGS\n",
      "Predicting for family: FROZEN FOODS\n",
      "Generated 864 predictions for FROZEN FOODS\n",
      "Predicting for family: GROCERY I\n",
      "Generated 864 predictions for GROCERY I\n",
      "Predicting for family: GROCERY II\n",
      "Generated 864 predictions for GROCERY II\n",
      "Predicting for family: HARDWARE\n",
      "Generated 864 predictions for HARDWARE\n",
      "Predicting for family: HOME AND KITCHEN I\n",
      "Generated 864 predictions for HOME AND KITCHEN I\n",
      "Predicting for family: HOME AND KITCHEN II\n",
      "Generated 864 predictions for HOME AND KITCHEN II\n",
      "Predicting for family: HOME APPLIANCES\n",
      "Generated 864 predictions for HOME APPLIANCES\n",
      "Predicting for family: HOME CARE\n",
      "Generated 864 predictions for HOME CARE\n",
      "Predicting for family: LADIESWEAR\n",
      "Generated 864 predictions for LADIESWEAR\n",
      "Predicting for family: LAWN AND GARDEN\n",
      "Generated 864 predictions for LAWN AND GARDEN\n",
      "Predicting for family: LINGERIE\n",
      "Generated 864 predictions for LINGERIE\n",
      "Predicting for family: LIQUOR,WINE,BEER\n",
      "Generated 864 predictions for LIQUOR,WINE,BEER\n",
      "Predicting for family: MAGAZINES\n",
      "Generated 864 predictions for MAGAZINES\n",
      "Predicting for family: MEATS\n",
      "Generated 864 predictions for MEATS\n",
      "Predicting for family: PERSONAL CARE\n",
      "Generated 864 predictions for PERSONAL CARE\n",
      "Predicting for family: PET SUPPLIES\n",
      "Generated 864 predictions for PET SUPPLIES\n",
      "Predicting for family: PLAYERS AND ELECTRONICS\n",
      "Generated 864 predictions for PLAYERS AND ELECTRONICS\n",
      "Predicting for family: POULTRY\n",
      "Generated 864 predictions for POULTRY\n",
      "Predicting for family: PREPARED FOODS\n",
      "Generated 864 predictions for PREPARED FOODS\n",
      "Predicting for family: PRODUCE\n",
      "Generated 864 predictions for PRODUCE\n",
      "Predicting for family: SCHOOL AND OFFICE SUPPLIES\n",
      "Generated 864 predictions for SCHOOL AND OFFICE SUPPLIES\n",
      "Predicting for family: SEAFOOD\n",
      "Generated 864 predictions for SEAFOOD\n",
      "Total predictions generated: 28512\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for test set\n",
    "print(\"Generating predictions for test set...\")\n",
    "\n",
    "# Initialize predictions array\n",
    "test_predictions = []\n",
    "test_ids = []\n",
    "\n",
    "# Generate predictions for each family\n",
    "for family in families:\n",
    "    print(f\"Predicting for family: {family}\")\n",
    "    \n",
    "    # Filter test data for current family\n",
    "    family_test_data = test[test['family'] == family].copy()\n",
    "    \n",
    "    if len(family_test_data) > 0:\n",
    "        # Prepare features (remove date and family columns)\n",
    "        X_test_family = family_test_data.drop(columns=['date', 'family'])\n",
    "        \n",
    "        # Get the trained model for this family\n",
    "        model = models[family]\n",
    "        \n",
    "        # Generate predictions\n",
    "        family_predictions = model.predict(X_test_family)\n",
    "        \n",
    "        # Ensure no negative predictions\n",
    "        family_predictions = np.maximum(family_predictions, 0)\n",
    "        \n",
    "        # Store predictions and corresponding IDs\n",
    "        test_predictions.extend(family_predictions)\n",
    "        \n",
    "        # Get corresponding IDs from test_df\n",
    "        family_ids = test_df[test_df['family'] == family]['id'].values\n",
    "        test_ids.extend(family_ids)\n",
    "        \n",
    "        print(f\"Generated {len(family_predictions)} predictions for {family}\")\n",
    "\n",
    "print(f\"Total predictions generated: {len(test_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4517c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission shape: (28512, 2)\n",
      "\n",
      "First few predictions:\n",
      "        id        sales\n",
      "0  3000888     3.570112\n",
      "1  3000889     0.008389\n",
      "2  3000890     4.317428\n",
      "3  3000891  1903.858702\n",
      "4  3000892     0.002790\n",
      "5  3000893   367.950008\n",
      "6  3000894     7.769529\n",
      "7  3000895   709.326395\n",
      "8  3000896   717.282500\n",
      "9  3000897   135.240102\n",
      "\n",
      "Last few predictions:\n",
      "            id        sales\n",
      "28502  3029390     8.568008\n",
      "28503  3029391   443.973066\n",
      "28504  3029392   409.737717\n",
      "28505  3029393     5.568979\n",
      "28506  3029394     5.598493\n",
      "28507  3029395   405.458147\n",
      "28508  3029396   146.848428\n",
      "28509  3029397  2380.691371\n",
      "28510  3029398   101.711035\n",
      "28511  3029399    14.649301\n",
      "\n",
      "Prediction statistics:\n",
      "Min: 0.0028\n",
      "Max: 10989.0807\n",
      "Mean: 414.5949\n",
      "Median: 28.1026\n"
     ]
    }
   ],
   "source": [
    "# Create submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'sales': test_predictions\n",
    "})\n",
    "\n",
    "# Sort by id to ensure proper order\n",
    "submission_df = submission_df.sort_values('id').reset_index(drop=True)\n",
    "\n",
    "print(f\"Submission shape: {submission_df.shape}\")\n",
    "print(\"\\nFirst few predictions:\")\n",
    "print(submission_df.head(10))\n",
    "\n",
    "print(\"\\nLast few predictions:\")\n",
    "print(submission_df.tail(10))\n",
    "\n",
    "print(f\"\\nPrediction statistics:\")\n",
    "print(f\"Min: {submission_df['sales'].min():.4f}\")\n",
    "print(f\"Max: {submission_df['sales'].max():.4f}\")\n",
    "print(f\"Mean: {submission_df['sales'].mean():.4f}\")\n",
    "print(f\"Median: {submission_df['sales'].median():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b30e223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved as: traditional_submission.csv\n",
      "File contains 28512 predictions\n",
      "\n",
      "Verifying submission file...\n",
      "Loaded file shape: (28512, 2)\n",
      "Columns: ['id', 'sales']\n",
      "No missing values: True\n",
      "All IDs unique: True\n"
     ]
    }
   ],
   "source": [
    "# Save submission file\n",
    "submission_filename = 'traditional_submission.csv'\n",
    "submission_df.to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"Submission file saved as: {submission_filename}\")\n",
    "print(f\"File contains {len(submission_df)} predictions\")\n",
    "\n",
    "# Verify the submission file\n",
    "print(\"\\nVerifying submission file...\")\n",
    "verify_df = pd.read_csv(submission_filename)\n",
    "print(f\"Loaded file shape: {verify_df.shape}\")\n",
    "print(f\"Columns: {list(verify_df.columns)}\")\n",
    "print(f\"No missing values: {verify_df.isnull().sum().sum() == 0}\")\n",
    "print(f\"All IDs unique: {len(verify_df['id'].unique()) == len(verify_df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
